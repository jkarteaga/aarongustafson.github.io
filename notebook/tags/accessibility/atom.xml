<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Browse by Tag: Accessibility | Aaron Gustafson]]></title>
  <link href="https://www.aaron-gustafson.com/notebook/tags/accessibility/atom.xml" rel="self"/>
  <link href="https://www.aaron-gustafson.com/"/>
  <updated>2017-01-04T21:04:39-05:00</updated>
  <id>https://www.aaron-gustafson.com/</id>
  <author>
    <name><![CDATA[Aaron Gustafson]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Lessons in Averaging]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/lessons-in-averaging/"/>
    <updated>2016-12-14T13:01:32-05:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/lessons-in-averaging</id>
    <content type="html"><![CDATA[<p>In the work that we do on the Web (as well as in our daily lives), we’re often confronted, informed, or judged based on averages. I never really stopped to think about it, beyond being bugged by the fact that averages aren’t truly representative of reality. Then I listened to <a href="http://99percentinvisible.org/episode/on-average/">99% Invisible’s episode “On Average”</a>. It was incredibly enlightening and the stories shared in that episode provide sage wisdom that is very relevant to the work that we do.</p>

<!-- more -->

<p>Do you know where our fascination with averages began? It all started with Adolphe Quételet, a Belgian mathematician and astronomer:</p>

<blockquote>
  <p>In the 1830s, astronomers were some of the only people that regularly calculated averages, since early telescopes were extremely imprecise. To obtain more accurate data for say, tracking the orbits of planets, astronomers would take multiple measurements (all of which were slightly different) add them together, then divide by the number of observations to get a better approximation of the true value.</p>
</blockquote>

<p>Quetelet decided to apply this tool to people, starting with Scottish soldiers’ chest sizes. Turns out the average chest size of a Scottish soldier in the 1830s was 39.75 inches. File that one away for Pub Trivia.</p>

<p>Quetelet believed that the average was the “true” size of something… something that we should strive for or that nature would attempt to create. The <a href="https://en.wikipedia.org/wiki/Platonic_idealism">Platonic ideal</a> if you will:</p>

<blockquote>
  <p>In Quetelet’s mind, human averages had a certain moral mandate. By his logic, if everyone were optimally fed and lived under the same environmental conditions, they would be average. And this is what society should be striving for: the continual improvement of the average of the group.</p>
</blockquote>

<p>We look at averages all the time in our work. Some, like average <a href="https://developers.google.com/web/tools/lighthouse/audits/time-to-interactive">Time To Interactive (TTI)</a>, are useful measurements that allow us to improve our work; others, like the “average” user are decidedly less so. <span data-quotable="">The “average” person (or dog or flower) is a myth. Everyone and everything is unique to some equally unique degree.</span> <a href="https://en.wikipedia.org/wiki/Factory_second">Even mass-produced objects have variance</a>.</p>

<p>Designing for the “average” user is incredibly problematic. The episode I mentioned captured this perfectly in a story about the U.S. Army’s design of airplane cockpits:</p>

<blockquote>
  <p>[I]n 1926, when the Army designed its first airplane cockpit, they measured the physical dimensions of male pilots and calculated the average measurement of their height, weight, arm-length and other dimensions.</p>
</blockquote>

<blockquote>
  <p>The results determined the size and shape of the seat, the distance to the pedals and the stick, and even the shape of the flight helmets. This mean that, in part, pilots were selected based on their ability to fit into the cockpit designed for the average 1920s man.</p>
</blockquote>

<blockquote>
  <p>This worked more or less up until World War II, when the Army began recruiting hundreds of new pilots to expand its air forces (which became a separate branch of the military in 1947). But with the birth and expansion of the Air Force came a decline in performance and a rash of deaths. Even with no war, pilots continued to die during training, as they were unable to control their planes.</p>
</blockquote>

<blockquote>
  <p>The high death rate in the Air Force was a mystery for many years, but after blaming the pilots and their training programs, the military finally realized that the cockpit itself was to blame, that it didn’t actually fit most pilots.</p>
</blockquote>

<p>In 1950, the Air Force sent Gilbert S. Daniels out to collect ten measurements from thousands of airmen—yes, they were all men at the time—across the U.S. in order to establish a new average. After collecting the data, Daniels got curious and decided to see how many of the airmen he measured hit the average on all ten measurements. Not a single one. How about three of the measurements? Less than five percent. He realized that <span data-quotable="">in designing for an average, they were, in fact, designing for no one.</span> Based on this discovery, the Air Force commissioned new equipment that including features like adjustable foot pedals, helmet straps, flight suits, and seats. And, wonder of wonders, pilot performance improved dramatically.</p>

<p>When we design, we need to be cognizant of the variety of human experience and plan accordingly. <span data-quotable="">For our work to be successful, we need to accommodate the adjustments our users require for <em>them</em> to be successful.</span> Responsive layouts, adaptive interfaces, support for assistive technologies… all of these approaches enable our work to go further by enabling it to be tailored to the permanent, temporary, and/or situational needs of our users.</p>

<p>All of this is to say, this episode made me an even more ardent believer in the idea of <a href="http://alistapart.com/article/understandingprogressiveenhancement">progressive enhancement</a> and the continuum of experience it enables. You should go listen to it now, I promise there’s more to the story.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Progressive Misconceptions]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/progressive-misconceptions/"/>
    <updated>2016-10-17T15:33:55-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/progressive-misconceptions</id>
    <content type="html"><![CDATA[<p>Last week, my colleague<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup> <a href="https://nolanlawson.com/">Nolan Lawson</a> wrote <a href="https://nolanlawson.com/2016/10/13/progressive-enhancement-isnt-dead-but-it-smells-funny/">a lengthy post about his struggles with progressive enhancement</a>. In it, he identified a key tension between the JavaScript community and the progressive enhancement community that has, frankly, existed since the term “progressive enhancement” was coined some 13 years ago. I wanted to take a few minutes to tuck into that tension and assure Nolan and other folks within the JS community that neither progressive enhancement nor the folks who advocate it (like me) is at odds with them or their work.</p>

<!-- more -->

<p>But first let’s take a a trip back in time to 2003. In March of that year, <a href="http://hesketh.com/publications/inclusive_web_design_for_the_future.html">Steve Champion introduced a concept he called “progressive enhancement”</a>. It caused a bit of an upheaval at the time because it challenged the dominant philosophy of graceful degradation. Just so we’re all on the same page, I’ll compare these two philosophies.</p>

<h2 id="whats-graceful-degradation">What’s graceful degradation?</h2>

<p><em>Graceful degradation</em> assumes that an experience is going to be worse on older, less capable browsers and devices. To address potential problems, it recommends that developers take steps to avoid throwing errors—JavaScript or otherwise—for their users. Under this philosophy, a developer can take a range of approaches ranging from making everything work perfectly in down-level browsers to only addressing egregious errors or even chosing to block certain browsers from accessing the content if they are known to have problems. We saw this latter approach often with Flash-only sites, but it wasn’t limited to them. I used <a href="#2016-10-17-1">this “roadblock” example from Kodak.com</a> in <a href="http://adaptivewebdesign.info/">my book</a>:</p>

<figure id="fig-2016-10-17-1" class="media-container">{% adaptive_image /i/posts/2016-10-17/kodak-roadblock.png %}</figure>

<p>Overall, graceful degradation is about risk avoidance. The problem was that it created a climate on the Web where we, as developers, got comfortable with the idea of denying access to services (e.g., people’s bank accounts) because we deemed a particular browser (or browsers) too difficult to work with. Or, in many cases, we just didn’t have the time or budget (or both) to address the broadest number of browsers. It’s kind of hard to reconcile the challenge of cross-browser development in 2003 with what we are faced with today as we were only really dealing with 2-3 browsers back then, but you need to remember that standards support was far worse at the time.</p>

<h2 id="so-whats-progressive-enhancement">So what’s progressive enhancement?</h2>

<p>In his talk, Steve upended the generally shared perspective that older browsers deserved a worse experience because they were less technically capable. He asked us to look beyond the browsers and the technologies in play and focus on the user experience, challenging us to design inclusive experiences that would work in the broadest of scenarios. He asked that we focus on the content and core tasks in a given interface and then enhance the experience when we could. We accomplish this by layering experiences on top of one another, hence “progressive enhancement”.</p>

<p>What’s particularly interesting about this approach is that it is still technically graceful degradation because all of the interfaces do gracefully fall back to a usable state. But it’s graceful degradation at its best, focused on delivering a good experience to everyone. No excuses.</p>

<p>To give a simple example, consider a form field for entering your email address. If we were to mark it up like this</p>

<pre><code>&lt;input type="email" name="email" id="email"&gt;
</code></pre>

<p>I automatically create layers of experience with no extra effort:</p>

<ol>
<li>Browsers that don’t understand “email” as a valid <code>input</code> type will treat the “email” text as a typo in my HTML (like when you type “rdio” instead of “radio”… or maybe I’m the only one that does that). As a result, they will fall back to the default input type of “text”, which is usable in every browser that supports HTML2 and up.</li>
<li>Browsers that consider “email” a valid <code>input</code> type will provide one (or more) of many potential enhanced experiences:
<ol type="a">
<li>In a virtual keyboard context, the browser may present a keyboard that is tailored toward quickly entering email addresses.</li>
<li>In a browser that supports auto-completion, it may use this as a cue to suggest entering a commonly-entered email or one that has been stored in the user’s profile.</li>
<li>In a browser that supports HTML5 validation, the browser may validate this field for proper email formatting when the user attempts to submit the form.</li>
<li>In a browser that does not support HTML5 validation or that doesn’t actively block submission on validation errors—<a href="https://bugs.webkit.org/show_bug.cgi?id=28649">like Safari</a>—a developer-supplied JavaScript program may use the <code>type</code> attribute as a signal that it should validate the field for proper email address formatting.</li>
</ol>
</li>
</ol>

<p>That means that there are between 5 and 13 potential experiences (given all of the different possible combinations of these layers) in this one single single element… it’s kind of mind-boggling to think about, right? And the clincher here is that any of these experiences can be a good experience. Heck for nearly 15 years of the Web, the plain-ol’ text <code>input</code> was the only way we had for entering an email address. Anything better than that is gravy.</p>

<p>Progressive enhancement embraces the idea of experience as a continuum rather than some singular ideal. It recognizes that every person is different and we all have special requirements for Web access. Some may depend on our browser, the device we’re on, and the network we are using. Others may be the result of a limitation we have dealt with since birth, are dealing with temporarily as the result of an injury or incident, or are simply a factor of our current situation. We all experience the world differently and progressive enhancement not only respects that, it embraces that variability.</p>

<p>How does it do this? Progressive enhancement takes advantage of the fault tolerant nature of HTML and CSS. It also uses JavaScript’s own ability to test for browser features to tailor programmatic enhancements to the given device and situation. That’s right: progressive enhancement and JavaScript go hand-in-hand.</p>

<h2 id="why-are-so-many-javascript-folks-hostile-to-progressive-enhancement">Why are so many JavaScript folks hostile to progressive enhancement?</h2>

<p>As a member of the JavaScript community for over a decade now, I have theory for why many JavaScript developers are so antagonistic toward progressive enhancement. Part of it has to do with history and part of it has to do with programming culture. Let’s tackle the history first.</p>

<p>When progressive enhancement was first proposed, the Web was getting more standardized, but things were still a bit of a mess… especially in the JavaScript world. Many JavaScript programs were poorly-written, contained lots of browser-specific code, and were generally unfriendly to anyone who fell outside of the relatively narrow band of “normal” Web use… like screen reader users, for example. It’s not surprising though: Graceful degradation was the name of the game at the time.</p>

<p>Because JavaScript programs were creating barriers for users who just wanted to read news articles, access public services, and check their bank accounts, many accessibility advocates recommended that these folks disable JavaScript in their browsers. By turning off JavaScript, the theory went, users would get clean and clear access to the content and tasks they were using the Web for. Of course that was in the days before Ajax, but I digress.</p>

<p>This recommendation served as a bit of a wake-up call for many JavaScript developers who had not considered alternate browsing experiences. Some chose to write it off and continued doing their own thing. Others, however, accepted the challenge of making JavaScript more friendly to the folks who relied on assistive technologies (AT). Many even went on to write code that actually improved the experience specifically for folks who are AT-dependent. Dojo and YUI, though sadly out of favor these days, were two massive libraries that prioritized accessibility. In fact, I’d go so far as to say they ushered in a period of alignment between JavaScript and accessibility.</p>

<p>Even though JavaScript and accessibility are no longer at odds (and really haven’t been for the better part of a decade), there are still some folks who believe they are. People routinely come across old articles that talk about JavaScript being inaccessible and they turn around and unfairly demonize JavaScript developers as unsympathetic toward folks who rely on screen readers or other AT. It’s no wonder that some JavaScript developers become immediately defensive when the subject of accessibility comes up… especially if it’s not something they’re all that familiar with.</p>

<hr />

<p>I also mentioned that programming culture plays a part in the antagonistic relationship between the progressive enhancement camp and the JavaScript community. If you’ve been a programmer for any amount of time, you’ve probably borne witness to the constant finger-pointing, belittling, and arrogance when it come to the languages we choose to program in or the tools we use to do it.</p>

<p>As a programmer, you receive a near constant barrage of commentary on your choices… often unsolicited. <em>You’re using PHP? That’s so 1996! You’re still using TextMate?! You still use jQuery? How quaint!</em> I’m not exactly sure where this all began, but it’s unhealthy and causes a lot of programmers to get immediately defensive when anyone challenges their language of choice or their process. And this hostile/defensive environment makes it very difficult to have a constructive conversation about best practices.</p>

<p>Progressive enhancement should not be viewed as a challenge to JavaScript any more than concepts like <a href="https://www.safaribooksonline.com/library/view/learning-javascript-design/9781449334840/ch13s15.html">namespacing</a>, <a href="https://en.wikipedia.org/wiki/Test-driven_development">test driven development</a>, or <a href="http://www.yottaa.com/company/blog/application-optimization/how-does-reducing-javascript-requests-minifying-javascript/">file concatenation &amp; minification</a> are; it’s just another way to improve your code. That said, progressive enhancement does introduce a wrinkle many for hardcore JavaScript programmers seem unwilling to concede: JavaScript is fragile. At least on the client side, JavaScript development requires far more diligence when it comes to error handling and fallbacks than traditional programming because, unlike with traditional software development, <a href="https://www.aaron-gustafson.com/notebook/a-fundamental-disconnect/">we don’t control the execution environment</a>.</p>

<p><a href="http://www.crockford.com/">Douglas Crockford</a> (in)famously declared the Web “the most hostile software engineering environment imaginable” and he wasn’t wrong. A lot of things have to go right for our code to reach our users precisely the way we intend. Here are just a few of these requirements:</p>

<ol>
  <li>Our code must be bug-free;</li>
  <li>Included 3rd party code must be bug free and must not interfere with our code;</li>
  <li>Intermediaries—ISPs, routers, etc.—must not inject code or if they do, it must be bug free and not interfere with our code;</li>
  <li>Browser plugins must not interfere with our code;</li>
  <li>The browser must support every language feature and API we want to use; and</li>
  <li>The device must have enough RAM and a fast enough processor to run our code.</li>
</ol>

<p>Some of these can be addressed by programming defensively using test-driven development, <a href="http://www.slideshare.net/simonguest/automated-web-testing-using-javascript">automated QA testing</a>, <a href="https://developer.mozilla.org/docs/Using_Web_Standards_in_your_Web_Pages/Developing_cross-browser_and_cross-platform_pages#Using_Object.2FFeature_support_detection_approach:_best_and_overall_most_reliable">feature detection</a>, and markup detection. These aren’t guaranteed to catch everything—markup can change after a test has run but before the rest of the code executed, <a href="http://javascriptissexy.com/javascript-objects-in-detail/">JavaScript objects are mutable</a> meaning features can accidentally disappear, etc.—but they are incredibly helpful for creating robust JavaScript programs. You can also run your projects under HTTPS to avoid intermediaries manipulating your code, though <a href="http://arstechnica.com/security/2015/01/gogo-issues-fake-https-certificate-to-users-visiting-youtube/">that’s not fool-proof either</a>.</p>

<p>The devices themselves, we have no control over. It’s not like we can send a new device to each and every user (or prospective user) we have just to ensure they have the appropriate hardware and software requirements to use our product.<sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup> Instead, we need to <a href="https://www.smashingmagazine.com/2012/11/writing-fast-memory-efficient-javascript/">write JavaScript programs that play well in a multitude of of scenarios (including resource-limited ones)</a>.</p>

<p>And, of course, none of this addresses network availability. In many instances, a user’s network connection has the greatest impact on their experience of our products. If the connection is slow (or the page’s resources are exceptionally large) the page load experience can be excruciatingly painful. If the connection goes down and dependencies aren’t met, the experience can feel disjointed or may be flat out broken. Using <a href="https://developer.mozilla.org/docs/Web/API/Service_Worker_API">Service Worker</a> and client-side storage (<a href="https://developer.mozilla.org/docs/Web/API/IndexedDB_API"><code>indexedDB</code></a> and <a href="https://developer.mozilla.org/docs/Web/API/Web_Storage_API">Web Storage</a>) can definitely help mitigate these issues for repeat visits, but they don’t do much to help with initial load. They also don’t work at all if your JavaScript program doesn’t run. Which brings me to my last point.</p>

<p>When you love a language like JavaScript (as I do), it can be difficult to recognize (or even admit) it’s shortcomings, but recognizing them is part of becoming a better programmer. The Web is constantly evolving and our understanding of the languages we use to build it expands as fast as—or often faster than—their capabilities do. As such, we need to remain open to new and different ways of doing things. Change can be scary, but it can also be good. Being asked to consider a non-JavaScript experience shouldn’t be seen as an affront to JavaScript, but rather a challenge to create more robust experiences. After all, our last line of defense in providing a good user experience is providing one with <a href="https://www.smashingmagazine.com/2016/05/developing-dependency-awareness/">the least number of dependencies</a>. That’s what progressive enhancements asks us to do.</p>

<h2 id="javascript--pe-kissing-in-a-tree">JavaScript &amp; PE kissing in a tree?</h2>

<p>All of this is to say I don’t think JavaScript and progressive enhancement are diametrically opposed and I don’t think folks who love the JavaScript language or tout the progressive enhancement philosophy should be either. Together they have the potential to making the Web the best it can possibly be.</p>

<p>Progressive enhancement’s focus on providing a baseline experience that makes no assumptions about browser features will provide a robust foundation for any project. It also guides us to be smarter about <em>how</em> we apply technologies like HTML, CSS, JavaScript and ARIA by asking us to consider what happens when those dependencies aren’t met.</p>

<p>JavaScript absolutely makes the user experience better for anyone who can benefit from it. It can make interfaces more accessible. It can help mitigate networking issues. It can create smoother, more seamless experiences for our users. And it can reduce the friction inherent in accomplishing most tasks on the Web. JavaScript is an indispensable part of the modern Web.</p>

<p>In order to come together, however, folks <a href="https://www.baldurbjarnason.com/notes/debating-web-development/">need to stop demonizing and dismissing one another</a>. Instead we need to rally together to make the Web better. But before we can do that, we need to start with a common understanding of the nature of JavaScript. The progressive enhancement camp needs to concede that all JavaScript is not evil, or even bad—JavaScript can be a force for good and it’s got really solid support. The JavaScript camp needs to concede that, despite its ubiquity and near universal support, we can never be absolutely guaranteed our JavaScript programs will run.</p>

<p>I fully believe we can heal this rift, but it’s probably gonna take some time. I fully intend to do my part and I hope you will as well.</p>

<p><ins datetime="2016-10-18T11:11:00-04:00"><strong>Update:</strong> This post was updated to clarify that graceful degradation can take many forms and to explicitly tie progressive enhancement and graceful degradation together.</ins></p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>Full disclosure: We both work at Microsoft, but on different teams. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>It’s worth noting that <a href="http://gizmodo.com/website-opts-to-buy-customers-new-computers-rather-than-1513186669">one company, NursingJobs, actually did this</a>. <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What Would You Do With 10kB?]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/what-would-you-do-with-10kb/"/>
    <updated>2016-08-17T14:48:27-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/what-would-you-do-with-10kb</id>
    <content type="html"><![CDATA[<p>Sixteen years ago, <a href="https://twitter.com/stewart">Stewart Butterfield</a> conceived of a contest that would test the mettle of any web designer: <a href="http://web.archive.org/web/20000510010054/http:/www.sylloge.com/5k/home.html">The 5k</a>. The idea was that entrants would build <a href="http://alistapart.com/article/5k">an entire site in 5kB of code or less</a>. Its aim was to force us to get creative by putting a bounding box on what we could do:</p>

<blockquote>
  <p>Between servers and bandwidth, clients and users, HTML and the DOM, browsers and platforms, our conscience and our ego, we’re left in a very small space to find highly optimal solutions. Since the space we have to explore is so small, we have to look harder, get more creative; and that’s what makes it all interesting.</p>
</blockquote>

<!-- more -->

<p>The 5k contest ran from 2000 until 2002. In 2010, <a href="http://www.zeldman.com/2010/07/29/10k-apart-%E2%80%93%C2%A0inspire-the-web/">An Event Apart and Microsoft revived the idea</a> with an updated limit and a new name: <a href="http://web.archive.org/web/20100730090946/http:/10k.aneventapart.com/">10k Apart</a>. Staying true to its roots, this new incarnation, which ran for two years, continued to push designers and developers to get creative within a pretty extreme (though slightly expanded) limit while incorporating new goodies like HTML5 and responsive design.</p>

<p>I’m thrilled to announce that <a href="https://a-k-apart.com/">the 10k Apart contest is back</a> and brings with it a handful of new challenges:</p>

<ol>
  <li><strong>Each page must be usable in 10kB or less.</strong> The 10kB limit no longer applies to the size of a ZIP archive of your entry; the 10kB limit now applies to the total initial download size of the baseline experience of each page in your project. When we say “baseline experience,” we’re talking small screen devices running older, less capable browsers. The 10kB limit will apply to every page and whatever assets it loads by default; that means images, CSS, JavaScript, and so on.</li>
  <li><strong>Progressive enhancement is the name of the game.</strong> Your project should start with a super-basic, bare-bones-but-usable experience that will work no matter what (including without JavaScript). You can use clever CSS and JavaScript techniques to enhance that experience as it makes sense to do so. For example: You might lazy load an image using JavaScript if the screen size is above a certain threshold or when certain other conditions are met. Entries that depend entirely on JavaScript to render the front-end won’t be accepted. If you need a primer on progressive enhancement, <a href="http://alistapart.com/search?keywords=progressive%20enhancement">consult the pages of <cite>A List Apart</cite></a>.</li>
  <li><strong>Back ends are in this year.</strong> In previous iterations, each entry comprised client-side code submitted via ZIP file. Over time, that limitation led to an over-reliance on JavaScript for rendering. No more. This year, you can create dynamic experiences that work without front-end JavaScript using Node, PHP, Python or .Net. You will submit your entry as public GitHub repository (so we can all learn from your awesome code) and we’ll spin up a dedicated <a href="https://azure.microsoft.com/">Azure</a> instance running the appropriate stack.</li>
  <li><strong>Entries should be accessible.</strong> In line with the philosophy of progressive enhancement, your entry should be usable by the broadest number of users possible. <a href="http://www.accessiq.org/news/commentary/2012/09/web-accessibility-is-a-mindset-not-a-checklist">Accessibility is not a checklist</a>, but if you’re clueless about where to start, <a href="https://www.w3.org/TR/WCAG20-TECHS/">these techniques</a> can offer some guidance.</li>
  <li><strong>Nothing comes for free.</strong> In previous years, we gave a pass if you wanted to use jQuery or load some fonts from Typekit. This year we decided to change it up, not because we don’t love these products (we do), but because we wanted to force every piece of code, every asset, to fight for its place in your entry. Anything you add should be added with purpose.</li>
</ol>

<p>As with previous editions, your entry should use web standards and work in all modern browsers. You can use HTML, CSS, and JavaScript features and APIs that don’t have across-the-board support as long as you do so in keeping with the progressive enhancement philosophy. In other words, your entry can’t depend on that technology or feature in order to be usable.</p>

<p>All of this may sound like a tall order, but it’s entirely possible. In fact, the site we built for the contest also abides by these rules. My colleagues and I will touch on some of the techniques we used (and concessions we made) in building the site in future posts.</p>

<p>If you’ve read this far, you might be wondering <em>What’s in it for me?</em> Well, bragging rights, of course, but we’ve got some awesome prizes too! We’re giving away $10,000 to the top three entries, plus <a href="http://aneventapart.com/events">tickets to An Event Apart</a>, complete collections of <a href="https://abookapart.com/collections/standards-collection">A Book Apart titles</a>, and copies of <a href="http://adaptivewebdesign.info/2nd-edition/">my book</a> too. <a href="https://a-k-apart.com/#prizes">Complete details of the prizes</a> are over on <a href="https://a-k-apart.com/">the contest site</a>.</p>

<p>We’ve lined up an amazing group to judge the entires this year too: <a href="https://twitter.com/rachelandrew">Rachel Andrew</a>, <a href="https://twitter.com/lara_hogan">Lara Hogan</a>, <a href="https://twitter.com/wilto">Mat Marquis</a>, <a href="https://twitter.com/Heydonworks">Heydon Pickering</a>, <a href="https://twitter.com/jensimmons">Jen Simmons</a>, and <a href="https://twitter.com/SaraSoueidan">Sara Soueidan</a> will all be putting your entry through its paces and peering under the hood at your code. There’s also a People’s Choice award which will be based on votes you cast. Voting will open October 1st and run through October 14th.</p>

<p>The contest opened Monday and we will accept entries until 5pm Pacific Time on September 30th. <a href="https://a-k-apart.com/legal">Everything you should need to know about the contest, eligibility, etc.</a> is up on <a href="https://a-k-apart.com/">the 10k Apart site</a>, but if you have additional questions, <a href="https://a-k-apart.com/hi">you can always reach out</a>.</p>

<p>I can’t wait to see what you come up with! Happy coding!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Web Should Just Work for Everyone]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/the-web-should-just-work-for-everyone/"/>
    <updated>2016-04-11T11:51:52-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/the-web-should-just-work-for-everyone</id>
    <content type="html"><![CDATA[<p><em>I had the great pleasure of delivering the following talk at the <a href="http://lanyrd.com/2016/edgesummit/">Edge Web Summit</a> on April 4th. The talk is largely about accessibility with a push for thinking about the future of the interface and how considering accessibility now will help us prepare for a world of “headless UIs”.</em></p>

<!-- more -->

<hr />

<p>We, as an industry, tend to have a pretty myopic view of experience. Those of us who work day-to-day in accessibility probably have a broader perspective than most, but I would argue that even we all fall short now and again when it comes to seeing the Web as others do.</p>

<p>I’m, of course, talking about accessibility. Now if you’re like most audiences, I’m guessing when you hear the word “accessibility” you probably think “screen reader”. That’s ok. Screen readers are certainly one part of the assistive technology spectrum, but my hope is, that by the end of this talk, when someone says “accessibility” you instead think… “opportunity”.</p>

<figure id="fig-2016-04-11-01" class="media-container"><img src="https://www.aaron-gustafson.com/i/posts/2016-04-11/01.gif" alt="The word “Accessibility” exploding to reveal the word “opportunity”." /></figure>

<p>Accessibility is concerned with accommodating disabilities, but our understanding of what a disability is has changed over time. In the 1980s, the World Health Organization defined a disability as a personal attribute:</p>

<blockquote>
  <p>In the context of health experience, a disability is any restriction or lack of ability (resulting from an impairment) to perform an activity in the manner or within the range considered normal for a human being.</p>
</blockquote>

<p>They have since <a href="http://www.who.int/topics/disabilities/en/">updated their definition of a disability</a> to be more context-dependent:</p>

<blockquote>
  <p>Disability is not just a health problem. It is a complex phenomenon, reflecting the interaction between features of a person’s body and features of the society in which he or she lives.</p>
</blockquote>

<p>The points of interaction between a person and society are where disability happens. It’s our responsibility to know how our designs affect these interactions.</p>

<p>If we use our own abilities and biases as a starting point, we end up with products designed for people of a specific age, language ability, tech literacy, and physical ability. Plus those with specific access to money, time, and stable network connections.</p>

<figure id="fig-2016-04-11-02" class="media-container">
{% adaptive_image /i/posts/2016-04-11/02.png %}
<figcaption>A figurative graph charting user ability against population using a bunch of different icons for people. One person is identified as a designer and she is part of a subset of the people that are in grey, signifying that they are "included" when the designer considers things from their own perspective. The vast majority of the people icons are in red, signifying they are "excluded" by this line of thinking.</figcaption>
</figure>

<p>When it comes to people, there’s no such thing as “normal”. For example, the interactions we design with technology depend heavily on what we can see, hear, say, and touch. If we’re designing with ourselves as a baseline, we can overlook people with circumstances different from ours.</p>

<p>I love exercises that create opportunities for revelation. One of my favorites originates from <a href="https://en.wikipedia.org/wiki/John_Rawls">John Rawls</a>. Rawls was a philosopher who used to run a social experiment with students, church groups, and the like. In the experiment, individuals were allowed to create their ideal society. It could follow any philosophy. It could be a monarchy or democracy or anarchy. It could be capitalist or socialist. The people in this experiment had free rein to control absolutely every facet of the society… but then he’d add the twist: They could not control what position they occupied in that society.</p>

<p>This twist is what <a href="https://en.wikipedia.org/wiki/John_Harsanyi">John Harsanyi</a>—an early game theorist—refers to as the <a href="https://en.wikipedia.org/wiki/Veil_of_ignorance">“Veil of Ignorance”</a> and what Rawls found, time and time again, was that individuals participating in the experiment would gravitate toward creating the most egalitarian societies.</p>

<p>It makes sense: what rational, self-interested human being would treat the elderly, the sick, people of a particular gender or race or creed or color, poorly if they could find themselves in that position?</p>

<p>We’re often told accessibility is only concerned with folks with “special needs.” Well news flash: <em>we all have special needs</em>. Some we’re born with. Some we develop. Some are temporary. Some have nothing to do with us personally, but are situational or purely dependent on the hardware we are using, the interaction methods we have available to us, or even the speed at which we can access the Internet or process data.</p>

<p>Sometimes disability is a temporary thing. A short-term injury and illness affect the way people interact with the world around them. Looking into bright light can cause brief visual impairment. Being sick with a cough makes it hard to speak. Wearing a cast can severely limit a person’s ability to lift an everyday object.</p>

<p>On the more technical side of things, small touchscreens can be awkward to interact with is you’re fat-fingered like me. Glossy screens can be difficult to read under glaring light. Low-contrast text can be difficult to read when you turn the screen brightness down to conserve battery life on your mobile device.</p>

<p>Recognizing that we all have special needs leads us to make better decisions as designers and developers. When we understand that disability is a universal and dynamic way of interacting with the world, it can become something else as well: a new source for creativity. Our impact can also expand, as our inclusive designs reach a greater number of people.</p>

<p>Designing for people with permanent disabilities can seem like a significant constraint, but the resulting designs can actually benefit a much larger number of people. For example, curb cuts in sidewalks were first created to make it safer and easier for people in wheelchairs to cross the street.</p>

<figure id="fig-2016-04-11-03" class="media-container">
{% adaptive_image /i/posts/2016-04-11/03.jpg %}
<figcaption>A curb cut. <b class="media-container__credit">Photo credit: <a href="https://www.flickr.com/photos/12155320@N00/6793281764/">Dylan Passmore</a></b></figcaption>
</figure>

<p>But curb cuts also help people with a wide range of circumstances, from kids riding bicycles, to parents pushing strollers, to workers hauling heavy equipment.</p>

<figure id="fig-2016-04-11-04" class="media-container">
{% adaptive_image /i/posts/2016-04-11/04.png alt="Numerous needs that benefit from curb cuts: wheelchairs, strollers, bicycles, and skateboards." %}
</figure>

<p>Similarly, high-contrast screen settings were initially made to benefit people with vision impairments. But today, many people benefit from high-contrast settings when they use a device in bright sunlight. The same is true for remote controls, automatic door openers, voice controls, and much more. Designing with constraints in mind is simply designing well.</p>

<figure id="fig-2016-04-11-05" class="media-container">
{% adaptive_image /i/posts/2016-04-11/05.png alt="A disability continuum from permanent (a person with one arm) to temporary (a person with an arm injury) to situational (a new parent holding a baby)." %}
</figure>

<p>By designing for someone with a permanent disability, someone with a situational disability can also benefit. For example, a device designed for a person who has one arm could be used just as effectively by a person with a temporary wrist injury or a new parent holding an infant.</p>

<figure id="fig-2016-04-11-06" class="media-container">
{% adaptive_image /i/posts/2016-04-11/06.png alt="Adding up the number of people in the U.S. who deal with disabilities relating to arm usage gets your to 21 million pretty quickly." %}
</figure>

<p>Being mindful of the continuum from permanent to situational disabilities helps us rethink how our designs can scale to more people in new ways. In the United States, 26,000 people a year suffer from loss of upper extremities.</p>

<p>But when we include people with temporary and situational disabilities, the number is greater than 20M.</p>

<p>As a web design philosophy, progressive enhancement is right in line with the egalitarian inclusive design approach. It calls for equality of opportunity, but doesn’t require equality of outcome. It’s okay for different folks to experience your products in different ways as long as everyone can accomplish the task they set out to do.</p>

<p>As <a href="http://benhoh.com/journal/2012/01/30/from-degradation-to-enhancement">Ben Hoh eloquently put it</a></p>

<blockquote>
  <p>[Progressive enhancement] keeps the design open to the possibilities of sexiness in opportune contexts, rather than starting with the ‘whole’ experience that must be compromised.</p>
</blockquote>

<p>At its essence, progressive enhancement is about being good designers. The definition of design is “to devise for a specific function or end” Classically, it means “to indicate” and comes from the medieval Latin: <i lang="la">designare</i>, meaning “to mark out”.</p>

<blockquote>
  <p>I’ve been amazed at how often those outside the discipline of design assume that what designers do is decoration—likely because so much bad design simply is decoration. Good design isn’t. Good design is problem solving.</p>
</blockquote>

<p>As Jeff Veen so astutely observed in <a href="http://www.inspireux.com/2009/01/19/good-design-isnt-decoration-good-design-is-problem-solving/">this quote</a>, there is a lot of bad “design” out there that is more concerned with aesthetics than problem solving.</p>

<p>When we are concerned with the user interface, it can sometimes be at the expense of the user experience.</p>

<figure id="fig-2016-04-11-07" class="media-container">
{% adaptive_image /i/posts/2016-04-11/07.png %}
<figcaption>The <a href="http://impossibleobjects.com/coffeepot-for-masochists.html">Coffeepot for Masochists by Jaques Carelman</a> famously referenced by Donald Norman in <a href="http://amzn.to/1RP2vB9"><cite>Emotional Design</cite></a>.</figcaption>
</figure>

<p>It is possible to have something both beautiful and highly functional.</p>

<figure id="fig-2016-04-11-08" class="media-container">
{% adaptive_image /i/posts/2016-04-11/08.jpg %}
<figcaption>A ramp embedded in staircase of <a href="https://en.wikipedia.org/wiki/Robson_Square">Robson Square</a> in Vancouver, <abbr aria-label="British Columbia">BC</abbr>. <b class="media-container__credit">Photo credit: <a href="https://www.flickr.com/photos/mag3737/">Tom Magliery</a></b></figcaption>
</figure>

<p><a href="https://24ways.org/">24 Ways</a> is an advent calendar for web professionals. It’s a magazine of sorts, but it is both highly interactive and accessible. The site’s developers employ a handful of features from <a href="https://www.w3.org/TR/wai-aria/">the ARIA spec</a> to increase the accessibility of the site.</p>

<p>One such feature is <a href="https://www.w3.org/WAI/GL/wiki/Using_ARIA_landmarks_to_identify_regions_of_a_page">ARIA landmarks</a>, which identify key areas of a web page. Such as the primary header or “banner” of a site.</p>

<p>{% gist 9b3c92fec79342edc9400b48ecaa0cb8 banner.html embed %}</p>

<p>The main content.</p>

<p>{% gist 9b3c92fec79342edc9400b48ecaa0cb8 main.html embed %}</p>

<p>Content concerned with easing navigation of the site.</p>

<p>{% gist 9b3c92fec79342edc9400b48ecaa0cb8 navigation.html embed %}</p>

<p>Or even information about the content, such as copyright designations.</p>

<p>{% gist 9b3c92fec79342edc9400b48ecaa0cb8 contentinfo.html embed %}</p>

<p>Users browsing with an ARIA-aware screen reader can use these landmarks to quickly navigate through a document.</p>

<figure id="figure-2016-04-11-09">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-04-11/09.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-04-11/09.mp3" type="audio/mpeg;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-04-11/09.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-04-11/09.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<p>This example hints at a simple reality: <strong>Every interface is a conversation</strong>. We engage our users directly in an effort to inform them, entertain them, or persuade them to act in a particular way. How this conversation goes directly affects the experience our users have.</p>

<p>Now this may sound great as a quote to share on Twitter—feel free—but it’s absolutely true. And it’s going to become even more important that we pay attention to this conversation as personal assistants—you know, “assistive technology”, it’s right there in the name—begins to play a larger part in our users’ lives.</p>

<p>We need to consider the experience when our products are stripped to their essence. When there is no visual design to entice our users to overlook the fundamental flaws in the design of our interfaces. When there is no UI to help them manage the cognitive load of accomplishing a given task.</p>

<p>Considering this now will put you way ahead of your competition and empower your users to do more with your products. It can seem like a daunting task when we’ve spent so much time fixated on how to enable our users to accomplish key tasks on a screen, especially in a responsive context. But what is responsive design about if not accessibility? Responsive design is concerned with presenting the most appropriate visual experience given the constraints of a screen’s size.</p>

<p>Similarly, conversational interfaces are concerned with the way we communicate with our users, whether there is a screen or not and whether the user can see it or not. This isn’t new, it’s a challenge we’ve tackled before…</p>

<p>Let’s take a trip back in time to one of the earliest computer games: Zork. Zork was written between 1977 and 1979. It’s a text-based adventure game that operates a lot like a game of <em>Dungeons &amp; Dragons</em>—with the program serving the role of gamemaster.</p>

<p>As you move from location to location throughout the game, the program describes the environment and notes objects and people you can interact with. You type what you want to do and the program tells you the results of your actions.</p>

<blockquote>
  <p>West of House<br /> You are standing in an open field west of a white house, with a boarded front door.<br /> There is a small mailbox here.<br /><br />&gt; <strong>open mailbox</strong></p>
</blockquote>

<p>As this was the early days of computer gaming, you might think Zork’s interactions would be simple noun-verb combinations—”kill troll”—but Zork was more sophisticated than that. Its parser was could understand far more complex commands like “hit the troll with the Elvish sword”. This made the experience far more natural, as if you were playing a table top game with friends.</p>

<p>Whether Zork or a webpage, <strong>every interface is a conversation</strong>. When I create a homepage, I’m talking to visitors as if we’ve just met. I’m explaining what they can do on my site (and, in some cases, why it matters). If I’m designing a product page, the conversation is a little different. I’m explaining to my users what a particular object or service is, what it does, and how it will benefit them. I’ll skip the BS sales pitch and talk honestly about the product’s benefits. If I’m designing a contact form, I want to help my users get a message to me quickly and efficiently. I’m also going to set some expectations around how long it will take me to get back to them (and, of course, I’ll need to abide by that promise). Even the humble status update is a conversation. I’m asking a question and then stepping back and letting my users speak. The floor is theirs. (But I’m probably mining what they say for data so I can market to them later.)</p>

<p>Conversations consist of words, so it should come as no surprise that we should choose our words carefully. When talking to people, things generally go better when you talk to them like they talk to you. This is a lesson Facebook learned the (somewhat) hard way.</p>

<p>Over the 2011 holidays, Facebook users were uploading photos like crazy. In the span of a few days, Facebook processed more photo uploads than are contained in the entirety of Flickr. Seriously, that’s a lot of photos.</p>

<p>One unintended consequence of this deluge of photo uploads was a significant uptick in people asking Facebook to remove specific ones. Facebook received millions of these “photo reports”, but they made no sense: Moms holding babies reported for harassment, pictures of puppies reported for hate speech, and so on. Roughly 97% of these photo reports were dramatically mis-categorized.</p>

<p>Facebook’s engineers reached out to some of the users who had reported these photos to get a bit more background regarding their submissions.</p>

<p>At the time Facebook’s photo reporting interface provided a list of reasons users could choose from if they wanted a photo removed, but, as Facebook soon discovered, many of the reports were made because users didn’t want the photo posted for reasons other than those provided.</p>

<p>In some cases, it was because they didn’t like how they looked in the photo. In others, it was because the photo was of an ex-partner or even a beloved pet they’d shared with an ex-boyfriend or ex-girlfriend. The existing photo reporting tool had not done a good job of accounting for these more personal reasons for wanting a photo removed, so the Facebook engineers went to work. They added a step that asked <em>How does this photo make you feel?</em> The options were simple:</p>

<ul>
  <li>Embarrassing</li>
  <li>Upsetting</li>
  <li>Saddening</li>
  <li>Bad Photo</li>
  <li>Other</li>
</ul>

<p>The “other” option also provided a free-response text field to fill in.</p>

<p>With this system in place, they found that 50% of reporters who answered the new question chose one of the provided options. That was pretty helpful, but there was still a problem: 34% of the “other” respondents were writing “It’s embarrassing” in the blank rather than choosing the “embarrassing” option already provided.</p>

<p>What the Facebook team realized was that people were not identifying with the “embarrassing” text (or may have even thought it was referring to them, rather than assuming an implied “It’s”). A subtle shift in language was needed, so they changed the label to <em>Please describe the photo</em> and they updated the options to mirror how people actually talk:</p>

<ul>
  <li>It’s embarrassing</li>
  <li>It’s a bad photo of me</li>
  <li>It makes me sad</li>
</ul>

<p>With this subtle change, they were able to increase the percentage of photo reporters who chose one of the options provided to a whopping 78%.</p>

<p>Words matter. Even in something as simple and banal as a form, the words we choose set the tone for our users’ experiences and often have an affect on what they do… or fail to do. The words we choose matter even more in the world of headless UIs. Without visual aids to help a user see where they are in a form or to aid them in managing the cognitive load of our interfaces, every bit of label and helper text becomes even more important.</p>

<p>When Luke Wroblewski coined “mobile first”, he told us to focus on the core purpose each and every page. He was, in essence, telling us to focus on the conversation we are having with our users. This approach pays huge dividends on small screens, but when it comes to voice-based interactions, “the page” doesn’t really exist. Experience is the sum of each individual interaction.</p>

<p>As part of their Alexa Skills Kit, Amazon offers a ton of recommendations for designing for voice, many of which happen to be equally useful for sighted users.</p>

<h2 id="write-for-people">Write for People</h2>

<p>We don’t author content for ourselves. We write for others. If what we write frustrated or alienates our users, we’ve failed at our job. In their profoundly helpful book <a href="http://amzn.to/1YpYLq1"><cite>Nicely Said</cite></a>, Nicole Fenton and Kate Kiefer Lee offer numerous suggestions for how to write with the reader in mind:</p>

<ul>
  <li>Be clear.</li>
  <li>Be concise.</li>
  <li>Be honest.</li>
  <li>Be considerate.</li>
  <li>Write how you speak.</li>
</ul>

<p>They also make the recommendation that you read your work aloud. As we head into the world of voice-based interactions, that’s beta testing!</p>

<h2 id="avoid-technical-and-legal-jargon">Avoid Technical and Legal Jargon</h2>

<p>For example, if you track error codes for issues on your site, send them to <em>your developers</em>, but never present them to a user. Similarly, we should avoid legalese and write in plain language. Medium has done a great job of this with <a href="https://medium.com/policy/medium-terms-of-service-9db0094a1e0f#.mgexdk816">their Terms of Service</a>.</p>

<h2 id="when-requesting-feedback-make-it-clear-that-the-user-needs-to-respond">When Requesting Feedback, Make It Clear That the User Needs to Respond</h2>

<p>In perhaps the most common form example, consider the label “First Name”. It’s not terribly conversational and doesn’t beg for a response.</p>

<p>{% gist 6f5b7c0f0c072631a908 better-labels.html %}</p>

<figure id="figure-2016-03-04-05">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.mp3" type="audio/mpeg;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<p>Similarly, when there’s an error, notify them of the error and, if possible, give them some clues on how to fix it.</p>

<p>{% gist 6f5b7c0f0c072631a908 field-error.html %}</p>

<figure id="figure-2016-03-04-06">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.mp3" type="audio/mpeg; codecs=&quot;mp3&quot;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<h2 id="when-asking-a-user-to-choose-clearly-present-the-options">When Asking a User to Choose, Clearly Present the Options</h2>

<p>This comes into play often when dealing with forms. Ensuring radio and checkbox controls are properly associated with their labels is critical.</p>

<p>{% gist 6f5b7c0f0c072631a908 radio-label.html %}</p>

<p>You can also use the <code>fieldset</code> and <code>legend</code> elements to group the related controls, but be sure to make the <code>legend</code> focusable or associate it with the first focusable form control in order to ensure the question is read out.</p>

<p>{% gist 6f5b7c0f0c072631a908 fieldset.html %}</p>

<figure id="figure-2016-03-04-07">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.mp3" type="audio/mpeg; codecs=&quot;mp3&quot;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<p>We should strive for the same sort of clarity when presenting navigation options. The HTML5 <code>nav</code> element enables us to semantically identify an area of the page being used for navigation. It is not, however, always identified as being navigation when encountered naturally in the flow of the document. (It is when using role-based navigation like we saw earlier.) For that reason, it can be useful to provide an textual introduction to the section, even if you choose to visibly hide it. You might even consider expanding the text of your navigation items to provide additional context like I do on my site.</p>

<p>{% gist 6f5b7c0f0c072631a908 navigation.html %}</p>

<figure id="figure-2016-03-04-08">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.mp3" type="audio/mpeg; codecs=&quot;mp3&quot;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<p><a href="http://www.npr.org/">NPR</a> has multiple navigation elements on the page and they use ARIA to label them without adding additional tags. Instead, they use the <code>aria-label</code> attribute to distinguish them.</p>

<p>{% gist 9b3c92fec79342edc9400b48ecaa0cb8 aria-label.html embed %}</p>

<h2 id="prompts-should-be-short-while-still-being-clear">Prompts Should be Short, While Still Being Clear</h2>

<p>In <a href="https://www.stmarys-ca.edu/sites/default/files/attachments/files/On_The_Method_of_Theoretical_Physics.pdf">a 1933 lecture at Oxford</a>, Albert Einstein famously said</p>

<blockquote>
  <p>It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience.</p>
</blockquote>

<p>Or, as <a href="https://books.google.com/books?id=prDfAFjet9cC&amp;lpg=PR7&amp;ots=PA9rRog4cr&amp;dq=How%20a%20%E2%80%98Difficult%E2%80%99%20Composer%20Gets%20That%20Way&amp;pg=PA230#v=onepage&amp;q&amp;f=false">Roger Sessions paraphrased it</a></p>

<blockquote>
  <p>Everything should be as simple as it can be but not simpler.</p>
</blockquote>

<p>Clear and concise writing is the hallmark of great content. We need to resist the urge to write for writing’s sake. We write in the service our audience, not for ourselves.</p>

<p>Government websites are some of the worst offenders in this area. Consider this lovely passage:</p>

<blockquote>
  <p>Heavy rains throughout most of the State have given an optimistic outlook for lessened fire danger for the rest of the season. However, an abundance of lightning maintains a certain amount of hazard in isolated areas that have not received an excessive amount of rain.</p>
</blockquote>

<p>It could be written far more clearly as</p>

<blockquote>
  <p>Heavy rains throughout most of the State have lessened fire danger for the rest of the season. However, lightning threatens isolated dry areas.</p>
</blockquote>

<p>In the UK, the Government Digital Service has made great strides overhauling excruciatingly painful content and making it easier to read and understand. One such example is <a href="https://gds.blog.gov.uk/2014/07/28/doing-the-hard-work-to-make-things-simple/">their overhaul of the Accelerated Possession process</a> that allows landlords to evict a tenant.</p>

<p>The original paper form asked for the address like this</p>

<blockquote>
  <p>The claimant seeks an order that the defendant(s) give possession of:<br /> (If the premises of which you seek possession are part of a building identify the part eg. Flat 3, Rooms 6 and 7)</p>
</blockquote>

<p>Before requesting the type of property concerned</p>

<blockquote>
  <p>(‘the premises’) which is<br /> ☐ a dwelling house<br /> ☐ part of a dwellinghouse</p>
</blockquote>

<figure id="figure-2016-03-04-09">
{% adaptive_image /i/posts/2016-03-04/09.png %}
</figure>

<p>Clear and to the point, right?</p>

<p>The GDS went to work and streamlined the process in plain language:</p>

<blockquote>
  <p>What kind of property do you want to take back?<br /> ◎ A self-contained house, flat or bedsit<br /> ◎ Room or rooms in a property.<br /> Tenants may share kitchen or bathroom</p>
</blockquote>

<p>Then they allow you to lookup the property or manually enter the address.</p>

<figure id="figure-2016-03-04-10">
{% adaptive_image /i/posts/2016-03-04/10.png %}
</figure>

<p>While not specifically designed for the future of headless UIs, this form is prepared for their eventuality.</p>

<h2 id="ask-only-necessary-questions">Ask Only Necessary Questions</h2>

<p>We show our users respect by respecting their time. Obviously straightforward, brief writing is one way we do that, but another is to reduce the time it takes to complete a task. Many forms are brimming with fields to be filled in. In some cases, the vast majority are purely optional. And while it may be easy to spot the required fields visually, bypassing them in an aural interface can be incredibly difficult.</p>

<figure id="figure-2016-03-04-11">
{% adaptive_image /i/posts/2016-03-04/11.jpg %}
</figure>

<p>User experience designers have been pushing for simplified forms since… well, as long as I can remember. Users appreciate them, they tend to result in better data, and they also tend to convert better than long forms. And when it comes to voice-based interactions, they will become a necessity. No one is going to want to spend 15 minutes working their way through a 15 question registration form when all that’s required is their email address and for them to choose a password.</p>

<figure id="figure-2016-03-04-12">
{% adaptive_image /i/posts/2016-03-04/12.jpg %}
</figure>

<p>On a similar note, we should avoid slicing fields into multiple parts if at all possible. For instance, you still see fields like this one, asking for a US phone number, quite often:</p>

<figure id="figure-2016-03-04-13">
{% adaptive_image /i/posts/2016-03-04/13.png %}
</figure>

<p>When interacting with this construct via voice, a user will be required to supply three separate values. In order to do so, each field would require a label. Most developers only know how to label the first of those three boxes and users would be really confused if you asked them for their exchange code and line number.</p>

<p>HTML5 introduced a host of new field types that consolidate phone numbers, dates, times, and other complex data types into single fields. Use them! As an added bonus, most enforce content validation and formatting rules for you automatically.</p>

<h3 id="present-information-in-consumable-pieces">Present Information in Consumable Pieces</h3>

<p>Like computers, we humans have a finite amount of “working memory”. The amount of mental resources required to operate an interface is called its “cognitive load”. When the amount of information we need to process exceeds our capacity to handle it, we can miss important details, have trouble concentrating, and become frustrated.</p>

<p>We deal with cognitive load in GUI design all the time, but in voice-based interactions, there are no visuals to act as signposts and provide reminders about where we are and what we’re doing. This is why it is critical to break complicated tasks down into simpler ones and eliminate excess noise (like non-required fields). We can also reduce cognitive load by chunking search results and other list-type content into small groups, asking the user if they want more before loading and presenting them.</p>

<blockquote>
  <p>The top seller in the garden department is Repel Lemon Eucalyptus Natural Insect Repellent, 4-Ounce Pump Spray</p>
</blockquote>

<blockquote>
  <p>Would you like to hear the rest?</p>
</blockquote>

<hr />

<p>As human beings, we all have special needs, but as designers and developers, it can sometimes be difficult to diagnose potential issues within our products when it comes to accessibility. Especially if we don’t typically experience that need or are unfamiliar with the tools used to address it.</p>

<p>To that end, my colleagues have been hard at work to make it easier to enhance the accessibility of our products. The first tool I want to discuss is the F12 developer tools in Edge.</p>

<p>As Andy Sterland mentioned in his talk, in a forthcoming release of F12, the inspector will surface accessibility information about each node in the DOM. Let’s take a look at an example:</p>

<p>{% youtube Z0PSK4IUAVM %}</p>

<p>Here we have the forthcoming redesign of <a href="http://html5accessibility.com/">HTML5accessibility.com</a> and if I inspect the section containing the test results, I can see information about that section element. On the right hand side, you’ll notice an inspector tab dedicated to accessibility information such as the node’s accessible name, it’s role, whether it’s keyboard focusable, ARIA properties assigned to it (in this case, <code>aria-label</code>), and so on.</p>

<p>Adding this functionality into F12 lifts the veil from the way Edge exposes the DOM to assistive technology and will go a long way toward helping us fine tune our experiences for <abbr aria-label="assistive technology">AT</abbr>, including screen readers and virtual assistants.</p>

<p>Another area where we are doing some work is within Narrator itself. When testing with screen readers, it can be quite tempting as a sighted user, to leave your screen on so you can follow along. Sadly, that action directly prohibits you from experiencing a site or application the way folks with visual impairments or in a headless UI scenario do. It can cause you to miss things or assume something makes sense when, in fact, it doesn’t.</p>

<p>To help address that, Narrator will soon sport a “Developer Mode” that enables you to blank out a single app (such as the Edge browser window) so you can experience it without any visual access to the UI. (You can also use it for installed and hosted apps.)</p>

<p>{% youtube lJ-4AVxAIsc %}</p>

<p>Here we see the HTML5accessibility site again. If I flip on Developer Mode in Narrator, the Edge browser window goes black and I can see where the focus carat moves (the blue box), but I can’t see the design. For diagnostic purposes, the contents being read by Narrator are also presented as text on the screen in the position of the element (which can help with identifying where the issue was when you come back out of Developer Mode).</p>

<p>Microsoft is committed to improving the accessibility, not only of its own products, but of the Web as a whole. These two tools are only a few of the many ways we are doing that today.</p>

<p>Obviously, part of that is continuing to evolve and improve the accessibility of the Web for users browsing in Edge, whether they are using Narrator or other screen readers like Jaws or NVDA.</p>

<p>But, in addition to that, Microsoft—in partnership with Carnegie Mellon and Stanford, Adobe, AT&amp;T, Dropbox, Facebook, Intuit, LinkedIn, and Yahoo—helped launch <a href="http://teachaccess.org/">TeachAccess</a>. This site is an effort to address the “lack of awareness and understanding of basic accessibility issues, concepts and best practices” in the world of <abbr aria-label="computer science">CS</abbr> and <abbr aria-label="human-computer interaction">HCI</abbr> education. If successful, which I sincerely hope it is, it will help address the dire need we have for a more accessibility-aware workforce building for the Web.</p>

<p>Similarly, <a href="https://www.microsoft.com/design">Microsoft Design</a> has shared <a href="https://www.microsoft.com/design/practice">their fantastic set of resources for improving the inclusiveness of design</a>. They have created a guide as well as a set of activities you can use to get your team into the <a href="http://www.inclusivedesigntoolkit.com/betterdesign2/whatis/whatis.html">Inclusive Design</a> mindset.</p>

<p>And in the not too distant future, we’ll be publishing a series of in-depth posts about accessibility on the <a href="https://blogs.windows.com/msedgedev/">Microsoft Edge Dev Blog</a>. These will tackle topics like how we re-architected Edge for better ARIA support and name computation, working with HTML5 accessibility to improve the tests, and how we can enable automated testing in order to discover accessibility regressions before they make it into production.</p>

<p>We do this because, with accessibility in mind, we can improve the lives of billions of people. Friends, family, neighbors, and complete strangers, all of whom deserve the opportunity to access the products we create regardless of the different ways we experience the world.</p>

<p>Ultimately “accessibility” is not about disabilities or the technologies we use to address them, <strong>it’s about people</strong>. Sure, we’ll make it easier to look up movie times and purchase tickets to see the latest Transformers debacle, but we’ll also empower the nearly 900 million people globally—over 60% of whom are female—that are illiterate by enabling our sites to be used purely via voice, even translated in real-time into their native language and dialect.</p>

<p>We will create new opportunities for the poor and disadvantaged to participate in a world that has largely excluded them. You may not be aware, but 80% of Fortune 500 companies—think Target, Walmart—only accept job applications online or via computers.</p>

<p>We will enable people who have limited computer skills or who struggle with reading to apply for jobs with these companies.</p>

<p>We will empower immigrants to read lease agreements and postal mail in languages they haven’t fully grasped yet.</p>

<p>We will enable people with visual disabilities to vote, even on paper ballots, without human assistance.</p>

<p>We can help bridge the digital divide and the literacy gap. We can create opportunities for people to better their lives and the lives of their families. We have the power to create more equity in this world than most of us have ever dreamed.</p>

<p>This is an incredibly exciting time, not just for accessibility, not just for user experience, not just the Web, but for the world! I can’t wait to see how awesome you make it!</p>

<p>Thank you!</p>

<hr />

<p><em>You can watch (or listen) to me present this talk (albeit with a bit of technical difficulty) <a href="https://channel9.msdn.com/Events/WebPlatformSummit/edgesummit2016/ES1612">over on the Channel 9 website.</a></em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Learn From the Past, Enhance for the Future]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/learn-from-the-past-enhance-for-the-future/"/>
    <updated>2016-03-04T17:33:57-05:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/learn-from-the-past-enhance-for-the-future</id>
    <content type="html"><![CDATA[<p><em>I had the great pleasure of delivering the closing keynote for the first EnhanceConf. I wanted to talk about voice and the future of “headless” user interfaces. Here’s what I had to say.</em></p>

<!-- more -->

<hr />

<p>Early last year, <a href="/notebook/how-to-apply-progressive-enhancement-when-javascript-seems-like-a-requirement/">a cry for help on Stack Overflow drew my attention</a>:</p>

<blockquote>
  <p>I’ve been trying to make my site … work fully without JavaScript, however, I’ve found myself in situations where I can’t honestly think how I would do some features without it.</p>
</blockquote>

<p>The submitter, JamHam, is certainly not alone in feeling this way. The ways we build websites change all the time. When I started out, it was pretty simple: you had HTML. Lots and lots of HTML. We also had Java applets, then Shockwave and Flash. Then we got some very basic stylesheet support. Then JavaScript.</p>

<p>As the years pressed on, the three major technologies underpinning the Web—HTML, CSS, and JavaScript—evolved and became even more powerful.</p>

<p>Things coalesced for a while in the early oughts before Jesse James Garrett re-christened a relatively obscure Microsoft creation, <code>XMLHttpRequest</code>, “AJAX” and set countless designers hearts aflutter with the promise of banishing the page refresh. At the heart of this revolution was JavaScript, and companies began betting their entire Web presence on its availability. Most learned that wasn’t such a good idea and began using it as an enhancement to the experience rather than a requirement.</p>

<p>After Ajax, there was HTML5, CSS3, and a host of new JavaScript APIs… the JavaScript frameworks—Angular, Knockout, Backbone, Ember, React… The ways we can create Web products just keep changing; sometimes slowly, but more often than not at such a speedy clip it leaves my head spinning.</p>

<p>The one thing I’ve learned however, being an “old man” in Web terms, is that web design is cyclical, just like everything else. <strong>The challenges we face building web products today are not new challenges.</strong> Moreover, the lessons we learned building similar products in the “Web 1.0” days pay dividends today and will continue to do so in the future.</p>

<p>When I started out on the Web, I had a 28.8 <abbr aria-label="kilobits per second">kbit/s</abbr> modem, but still had to support users on 14.4 <abbr aria-label="kilobits per second">kbit/s</abbr> connections. That’s half the speed I was used to running at. That may have been 20 years ago, but the lessons I learned about streamlining my HTML, optimizing images, and minimizing downloads has helped me immeasurably when dealing with high-latency mobile networks and excruciatingly slow “broadband” connections.</p>

<p>(I’m looking at you, every hotel ever.)</p>

<p>When I started out on the Web, I had an 800x600 monitor, but still had to support 640x480 screen resolutions. I learned the importance of prioritizing content long before media queries and flexbox enabled us to adapt our layouts on the fly. And while our computer screens keep getting bigger, mobile devices and wearables present the very same challenges I was tackling with 640x480, but in even tighter confines.</p>

<figure id="figure-2016-03-04-01">
<img src="https://www.aaron-gustafson.com/i/posts/2016-03-04/01.gif" alt="Screen sizes changing over time." />
</figure>

<p>When I started out on the Web, there was no JavaScript. All calculations, data processing, and dynamic functionality had to be handled by the server. I learned how to process web forms in Perl, later trading in my CGI scripts for PHP, Ruby, and Python. And while the vast majority of our users today have JavaScript baked into their browsers, I still rely on server-side fallbacks because I recognize that we don’t control the execution environment on the open Web.</p>

<blockquote>
  <p>The Web is the most hostile software engineering environment imaginable.<br />— Douglas Crockford</p>
</blockquote>

<p>You’re a savvy bunch, so I’m sure none of this is news to you, but I wanted to set the stage for what I’m really here to talk about. There’s a new cycle about to hit us and chances are you might not be thinking about it yet: Voice.</p>

<h2 id="i-the-headless-ui">I: The Headless UI</h2>

<p>Science fiction has often been a strong predictor of our technological future. HAL 9000 from <em>2001: A Space Odyssey</em> is probably the most (in)famous example of a computer that interacts with its users largely via voice. As a concept, the “talking computer” has appeared time and time again in space-age fiction—everything from <em>Red Dwarf</em> to <em>Interstellar</em>.</p>

<p>To function in the real world like they do on TV and in the movies, computers need two capabilities: Natural language processing (to understand what we say) and speech synthesis (to communicate, aurally, back to us).</p>

<figure id="figure-2016-03-04-02">
<img src="https://www.aaron-gustafson.com/i/posts/2016-03-04/02.gif" alt="Visual of a human and a computer conversing." />
</figure>

<p>Natural language processing has its roots in the 1950s, but many of these early speech models were limited because they were built around a series of hard-coded rules that the computers followed. In the 1980s, however, machine learning and real-time statistical analysis became possible.</p>

<p>As hardware capabilities continued to improve and computers became more powerful, they got better at recognizing the words we were saying to them. Eventually, and with enough processing power, they also began to assign meaning to words and could react accordingly.</p>

<p>As the years marched on, the overhead required to enable our projects to listen to our users has dropped significantly.</p>

<p>Listening is great, but true communication is bidirectional. Humans have been experimenting with speech synthesis since the late 1700s, but it wasn’t until the 1980s that we got a decent result though. By the 1990s, reasonably intelligible text-to-speech software was being rolled out alongside most operating systems as a core component of their assistive technology offerings: The “screen reader”. At present, screen readers are probably the best indicator of what the future of voice interaction will sound like.</p>

<p>When combined, the ability of a computer to listen and respond gave rise to virtual personal assistants like Siri, Cortana, Alexa, and more.</p>

<p>Over time, our customers will become more accustomed to and reliant on voice-based interactions with their computers and the Web. Enabling them to complete critical tasks without a visual user interface will be crucial for the long-term success of our Web-based products.</p>

<p>So how do you design a “headless” UI? That’s easy: You design the conversation.</p>

<h2 id="ii-interface-is-conversation">II: Interface is Conversation</h2>

<p>Let’s take a trip back in time to one of the earliest computer games: Zork. Zork was written between 1977 and 1979. It’s a text-based adventure game that operates a lot like a game of <em>Dungeons &amp; Dragons</em>—with the program serving the role of gamemaster.</p>

<blockquote>
  <p>West of House<br /> You are standing in an open field west of a white house, with a boarded front door.<br /> There is a small mailbox here.<br /><br />&gt; <strong>open mailbox</strong></p>
</blockquote>

<p>As you move from location to location throughout the game, the program describes the environment and notes objects and people you can interact with. You type what you want to do and the program tells you the results of your actions.</p>

<p>As this was the early days of computer gaming, you might think Zork’s interactions would be simple noun-verb combinations—”kill troll”—but Zork was more sophisticated than that. Its parser was could understand far more complex commands like “hit the troll with the Elvish sword”. This made the experience far more natural, as if you were playing a table top game with friends.</p>

<p>Whether Zork or a webpage, <strong>every interface is a conversation</strong>—we engage our users directly in an effort to inform them, entertain them, or persuade them to act in a particular way. How this conversation goes directly affects the experience our users have.</p>

<p>Let’s look at a few web page and interface component types to identify the kinds of conversations we trying to have with our users in each:</p>

<ul>
  <li><strong>Homepage</strong><br /> We’ve just met and I’m explaining what you can do on my site (and, in some cases, why it matters).</li>
  <li><strong>Contact Form</strong><br /> You’re asking or telling me something. I want to help you. It’s common courtesy for me to let you know how long it may take me to get back to you with a response; and for me to abide by that.</li>
  <li><strong>Product Page</strong><br /> I’m explaining what a particular object or service is, what it does, and how it will benefit you. I should “show” you why something is great rather than “tell”-ing you that it is because you’re immune to salesy <abbr aria-label="bullshit">BS</abbr>.</li>
  <li><strong>Status Update</strong><br /> I may prompt you with a question, but I’m here to listen. The floor is yours. (But I’m probably mining what you say for data so I can market to you later.)</li>
</ul>

<p>When we approach interfaces as conversations, we humanize our products and improve our users’ experiences. When we don’t, things can fall apart quickly…</p>

<p>Over the 2011 holidays, Facebook users were uploading photos like crazy. In the span of a few days, Facebook processed more photo uploads than are contained in the entirety of Flickr. Seriously, that’s a lot of photos.</p>

<p>One unintended consequence of this deluge of photo uploads was a significant uptick in people asking Facebook to remove specific ones. Facebook received millions of these “photo reports”, but they made no sense: Moms holding babies reported for harassment, pictures of puppies reported for hate speech, and so on. Roughly 97% of these photo reports were dramatically mis-categorized.</p>

<p>Facebook’s engineers reached out to some of the users who had reported these photos to get a bit more background regarding their submissions. At the time Facebook’s photo reporting interface provided a list of reasons users could choose from if they wanted a photo removed, but, as Facebook soon discovered, many of the reports were made because users didn’t want the photo posted for reasons other than those provided. In some cases, it was because they didn’t like how they looked in the photo. In others, it was because the photo was of an ex-partner or even a beloved pet they’d shared with an ex-boyfriend or ex-girlfriend.</p>

<p>The existing photo reporting tool had not done a good job of accounting for these more personal reasons for wanting a photo removed, so the Facebook engineers went to work. They added a step that asked <em>How does this photo make you feel?</em> The options were simple:</p>

<ul>
  <li>Embarrassing</li>
  <li>Upsetting</li>
  <li>Saddening</li>
  <li>Bad Photo</li>
  <li>Other</li>
</ul>

<p>The “other” option also provided a free-response text field to fill in.</p>

<p>With this system in place, they found that 50% of reporters who answered the new question chose one of the provided options. That was pretty helpful, but there was still a problem: 34% of the “other” respondents were writing “It’s embarrassing” in the blank rather than choosing the “embarrassing” option already provided.</p>

<p>What the Facebook team realized was that people were not identifying with the “embarrassing” text (or may have even thought it was referring to them, rather than assuming an implied “It’s”). A subtle shift in language was needed, so they changed the label to <em>Please describe the photo</em> and they updated the options to mirror how people actually talk:</p>

<ul>
  <li>It’s embarrassing</li>
  <li>It’s a bad photo of me</li>
  <li>It makes me sad</li>
</ul>

<p>With this subtle change, they were able to increase the percentage of photo reporters who chose one of the options provided to a whopping 78%.</p>

<p>Words matter. Even in something as simple and banal as a form, the words we choose set the tone for our users’ experiences and often have an affect on what they do… or fail to do.</p>

<p>The text of our interfaces—especially form labels and responses—is just one small part of the content picture, but it’s a perfect example of how easy it can be to overlook conversation in our interfaces. There are many other types of content like product descriptions, marketing copy, legal statements, visualizations, video, audio, and more. Content is where experience begins. It’s the core that we seek to progressively enhance. It’s also the foundation upon which the voice-based experiences of the future will be based.</p>

<p>The more time and consideration we put into how our interfaces read, the better-positioned we will be to succeed in the future of headless UIs. Once stripped of its beautifully-crafted, responsive layout, engaging animations, and artful illustrations, does your site hold up?</p>

<hr />

<p>Back in 2006, <a href="http://www.dustindiaz.com/naked-day/">Dustin Diaz proposed CSS Naked Day</a>—a day when sites could be stripped of their visual design to showcase their content, semantics, and organization.</p>

<blockquote>
  <p>It will be a test case to see how usable your website is to others without a “design”.<br /> —Dustin Diaz</p>
</blockquote>

<p>“Design”, as Dustin was refering to it, is the visual design of a site, but design is not solely concerned with visual representations. Diving into etymology for a moment here, <em>design</em> comes from the Latin <i lang="la">designare</i> meaning “to mark out or indicate”. The purpose of design is not to make something pretty, it’s to clarify.</p>

<p>If the words we use form the basis of the conversations we have with our users, the semantics we employ clarify that meaning. Choosing elements with semantic value enriches our content, illuminating the meaning and intent of our words in order to overcome the limitations of text and bring it up to par with spoken language. After all, they may look the same visually, but there’s a big difference between these two statements:</p>

<p>{% gist 6f5b7c0f0c072631a908 different-meanings.html %}</p>

<p>Beyond using markup to clarify the intent of the words we write, we can use it to spell out relationships that are often represented visually. Dustin described one way we do this as part of the impetus for CSS Naked Day (emphasis mine):</p>

<blockquote>
  <p>In the spirit of promoting Web Standards along with good semantic markup and <em>proper hierarchy structures</em></p>
</blockquote>

<p>By “proper hierarchy”, Dustin is talking about the document outline. A document outline is created through use of heading elements (<code>h1</code>–<code>h6</code>). It provides a easy way to review the organization of our web pages and validate our source order decisions. It also helps us ensure the flow works, which is incredibly important in any conversation. It helps us get to the point, streamline our content, and remove distractions… all of which are a sign of respect to our users.</p>

<p>None of this is news, of course, content strategists have been recommending that we streamline our content since the dawn of the Web. Sadly, many folks didn’t heed that advice until they were forced to confront the often infuriating world of mobile. Smaller screens required focused content.</p>

<p>When Luke Wroblewski coined “mobile first”, he told us to focus on the core purpose each and every page. He was, in essence, telling us to focus on the conversation we are having with our users. This approach pays huge dividends on small screens, but when it comes to voice-based interactions, “the page” doesn’t really exist. Experience is the sum of each individual interaction. As part of their <a href="https://developer.amazon.com/public/solutions/alexa/alexa-skills-kit">Alexa Skills Kit</a>, <a href="https://developer.amazon.com/public/solutions/alexa/alexa-skills-kit/docs/alexa-skills-kit-voice-design-best-practices">Amazon offers a ton of recommendations for designing for voice</a>, many of which happen to be equally useful for sighted users.</p>

<h3 id="write-for-people">Write for People</h3>

<p>We don’t author content for ourselves. We write for others. If what we write frustrated or alienates our users, we’ve failed at our job. In their profoundly helpful book <a href="http://www.amazon.com/gp/product/0321988191/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0321988191&amp;linkCode=as2&amp;tag=easydesign-20&amp;linkId=5INOUNG72ODCWZQV"><cite>Nicely Said</cite></a>, Nicole Fenton and Kate Kiefer Lee offer numerous suggestions for how to write with the reader in mind:</p>

<blockquote>
  <ul>
    <li>Be clear.</li>
    <li>Be concise.</li>
    <li>Be honest.</li>
    <li>Be considerate.</li>
    <li>Write how you speak.</li>
  </ul>
</blockquote>

<p>They also make the recommendation that you read your work aloud. As we head into the world of voice-based interactions, that’s beta testing!</p>

<h3 id="avoid-technical-and-legal-jargon">Avoid Technical and Legal Jargon</h3>

<p>When we are writing for our readers, we need to be familiar with their level of domain knowledge so we don’t frustrate or alienate them. For example, if you track error codes for issues on your site, send them to <em>your developers</em>, but never present them to a user.</p>

<figure id="figure-2016-03-04-03">
{% adaptive_image /i/posts/2016-03-04/03.png %}
</figure>

<p>Similarly, we should avoid legalese and write in plain language. Medium has done a great job of this with <a href="https://medium.com/policy/medium-terms-of-service-9db0094a1e0f#.mgexdk816">their Terms of Service</a>.</p>

<figure id="figure-2016-03-04-04">
{% adaptive_image /i/posts/2016-03-04/04.png %}
</figure>

<h3 id="when-requesting-feedback-make-it-clear-that-the-user-needs-to-respond"><strong>When Requesting Feedback, Make It Clear that the User Needs to Respond</strong></h3>

<p>In perhaps the most common form example, consider the label “First Name”. It’s not terribly conversational and doesn’t beg for a response. Labels like “What is your first name?” make it clear the user should respond.</p>

<p>{% gist 6f5b7c0f0c072631a908 better-labels.html %}</p>

<figure id="figure-2016-03-04-05">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.mp3" type="audio/mpeg;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<p>Similarly, when there’s an error, notify them of the error and, if possible, give them some clues on how to fix it.</p>

<p>{% gist 6f5b7c0f0c072631a908 field-error.html %}</p>

<figure id="figure-2016-03-04-06">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.mp3" type="audio/mpeg; codecs=&quot;mp3&quot;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<h3 id="when-asking-a-user-to-choose-clearly-present-the-options"><strong>When Asking a User to Choose, Clearly Present the Options</strong></h3>

<p>This comes into play often when dealing with forms. Ensuring radio and checkbox controls are properly associated with their labels is critical.</p>

<p>{% gist 6f5b7c0f0c072631a908 radio-label.html %}</p>

<p>You can also use the <code>fieldset</code> and <code>legend</code> elements to group the related controls, but be sure to make the <code>legend</code> focusable or associate it with the first focusable form control in order to ensure the question is read out.</p>

<p>{% gist 6f5b7c0f0c072631a908 fieldset.html %}</p>

<figure id="figure-2016-03-04-07">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.mp3" type="audio/mpeg; codecs=&quot;mp3&quot;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<p>We should strive for the same sort of clarity when presenting navigation options. The HTML5 <code>nav</code> element enables us to semantically identify an area of the page being used for navigation. It does not, however, identify the <code>nav</code> element as being for navigation when encountered naturally in the flow of the document. For that reason, it can be useful to provide an textual introduction to the section, even if you choose to visibly hide it. You might even consider expanding the text of your navigation items to provide additional context.</p>

<p>{% gist 6f5b7c0f0c072631a908 navigation.html %}</p>

<figure id="figure-2016-03-04-08">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.mp3" type="audio/mpeg; codecs=&quot;mp3&quot;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<h3 id="prompts-should-be-short-while-still-being-clear">Prompts Should be Short, While Still Being Clear.</h3>

<p>In <a href="https://www.stmarys-ca.edu/sites/default/files/attachments/files/On_The_Method_of_Theoretical_Physics.pdf">a 1933 lecture at Oxford</a>, Albert Einstein famously said</p>

<blockquote>
  <p>It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience.</p>
</blockquote>

<p>Or, as <a href="https://books.google.com/books?id=prDfAFjet9cC&amp;lpg=PR7&amp;ots=PA9rRog4cr&amp;dq=How%20a%20%E2%80%98Difficult%E2%80%99%20Composer%20Gets%20That%20Way&amp;pg=PA230#v=onepage&amp;q&amp;f=false">Roger Sessions paraphrased it</a></p>

<blockquote>
  <p>Everything should be as simple as it can be but not simpler.</p>
</blockquote>

<p>Clear and concise writing is the hallmark of great content. We need to resist the urge to write for writing’s sake. We write in the service our audience, not for ourselves.</p>

<p>Government websites are some of the worst offenders in this area. Consider this lovely passage:</p>

<blockquote>
  <p>Heavy rains throughout most of the State have given an optimistic outlook for lessened fire danger for the rest of the season. However, an abundance of lightning maintains a certain amount of hazard in isolated areas that have not received an excessive amount of rain.</p>
</blockquote>

<p>It could be written far more clearly as</p>

<blockquote>
  <p>Heavy rains throughout most of the State have lessened fire danger for the rest of the season. However, lightning threatens isolated dry areas.</p>
</blockquote>

<p>Here in the UK, the Government Digital Service has made great strides overhauling excruciatingly painful content and making it easier to read and understand. One such example is <a href="https://gds.blog.gov.uk/2014/07/28/doing-the-hard-work-to-make-things-simple/">their overhaul of the Accelerated Possession process</a> that allows landlords to evict a tenant.</p>

<p>The original paper form asked for the address like this</p>

<blockquote>
  <p>The claimant seeks an order that the defendant(s) give possession of:<br /> (If the premises of which you seek possession are part of a building identify the part eg. Flat 3, Rooms 6 and 7)</p>
</blockquote>

<p>Before requesting the type of property concerned</p>

<blockquote>
  <p>(‘the premises’) which is<br /> ☐ a dwelling house<br /> ☐ part of a dwellinghouse</p>
</blockquote>

<figure id="figure-2016-03-04-09">
{% adaptive_image /i/posts/2016-03-04/09.png %}
</figure>

<p>Clear and to the point, right?</p>

<p>The GDS went to work and streamlined the process in plain language:</p>

<blockquote>
  <p>What kind of property do you want to take back?<br /> ◎ A self-contained house, flat or bedsit<br /> ◎ Room or rooms in a property.<br /> Tenants may share kitchen or bathroom</p>
</blockquote>

<p>Then they allow you to lookup the property or manually enter the address.</p>

<figure id="figure-2016-03-04-10">
{% adaptive_image /i/posts/2016-03-04/10.png %}
</figure>

<p>While not specifically designed for the future of headless UIs, this form is prepared for their eventuality.</p>

<h3 id="ask-only-necessary-questions">Ask Only Necessary Questions</h3>

<p>We show our users respect by respecting their time. Obviously straightforward, brief writing is one way we do that, but another is to reduce the time it takes to complete a task. Many forms are brimming with fields to be filled in. In some cases, the vast majority are purely optional. And while it may be easy to spot the required fields visually, bypassing them in an aural interface can be incredibly difficult.</p>

<figure id="figure-2016-03-04-11">
{% adaptive_image /i/posts/2016-03-04/11.jpg %}
</figure>

<p>User experience designers have been pushing for simplified forms since… well, as long as I can remember. Users appreciate them, they tend to result in better data, and they also tend to convert better than long forms. And when it comes to voice-based interactions, they will become a necessity. No one is going to want to spend 15 minutes working their way through a 15 question registration form when all that’s required is their email address and for them to choose a password.</p>

<figure id="figure-2016-03-04-12">
{% adaptive_image /i/posts/2016-03-04/12.jpg %}
</figure>

<p>On a similar note, we should avoid slicing fields into multiple parts if at all possible. For instance, you still see fields like this one, asking for a US phone number, quite often:</p>

<figure id="figure-2016-03-04-13">
{% adaptive_image /i/posts/2016-03-04/13.png %}
</figure>

<p>When interacting with this construct via voice, a user will be required to supply three separate values. In order to do so, each field would require a label. Even in the States, most developers would only know how to label the first of those three boxes. (They are area code, exchange or central office code, and line number, if you’re interested.)</p>

<p>HTML5 introduced a host of new field types that consolidate phone numbers, dates, times, and other complex data types into single fields. Use them! As an added bonus, most enforce content validation and formatting rules for you automatically.</p>

<h3 id="present-information-in-consumable-pieces">Present Information in Consumable Pieces</h3>

<p>Like computers, we humans have a finite amount of “working memory”. The amount of mental resources required to operate an interface is called its “cognitive load”. When the amount of information we need to process exceeds our capacity to handle it, we can miss important details, have trouble concentrating, and become frustrated.</p>

<p>We deal with cognitive load in GUI design all the time, but in voice-based interactions, there are no visuals to act as signposts and provide reminders about where we are and what we’re doing. This is why it is critical to break complicated tasks down into simpler ones and eliminate excess noise (like non-required fields). We can also reduce cognitive load by chunking search results and other list-type content into small groups, asking the user if they want more before loading and presenting them.</p>

<blockquote>
  <p>The top seller in the garden department is Repel Lemon Eucalyptus Natural Insect Repellent, 4-Ounce Pump Spray</p>
</blockquote>

<blockquote>
  <p>Would you like to hear the rest?</p>
</blockquote>

<h2 id="iii-future-enhancements">III: Future Enhancements</h2>

<p>Paying attention to how our interfaces read is critical to success in the future of voice-based interactions. Thankfully, we already view content as the centerpiece of every progressively enhanced experience. But we can go further.</p>

<p>Both Microsoft and Amazon have given us the tools to voice-enable our websites beyond the HTML we present. Amazon has chosen to do this via a dedicated JSON API, through which we can “teach” Alexa “skills”. Using this API, you can enable your users to access core site functionality through the Echo, FireTV, or any other device that has integrated the Alexa Voice Service.</p>

<p>Microsoft has taken a slightly different approach. Using a relatively simple XML format, they have enabled us to teach Cortana new commands that tie directly into our website.</p>

<p>{% gist 6f5b7c0f0c072631a908 meta.html %}</p>

<p>All we need to do is include a <code>meta</code> tag pointing to an XML file that details the commands (and variations) and, when a user installs the site as a hosted app, Cortana picks up the new commands automatically. Those commands, when issued, can open a specific page or even kick off JavaScript methods in the target page.</p>

<p>{% gist 6f5b7c0f0c072631a908 vcd.xml %}</p>

<hr />

<p>We are just starting to scratch the surface of what’s possible in voice-enabling the Web, but it’s exciting to see how some companies are addressing this opportunity. It’s always interesting when things come full circle and we see how lessons we learned early on in the Web remain applicable, not matter how much or quickly things seem to change. Seeing this pattern repeat time and time again is why I’m so drawn to the philosophy of progressive enhancement; it’s not only concerned with supporting the past… it’s setting us up for success in the future.</p>
]]></content>
  </entry>
  
</feed>
