<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Browse by Tag: Web Design | Aaron Gustafson]]></title>
  <link href="https://www.aaron-gustafson.com/notebook/tags/web-design/atom.xml" rel="self"/>
  <link href="https://www.aaron-gustafson.com/"/>
  <updated>2016-11-10T00:23:23-05:00</updated>
  <id>https://www.aaron-gustafson.com/</id>
  <author>
    <name><![CDATA[Aaron Gustafson]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[One Person’s Bloat…]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/one-persons-bloat-dot-dot-dot/"/>
    <updated>2016-10-25T15:15:01-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/one-persons-bloat-dot-dot-dot</id>
    <content type="html"><![CDATA[<figure id="fig-2016-10-25-1" class="media-container"><img  src="https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-10-25/webbloatscore.png&amp;resize_w=320&amp;container=focus&amp;refresh=2592000 320w" srcset="https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-10-25/webbloatscore.png&amp;resize_w=1920&amp;container=focus&amp;refresh=2592000 1920w,https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-10-25/webbloatscore.png&amp;resize_w=600&amp;container=focus&amp;refresh=2592000 600w,https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-10-25/webbloatscore.png&amp;resize_w=320&amp;container=focus&amp;refresh=2592000 320w" sizes="100vw" alt=""></figure>

<p>The <a href="http://www.webbloatscore.com/">Web Bloat Score Calculator</a> has been making the rounds on Twitter and I wanted to share my immediate thoughts on it.</p>

<!-- more -->

<p>First off, I am a big fan of simple tools that provide an often much-needed reality check on a project. Based squarely on its simplicity, I’d put this tool right up there alongside <a href="https://www.webpagetest.org/">WebPageTest</a> and <a href="https://whatdoesmysitecost.com/">What Does My Site Cost?</a>. The Web Bloat Score (or WebBS… clever) Calculator is about as simple an interface as you can get: Enter a URL &amp; hit the “Calculate” button.</p>

<p>When you do this, the service runs two tasks:</p>

<ol>
  <li>Load the URL and all of its assets, calculating a total page weight and chronicling the number of requests required to get there; and</li>
  <li>Generate a static screen capture of the page and then grab its file size.</li>
</ol>

<p>Once it has these two bits of info, it compares the real file size of the tested page against the image version to come up with your WebBS.</p>

<p>I <a href="http://www.webbloatscore.com">ran the calculator against the 10k Apart contest homepage</a> and here are the results:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">URL</th>
      <th style="text-align: left">Page Size</th>
      <th style="text-align: left">Requests</th>
      <th style="text-align: left">Image Size</th>
      <th style="text-align: left">WebBS</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">https://a-k-apart.com/</td>
      <td style="text-align: left">200 <abbr title="kilobytes">kB</abbr></td>
      <td style="text-align: left">49</td>
      <td style="text-align: left">195 <abbr title="kilobytes">kB</abbr></td>
      <td style="text-align: left">1.03</td>
    </tr>
  </tbody>
</table>

<p>Not too bad, considering <a href="http://www.webbloatscore.com/Details/612ea9a9-c548-4e20-99d1-910b449ba2c4">the number of images on the page</a> and the interactivity of the SVG. In the documentation about the tool, they have this to say about a high WebBS:</p>

<blockquote>
  <p>A high WebBS usually indicates unused stuff on the page: JavaScript, CSS, oversized images, etc. Maybe you have a valid reason for that content. But more often than not, it means you can optimize it more.</p>
</blockquote>

<p>I completely agree with the sentiment here: smaller is better and if there’s a huge discrepancy between the file size of an image of your page and the page itself, there <em>may</em> be something not so awesome going on behind the scenes. They reference Amazon as being particularly bad, with a WebBS of 20 (<a href="http://www.webbloatscore.com/Details/4abea720-677c-48f6-9ff2-2b816424be06">I got 12.3 in my test</a>, but Amazon frequently changes their homepage).</p>

<p>There’s always room for improvement when it comes to optimization, but I also worry about folks getting too hung up on numbers like this, especially striving for a score of 1 or less. Here are a few legitimate reasons your score may be more than 1:</p>

<ul>
  <li><strong>Your page is heavily interactive.</strong> The calculator does not take into account any sort of interactivity—progressively enhanced or not—nor does it tell you how well-optimized your JavaScript code is. There’s also the possibility that you’ve consciously decided to trade verbosity for speed. For large loops, for instance, <a href="https://en.wikipedia.org/wiki/Duff%27s_device">Duff’s device</a> is much faster but a lot more verbose than a normal <code>for</code> loop.</li>
  <li><strong>Your page serves alternate file formats.</strong> The tool runs <a href="http://slimerjs.org/">SlimerJS</a> to collect the performance data and, for instance, it doesn’t currently support WebP images. We serve WebP with a JPG or PNG fallback on the 10k Apart site (using <code>picture</code>), but <a href="http://www.webbloatscore.com/Details/612ea9a9-c548-4e20-99d1-910b449ba2c4">the file log</a> doesn’t include the WebP images at all.</li>
  <li><strong>You make use of micro-optimizations.</strong> Perhaps you use <a href="https://github.com/filamentgroup/loadCSS"><code>loadCSS</code></a> or <a href="https://github.com/filamentgroup/loadJS"><code>loadJS</code></a> or split your CSS into a default and advanced stylesheet (with the advanced one only loading if media queries are supported). Perhaps you lazy load images or fonts via JavaScript. Perhaps you only load certain assets or scripts based on browser capabilities. The calculator takes none of this into account.</li>
</ul>

<p>These are just three reasons to take your WebBS with a grain of salt. It’s good for a gut-check, but I wouldn’t spend a whole lot of time worrying about getting your score at or below 1.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Progressive Misconceptions]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/progressive-misconceptions/"/>
    <updated>2016-10-17T15:33:55-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/progressive-misconceptions</id>
    <content type="html"><![CDATA[<p>Last week, my colleague<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup> <a href="https://nolanlawson.com/">Nolan Lawson</a> wrote <a href="https://nolanlawson.com/2016/10/13/progressive-enhancement-isnt-dead-but-it-smells-funny/">a lengthy post about his struggles with progressive enhancement</a>. In it, he identified a key tension between the JavaScript community and the progressive enhancement community that has, frankly, existed since the term “progressive enhancement” was coined some 13 years ago. I wanted to take a few minutes to tuck into that tension and assure Nolan and other folks within the JS community that neither progressive enhancement nor the folks who advocate it (like me) is at odds with them or their work.</p>

<!-- more -->

<p>But first let’s take a a trip back in time to 2003. In March of that year, <a href="http://hesketh.com/publications/inclusive_web_design_for_the_future.html">Steve Champion introduced a concept he called “progressive enhancement”</a>. It caused a bit of an upheaval at the time because it challenged the dominant philosophy of graceful degradation. Just so we’re all on the same page, I’ll compare these two philosophies.</p>

<h2 id="whats-graceful-degradation">What’s graceful degradation?</h2>

<p><em>Graceful degradation</em> assumes that an experience is going to be worse on older, less capable browsers and devices. To address potential problems, it recommends that developers take steps to avoid throwing errors—JavaScript or otherwise—for their users. Under this philosophy, a developer can take a range of approaches ranging from making everything work perfectly in down-level browsers to only addressing egregious errors or even chosing to block certain browsers from accessing the content if they are known to have problems. We saw this latter approach often with Flash-only sites, but it wasn’t limited to them. I used <a href="#2016-10-17-1">this “roadblock” example from Kodak.com</a> in <a href="http://adaptivewebdesign.info/">my book</a>:</p>

<figure id="fig-2016-10-17-1" class="media-container"><img  src="https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-10-17/kodak-roadblock.png&amp;resize_w=320&amp;container=focus&amp;refresh=2592000 320w" srcset="https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-10-17/kodak-roadblock.png&amp;resize_w=1920&amp;container=focus&amp;refresh=2592000 1920w,https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-10-17/kodak-roadblock.png&amp;resize_w=600&amp;container=focus&amp;refresh=2592000 600w,https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-10-17/kodak-roadblock.png&amp;resize_w=320&amp;container=focus&amp;refresh=2592000 320w" sizes="100vw" alt=""></figure>

<p>Overall, graceful degradation is about risk avoidance. The problem was that it created a climate on the Web where we, as developers, got comfortable with the idea of denying access to services (e.g., people’s bank accounts) because we deemed a particular browser (or browsers) too difficult to work with. Or, in many cases, we just didn’t have the time or budget (or both) to address the broadest number of browsers. It’s kind of hard to reconcile the challenge of cross-browser development in 2003 with what we are faced with today as we were only really dealing with 2-3 browsers back then, but you need to remember that standards support was far worse at the time.</p>

<h2 id="so-whats-progressive-enhancement">So what’s progressive enhancement?</h2>

<p>In his talk, Steve upended the generally shared perspective that older browsers deserved a worse experience because they were less technically capable. He asked us to look beyond the browsers and the technologies in play and focus on the user experience, challenging us to design inclusive experiences that would work in the broadest of scenarios. He asked that we focus on the content and core tasks in a given interface and then enhance the experience when we could. We accomplish this by layering experiences on top of one another, hence “progressive enhancement”.</p>

<p>What’s particularly interesting about this approach is that it is still technically graceful degradation because all of the interfaces do gracefully fall back to a usable state. But it’s graceful degradation at its best, focused on delivering a good experience to everyone. No excuses.</p>

<p>To give a simple example, consider a form field for entering your email address. If we were to mark it up like this</p>

<pre><code>&lt;input type="email" name="email" id="email"&gt;
</code></pre>

<p>I automatically create layers of experience with no extra effort:</p>

<ol>
<li>Browsers that don’t understand “email” as a valid <code>input</code> type will treat the “email” text as a typo in my HTML (like when you type “rdio” instead of “radio”… or maybe I’m the only one that does that). As a result, they will fall back to the default input type of “text”, which is usable in every browser that supports HTML2 and up.</li>
<li>Browsers that consider “email” a valid <code>input</code> type will provide one (or more) of many potential enhanced experiences:
<ol type="a">
<li>In a virtual keyboard context, the browser may present a keyboard that is tailored toward quickly entering email addresses.</li>
<li>In a browser that supports auto-completion, it may use this as a cue to suggest entering a commonly-entered email or one that has been stored in the user’s profile.</li>
<li>In a browser that supports HTML5 validation, the browser may validate this field for proper email formatting when the user attempts to submit the form.</li>
<li>In a browser that does not support HTML5 validation or that doesn’t actively block submission on validation errors—<a href="https://bugs.webkit.org/show_bug.cgi?id=28649">like Safari</a>—a developer-supplied JavaScript program may use the <code>type</code> attribute as a signal that it should validate the field for proper email address formatting.</li>
</ol>
</li>
</ol>

<p>That means that there are between 5 and 13 potential experiences (given all of the different possible combinations of these layers) in this one single single element… it’s kind of mind-boggling to think about, right? And the clincher here is that any of these experiences can be a good experience. Heck for nearly 15 years of the Web, the plain-ol’ text <code>input</code> was the only way we had for entering an email address. Anything better than that is gravy.</p>

<p>Progressive enhancement embraces the idea of experience as a continuum rather than some singular ideal. It recognizes that every person is different and we all have special requirements for Web access. Some may depend on our browser, the device we’re on, and the network we are using. Others may be the result of a limitation we have dealt with since birth, are dealing with temporarily as the result of an injury or incident, or are simply a factor of our current situation. We all experience the world differently and progressive enhancement not only respects that, it embraces that variability.</p>

<p>How does it do this? Progressive enhancement takes advantage of the fault tolerant nature of HTML and CSS. It also uses JavaScript’s own ability to test for browser features to tailor programmatic enhancements to the given device and situation. That’s right: progressive enhancement and JavaScript go hand-in-hand.</p>

<h2 id="why-are-so-many-javascript-folks-hostile-to-progressive-enhancement">Why are so many JavaScript folks hostile to progressive enhancement?</h2>

<p>As a member of the JavaScript community for over a decade now, I have theory for why many JavaScript developers are so antagonistic toward progressive enhancement. Part of it has to do with history and part of it has to do with programming culture. Let’s tackle the history first.</p>

<p>When progressive enhancement was first proposed, the Web was getting more standardized, but things were still a bit of a mess… especially in the JavaScript world. Many JavaScript programs were poorly-written, contained lots of browser-specific code, and were generally unfriendly to anyone who fell outside of the relatively narrow band of “normal” Web use… like screen reader users, for example. It’s not surprising though: Graceful degradation was the name of the game at the time.</p>

<p>Because JavaScript programs were creating barriers for users who just wanted to read news articles, access public services, and check their bank accounts, many accessibility advocates recommended that these folks disable JavaScript in their browsers. By turning off JavaScript, the theory went, users would get clean and clear access to the content and tasks they were using the Web for. Of course that was in the days before Ajax, but I digress.</p>

<p>This recommendation served as a bit of a wake-up call for many JavaScript developers who had not considered alternate browsing experiences. Some chose to write it off and continued doing their own thing. Others, however, accepted the challenge of making JavaScript more friendly to the folks who relied on assistive technologies (AT). Many even went on to write code that actually improved the experience specifically for folks who are AT-dependent. Dojo and YUI, though sadly out of favor these days, were two massive libraries that prioritized accessibility. In fact, I’d go so far as to say they ushered in a period of alignment between JavaScript and accessibility.</p>

<p>Even though JavaScript and accessibility are no longer at odds (and really haven’t been for the better part of a decade), there are still some folks who believe they are. People routinely come across old articles that talk about JavaScript being inaccessible and they turn around and unfairly demonize JavaScript developers as unsympathetic toward folks who rely on screen readers or other AT. It’s no wonder that some JavaScript developers become immediately defensive when the subject of accessibility comes up… especially if it’s not something they’re all that familiar with.</p>

<hr />

<p>I also mentioned that programming culture plays a part in the antagonistic relationship between the progressive enhancement camp and the JavaScript community. If you’ve been a programmer for any amount of time, you’ve probably borne witness to the constant finger-pointing, belittling, and arrogance when it come to the languages we choose to program in or the tools we use to do it.</p>

<p>As a programmer, you receive a near constant barrage of commentary on your choices… often unsolicited. <em>You’re using PHP? That’s so 1996! You’re still using TextMate?! You still use jQuery? How quaint!</em> I’m not exactly sure where this all began, but it’s unhealthy and causes a lot of programmers to get immediately defensive when anyone challenges their language of choice or their process. And this hostile/defensive environment makes it very difficult to have a constructive conversation about best practices.</p>

<p>Progressive enhancement should not be viewed as a challenge to JavaScript any more than concepts like <a href="https://www.safaribooksonline.com/library/view/learning-javascript-design/9781449334840/ch13s15.html">namespacing</a>, <a href="https://en.wikipedia.org/wiki/Test-driven_development">test driven development</a>, or <a href="http://www.yottaa.com/company/blog/application-optimization/how-does-reducing-javascript-requests-minifying-javascript/">file concatenation &amp; minification</a> are; it’s just another way to improve your code. That said, progressive enhancement does introduce a wrinkle many for hardcore JavaScript programmers seem unwilling to concede: JavaScript is fragile. At least on the client side, JavaScript development requires far more diligence when it comes to error handling and fallbacks than traditional programming because, unlike with traditional software development, <a href="https://www.aaron-gustafson.com/notebook/a-fundamental-disconnect/">we don’t control the execution environment</a>.</p>

<p><a href="http://www.crockford.com/">Douglas Crockford</a> (in)famously declared the Web “the most hostile software engineering environment imaginable” and he wasn’t wrong. A lot of things have to go right for our code to reach our users precisely the way we intend. Here are just a few of these requirements:</p>

<ol>
  <li>Our code must be bug-free;</li>
  <li>Included 3rd party code must be bug free and must not interfere with our code;</li>
  <li>Intermediaries—ISPs, routers, etc.—must not inject code or if they do, it must be bug free and not interfere with our code;</li>
  <li>Browser plugins must not interfere with our code;</li>
  <li>The browser must support every language feature and API we want to use; and</li>
  <li>The device must have enough RAM and a fast enough processor to run our code.</li>
</ol>

<p>Some of these can be addressed by programming defensively using test-driven development, <a href="http://www.slideshare.net/simonguest/automated-web-testing-using-javascript">automated QA testing</a>, <a href="https://developer.mozilla.org/docs/Using_Web_Standards_in_your_Web_Pages/Developing_cross-browser_and_cross-platform_pages#Using_Object.2FFeature_support_detection_approach:_best_and_overall_most_reliable">feature detection</a>, and markup detection. These aren’t guaranteed to catch everything—markup can change after a test has run but before the rest of the code executed, <a href="http://javascriptissexy.com/javascript-objects-in-detail/">JavaScript objects are mutable</a> meaning features can accidentally disappear, etc.—but they are incredibly helpful for creating robust JavaScript programs. You can also run your projects under HTTPS to avoid intermediaries manipulating your code, though <a href="http://arstechnica.com/security/2015/01/gogo-issues-fake-https-certificate-to-users-visiting-youtube/">that’s not fool-proof either</a>.</p>

<p>The devices themselves, we have no control over. It’s not like we can send a new device to each and every user (or prospective user) we have just to ensure they have the appropriate hardware and software requirements to use our product.<sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup> Instead, we need to <a href="https://www.smashingmagazine.com/2012/11/writing-fast-memory-efficient-javascript/">write JavaScript programs that play well in a multitude of of scenarios (including resource-limited ones)</a>.</p>

<p>And, of course, none of this addresses network availability. In many instances, a user’s network connection has the greatest impact on their experience of our products. If the connection is slow (or the page’s resources are exceptionally large) the page load experience can be excruciatingly painful. If the connection goes down and dependencies aren’t met, the experience can feel disjointed or may be flat out broken. Using <a href="https://developer.mozilla.org/docs/Web/API/Service_Worker_API">Service Worker</a> and client-side storage (<a href="https://developer.mozilla.org/docs/Web/API/IndexedDB_API"><code>indexedDB</code></a> and <a href="https://developer.mozilla.org/docs/Web/API/Web_Storage_API">Web Storage</a>) can definitely help mitigate these issues for repeat visits, but they don’t do much to help with initial load. They also don’t work at all if your JavaScript program doesn’t run. Which brings me to my last point.</p>

<p>When you love a language like JavaScript (as I do), it can be difficult to recognize (or even admit) it’s shortcomings, but recognizing them is part of becoming a better programmer. The Web is constantly evolving and our understanding of the languages we use to build it expands as fast as—or often faster than—their capabilities do. As such, we need to remain open to new and different ways of doing things. Change can be scary, but it can also be good. Being asked to consider a non-JavaScript experience shouldn’t be seen as an affront to JavaScript, but rather a challenge to create more robust experiences. After all, our last line of defense in providing a good user experience is providing one with <a href="https://www.smashingmagazine.com/2016/05/developing-dependency-awareness/">the least number of dependencies</a>. That’s what progressive enhancements asks us to do.</p>

<h2 id="javascript--pe-kissing-in-a-tree">JavaScript &amp; PE kissing in a tree?</h2>

<p>All of this is to say I don’t think JavaScript and progressive enhancement are diametrically opposed and I don’t think folks who love the JavaScript language or tout the progressive enhancement philosophy should be either. Together they have the potential to making the Web the best it can possibly be.</p>

<p>Progressive enhancement’s focus on providing a baseline experience that makes no assumptions about browser features will provide a robust foundation for any project. It also guides us to be smarter about <em>how</em> we apply technologies like HTML, CSS, JavaScript and ARIA by asking us to consider what happens when those dependencies aren’t met.</p>

<p>JavaScript absolutely makes the user experience better for anyone who can benefit from it. It can make interfaces more accessible. It can help mitigate networking issues. It can create smoother, more seamless experiences for our users. And it can reduce the friction inherent in accomplishing most tasks on the Web. JavaScript is an indispensable part of the modern Web.</p>

<p>In order to come together, however, folks <a href="https://www.baldurbjarnason.com/notes/debating-web-development/">need to stop demonizing and dismissing one another</a>. Instead we need to rally together to make the Web better. But before we can do that, we need to start with a common understanding of the nature of JavaScript. The progressive enhancement camp needs to concede that all JavaScript is not evil, or even bad—JavaScript can be a force for good and it’s got really solid support. The JavaScript camp needs to concede that, despite its ubiquity and near universal support, we can never be absolutely guaranteed our JavaScript programs will run.</p>

<p>I fully believe we can heal this rift, but it’s probably gonna take some time. I fully intend to do my part and I hope you will as well.</p>

<p><ins datetime="2016-10-18T11:11:00-04:00"><strong>Update:</strong> This post was updated to clarify that graceful degradation can take many forms and to explicitly tie progressive enhancement and graceful degradation together.</ins></p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>Full disclosure: We both work at Microsoft, but on different teams. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>It’s worth noting that <a href="http://gizmodo.com/website-opts-to-buy-customers-new-computers-rather-than-1513186669">one company, NursingJobs, actually did this</a>. <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What Would You Do With 10kB?]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/what-would-you-do-with-10kb/"/>
    <updated>2016-08-17T14:48:27-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/what-would-you-do-with-10kb</id>
    <content type="html"><![CDATA[<p>Sixteen years ago, <a href="https://twitter.com/stewart">Stewart Butterfield</a> conceived of a contest that would test the mettle of any web designer: <a href="http://web.archive.org/web/20000510010054/http:/www.sylloge.com/5k/home.html">The 5k</a>. The idea was that entrants would build <a href="http://alistapart.com/article/5k">an entire site in 5kB of code or less</a>. Its aim was to force us to get creative by putting a bounding box on what we could do:</p>

<blockquote>
  <p>Between servers and bandwidth, clients and users, HTML and the DOM, browsers and platforms, our conscience and our ego, we’re left in a very small space to find highly optimal solutions. Since the space we have to explore is so small, we have to look harder, get more creative; and that’s what makes it all interesting.</p>
</blockquote>

<!-- more -->

<p>The 5k contest ran from 2000 until 2002. In 2010, <a href="http://www.zeldman.com/2010/07/29/10k-apart-%E2%80%93%C2%A0inspire-the-web/">An Event Apart and Microsoft revived the idea</a> with an updated limit and a new name: <a href="http://web.archive.org/web/20100730090946/http:/10k.aneventapart.com/">10k Apart</a>. Staying true to its roots, this new incarnation, which ran for two years, continued to push designers and developers to get creative within a pretty extreme (though slightly expanded) limit while incorporating new goodies like HTML5 and responsive design.</p>

<p>I’m thrilled to announce that <a href="https://a-k-apart.com/">the 10k Apart contest is back</a> and brings with it a handful of new challenges:</p>

<ol>
  <li><strong>Each page must be usable in 10kB or less.</strong> The 10kB limit no longer applies to the size of a ZIP archive of your entry; the 10kB limit now applies to the total initial download size of the baseline experience of each page in your project. When we say “baseline experience,” we’re talking small screen devices running older, less capable browsers. The 10kB limit will apply to every page and whatever assets it loads by default; that means images, CSS, JavaScript, and so on.</li>
  <li><strong>Progressive enhancement is the name of the game.</strong> Your project should start with a super-basic, bare-bones-but-usable experience that will work no matter what (including without JavaScript). You can use clever CSS and JavaScript techniques to enhance that experience as it makes sense to do so. For example: You might lazy load an image using JavaScript if the screen size is above a certain threshold or when certain other conditions are met. Entries that depend entirely on JavaScript to render the front-end won’t be accepted. If you need a primer on progressive enhancement, <a href="http://alistapart.com/search?keywords=progressive%20enhancement">consult the pages of <cite>A List Apart</cite></a>.</li>
  <li><strong>Back ends are in this year.</strong> In previous iterations, each entry comprised client-side code submitted via ZIP file. Over time, that limitation led to an over-reliance on JavaScript for rendering. No more. This year, you can create dynamic experiences that work without front-end JavaScript using Node, PHP, Python or .Net. You will submit your entry as public GitHub repository (so we can all learn from your awesome code) and we’ll spin up a dedicated <a href="https://azure.microsoft.com/">Azure</a> instance running the appropriate stack.</li>
  <li><strong>Entries should be accessible.</strong> In line with the philosophy of progressive enhancement, your entry should be usable by the broadest number of users possible. <a href="http://www.accessiq.org/news/commentary/2012/09/web-accessibility-is-a-mindset-not-a-checklist">Accessibility is not a checklist</a>, but if you’re clueless about where to start, <a href="https://www.w3.org/TR/WCAG20-TECHS/">these techniques</a> can offer some guidance.</li>
  <li><strong>Nothing comes for free.</strong> In previous years, we gave a pass if you wanted to use jQuery or load some fonts from Typekit. This year we decided to change it up, not because we don’t love these products (we do), but because we wanted to force every piece of code, every asset, to fight for its place in your entry. Anything you add should be added with purpose.</li>
</ol>

<p>As with previous editions, your entry should use web standards and work in all modern browsers. You can use HTML, CSS, and JavaScript features and APIs that don’t have across-the-board support as long as you do so in keeping with the progressive enhancement philosophy. In other words, your entry can’t depend on that technology or feature in order to be usable.</p>

<p>All of this may sound like a tall order, but it’s entirely possible. In fact, the site we built for the contest also abides by these rules. My colleagues and I will touch on some of the techniques we used (and concessions we made) in building the site in future posts.</p>

<p>If you’ve read this far, you might be wondering <em>What’s in it for me?</em> Well, bragging rights, of course, but we’ve got some awesome prizes too! We’re giving away $10,000 to the top three entries, plus <a href="http://aneventapart.com/events">tickets to An Event Apart</a>, complete collections of <a href="https://abookapart.com/collections/standards-collection">A Book Apart titles</a>, and copies of <a href="http://adaptivewebdesign.info/2nd-edition/">my book</a> too. <a href="https://a-k-apart.com/#prizes">Complete details of the prizes</a> are over on <a href="https://a-k-apart.com/">the contest site</a>.</p>

<p>We’ve lined up an amazing group to judge the entires this year too: <a href="https://twitter.com/rachelandrew">Rachel Andrew</a>, <a href="https://twitter.com/lara_hogan">Lara Hogan</a>, <a href="https://twitter.com/wilto">Mat Marquis</a>, <a href="https://twitter.com/Heydonworks">Heydon Pickering</a>, <a href="https://twitter.com/jensimmons">Jen Simmons</a>, and <a href="https://twitter.com/SaraSoueidan">Sara Soueidan</a> will all be putting your entry through its paces and peering under the hood at your code. There’s also a People’s Choice award which will be based on votes you cast. Voting will open October 1st and run through October 14th.</p>

<p>The contest opened Monday and we will accept entries until 5pm Pacific Time on September 30th. <a href="https://a-k-apart.com/legal">Everything you should need to know about the contest, eligibility, etc.</a> is up on <a href="https://a-k-apart.com/">the 10k Apart site</a>, but if you have additional questions, <a href="https://a-k-apart.com/hi">you can always reach out</a>.</p>

<p>I can’t wait to see what you come up with! Happy coding!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Offline First: Love the Idea, Hate the Name]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/offline-first-love-the-idea-hate-the-name/"/>
    <updated>2016-03-28T08:25:26-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/offline-first-love-the-idea-hate-the-name</id>
    <content type="html"><![CDATA[<p>Back in 2014, I had the great pleasure of listening to <a href="https://twitter.com/misprintedtype">Ola Gasidlo</a> of <a href="http://hood.ie/">Hood.ie</a> <a href="https://vimeo.com/103221949">discuss the importance of offline</a> at Beyond Tellerrand in Düsseldorf, Germany. Her excellent talk was my introduction to <a href="https://www.google.com/search?q=offline+first">the “Offline First” movement</a> and, while I can get behind the idea, I’ve had some serious issues with the name. And with the rise of Service Workers as a simple, usable means of making our content available offline, I thought it worth revisiting the idea of “offline first”, if only to address its core fallacy.</p>

<!-- more -->

<p>First, the good stuff: The “offline first” movement clearly recognizes the current dilemma of our time:</p>

<blockquote>
  <p>We live in a disconnected &amp; battery powered world, but our technology and best practices are a leftover from the always connected &amp; steadily powered past.</p>
</blockquote>

<p><a href="https://www.w3.org/TR/2011/WD-html5-20110525/offline.html">App Cache</a>, <a href="https://www.w3.org/TR/webdatabase/">Web SQL</a>, <a href="https://www.w3.org/TR/webstorage/">Web Storage</a>, <a href="https://www.w3.org/TR/IndexedDB/">Indexed DB</a>, <a href="https://www.w3.org/TR/service-workers/">Service Workers</a>, and a handful of other specs and ideas were all created to address this core limitation of the Web. They also make it possible to compete with “native” software experiences. I am 100% on board with this move. It sucks to open Chrome on my mobile and switch to a tab that’s been tucked out of view for a while only to have the page fail to load because I happen to be traveling abroad without a data plan. If that site was made to work offline, the fact that Chrome had recycled the RAM and CPU that tab had been consuming would be less of a problem and the page would load instantly from the cache.</p>

<p>Tunnels… hotel wifi… high latency mobile networks… expensive roaming data plans… these are all reasons we need an offline Web. I’m incredibly thankful for all of the hard work the smart folks working on solutions like these are contributing.</p>

<p>Also inline with the “offline first” movement, I think it’s important to consider the offline experience early in a project, so it isn’t forgotten or haphazardly bolted on. We need to make deliberate choices about what content and assets we are caching. We need to plan for offline, maybe not <em>first</em>, but certainly early.</p>

<p>All of this is to say I don’t have an issue with the philosophy of “offline first”, but I do take issue with the name. As a term, it’s a bit disingenuous. Looking at other “firsts”—”mobile first” or (to go back little further) “content first”—these terms work on multiple levels: They remind us to keep the core purpose of a page or interface central to our planning. They also support an experience that begins and ends with that core.</p>

<p>A “mobile first” experience starts with a distraction-free central message or content, optimized for a small screen and (often) a single, narrow viewport. It can be enhanced for larger screens and more capable devices, but that core experience may be all some users get, and that’s ok. Users will have an experience (and a site that works) no matter what. The same is true with a “content first” approach; its experience remains available regardless of device or access mechanism. Sure, both “mobile first” and “content first” require the network, but guess what: “<strong>Offline first” requires network connectivity too!</strong> <a href="http://www.dynamicdrive.com/forums/showthread.php?62807-Run-Website-from-a-Flashdrive-or-CD">You don’t see many websites delivering their content on USB drives</a>, so all of the code required to make the offline experience possible in the first place requires an initial (and stable) connection to the Web. In other words, offline can’t be first.</p>

<p>You may be wondering <em>Why is that important?</em> It’s important because, historically, a “first” approach (as I mentioned) sets an expectation of that experience always being available. Offline can’t provide that.</p>

<p>Moreover, offline has another core dependency beyond the network: JavaScript. Without JavaScript, none of your fancy offline stuff—except App Cache, which few folks are using these days—will work. And yes, I know, <em>everyone</em> has JavaScript support… but the reality is that <a href="https://gds.blog.gov.uk/2013/10/21/how-many-people-are-missing-out-on-javascript-enhancement/">not everyone will get your JavaScript enhancements</a>, <a href="http://kryogenix.org/code/browser/everyonehasjs.html">even if that were actually the case</a>.</p>

<p>Please don’t misunderstand the purpose of this post: I applaud the ideas behind the “offline first” movement and the amazing work that community is doing. And you should absolutely incorporate offline into projects you are building for the Web. Users with capable devices and browsers will thank you for it. Just try not to use the term “offline first” or at least be prepared for me to cringe a little when you do. Maybe I’m the only one who feels this way; if so, I’m okay with that. But, then again, semantics matter. Maybe we need a different rallying cry. Sadly “Offline Too” doesn’t have the same ring to it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[An Event Apart Nashville 2016, Day One]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/an-event-apart-nashville-2016-day-one/"/>
    <updated>2016-03-16T10:54:59-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/an-event-apart-nashville-2016-day-one</id>
    <content type="html"><![CDATA[<p>Unfortunately, I was unable to spend Tuesday in Nashville for An Event Apart (for reasons that will be revealed in about a month), but I did catch Monday and it was amazing.</p>

<!-- more -->

<p>The esteemed <a href="http://www.zeldman.com/">Jeffrey Zeldman</a> kicked the day off with a talk entitled <em>Designing with Web Standards in 2016</em>. A theme he touched on repeatedly was that none of the problems we are facing in web design today are new problems. It’s a topic near and dear to my heart, something I wrote about in the closing chapter of <a href="http://adaptivewebdesign.info/2nd-edition/"><cite>Adaptive Web Design’s</cite> Second Edition</a> and <a href="/notebook/learn-from-the-past-enhance-for-the-future/">recently spoke about at EnhanceConf in London</a>. He knocked this one out of the park and my head was nodding so much my neck began to hurt.</p>

<p>Next up was <a href="http://www.webstandards.org/about/members/">my former WaSP colleague</a> <a href="https://rachelandrew.co.uk/">Rachel Andrew</a> to give us the skinny on CSS Grid Layouts. This is an amazing spec that I’ve always struggled to understand fully (despite the fact that’s i’ve written a Javascript polyfill for it). Rachel made it crystal clear and got me very excited about the future of layout on the Web.</p>

<p><a href="http://jensimmons.com/">Jen Simmons</a> dropped some serious CSS-related design knowledge bombs that perfectly complimented Rachel’s talk. She discussed Flexbox, CSS Shapes, Multi-column layout, viewport units and more, demonstrating how they can be used right now to progressively enhance the design of your sites.</p>

<p>After lunch, <a href="http://bradfrost.com/">Brad Frost</a> took to the stage to talk about Style Guides. I only caught the last half—I’ll admit to doing some last-minute rehearsing in the hallway—but the bits I did catch were good. I’ve seen his Atomic Design talk a few times, which this one builds on. In this talk he touches on a lot of the atomic design concepts, but he also talked a lot more about workflow and the role of the front-end developer. No doubt the evolution of this talk has come in large part through writing <a href="http://atomicdesign.bradfrost.com/">a book on Atomic Design</a> and in hosting <a href="http://styleguides.io/podcast/">a podcast with Anna Debenham on website style guides</a>.</p>

<p>Next, I was given the opportunity to share some thoughts and advice on designing and building. My talk, <em>The Features of Highly Effective Forms</em>, evolved out of several earlier talks on building forms. With this one, I wanted to strike a little more balance between the nuts and bolts of building forms and the hows and whys of building better forms.</p>

<p>The deck, <a href="http://www.slideshare.net/AaronGustafson/the-features-of-highly-effective-forms-an-event-apart-nashville-2016">which I’ve posted to SlideShare</a>, doesn’t stand on its own quite as well as some of my other forms decks simply because the talk contained a lot of storytelling I chose not to pair with slides—instead opting for an black screen so folks could focus—but I did call out the salient points. I’ve begun writing up some of the recommendations as part of my <a href="/notebook/tags/web-forms/">Modern Web Forms Best Practices series</a> and will continue to do so in the future. And one of the stories I told, which I highly recommend you check out, had to do with <a href="/notebook/consider-how-your-forms-read/">a lesson Facebook learned in managing how users report offensive photos</a>.</p>

<p><a href="https://bigmedium.com/">Josh Clark</a> wrapped the day up with a discussion of the future of interface as things move from digital back to physical. He talked about a lot of really cool new tech that has me excited about the future, including <a href="https://google.github.io/physical-web/">the Physical Web</a>, which Josh had running as a live demo. I wonder if anyone noticed I had a beacon running too ;-)</p>

<p>All in all, day one was a blast. As always, Jeffrey, Eric, <a href="https://www.linkedin.com/in/toby-malina-6247a028">Toby</a>, and <a href="http://www.escapadeproductions.com/">Marci</a> do an awesome job programming their events. I’m really bummed I could not stick around to see <a href="http://valhead.com/">Val</a>, <a href="https://twitter.com/grigs">Jason</a>, <a href="http://www.kryshiggins.com/">Krystal</a>, <a href="http://meyerweb.com/">Eric</a>, <a href="http://braintraffic.com/">Kristina</a>, and <a href="http://cameronmoll.com/">Cameron</a> rock it out though. I’m sure it was amazing.</p>

<p>You can check out attendees thoughts from the event by <a href="https://twitter.com/search?q=%23aeansh&amp;src=typd">searching Twitter using the #aeansh hashtag</a>. I’ve <a href="https://storify.com/AaronGustafson/reactions-and-takeaways-from-my-aeansh-talk">collected reactions to my talk on Storify</a> for posterity as well.</p>
]]></content>
  </entry>
  
</feed>
