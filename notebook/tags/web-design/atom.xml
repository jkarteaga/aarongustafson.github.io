<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Browse by Tag: Web Design | Aaron Gustafson]]></title>
  <link href="https://www.aaron-gustafson.com/notebook/tags/web-design/atom.xml" rel="self"/>
  <link href="https://www.aaron-gustafson.com/"/>
  <updated>2017-01-04T11:31:14-05:00</updated>
  <id>https://www.aaron-gustafson.com/</id>
  <author>
    <name><![CDATA[Aaron Gustafson]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Lessons in Averaging]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/lessons-in-averaging/"/>
    <updated>2016-12-14T13:01:32-05:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/lessons-in-averaging</id>
    <content type="html"><![CDATA[<p>In the work that we do on the Web (as well as in our daily lives), we’re often confronted, informed, or judged based on averages. I never really stopped to think about it, beyond being bugged by the fact that averages aren’t truly representative of reality. Then I listened to <a href="http://99percentinvisible.org/episode/on-average/">99% Invisible’s episode “On Average”</a>. It was incredibly enlightening and the stories shared in that episode provide sage wisdom that is very relevant to the work that we do.</p>

<!-- more -->

<p>Do you know where our fascination with averages began? It all started with Adolphe Quételet, a Belgian mathematician and astronomer:</p>

<blockquote>
  <p>In the 1830s, astronomers were some of the only people that regularly calculated averages, since early telescopes were extremely imprecise. To obtain more accurate data for say, tracking the orbits of planets, astronomers would take multiple measurements (all of which were slightly different) add them together, then divide by the number of observations to get a better approximation of the true value.</p>
</blockquote>

<p>Quetelet decided to apply this tool to people, starting with Scottish soldiers’ chest sizes. Turns out the average chest size of a Scottish soldier in the 1830s was 39.75 inches. File that one away for Pub Trivia.</p>

<p>Quetelet believed that the average was the “true” size of something… something that we should strive for or that nature would attempt to create. The <a href="https://en.wikipedia.org/wiki/Platonic_idealism">Platonic ideal</a> if you will:</p>

<blockquote>
  <p>In Quetelet’s mind, human averages had a certain moral mandate. By his logic, if everyone were optimally fed and lived under the same environmental conditions, they would be average. And this is what society should be striving for: the continual improvement of the average of the group.</p>
</blockquote>

<p>We look at averages all the time in our work. Some, like average <a href="https://developers.google.com/web/tools/lighthouse/audits/time-to-interactive">Time To Interactive (TTI)</a>, are useful measurements that allow us to improve our work; others, like the “average” user are decidedly less so. <span data-quotable="">The “average” person (or dog or flower) is a myth. Everyone and everything is unique to some equally unique degree.</span> <a href="https://en.wikipedia.org/wiki/Factory_second">Even mass-produced objects have variance</a>.</p>

<p>Designing for the “average” user is incredibly problematic. The episode I mentioned captured this perfectly in a story about the U.S. Army’s design of airplane cockpits:</p>

<blockquote>
  <p>[I]n 1926, when the Army designed its first airplane cockpit, they measured the physical dimensions of male pilots and calculated the average measurement of their height, weight, arm-length and other dimensions.</p>
</blockquote>

<blockquote>
  <p>The results determined the size and shape of the seat, the distance to the pedals and the stick, and even the shape of the flight helmets. This mean that, in part, pilots were selected based on their ability to fit into the cockpit designed for the average 1920s man.</p>
</blockquote>

<blockquote>
  <p>This worked more or less up until World War II, when the Army began recruiting hundreds of new pilots to expand its air forces (which became a separate branch of the military in 1947). But with the birth and expansion of the Air Force came a decline in performance and a rash of deaths. Even with no war, pilots continued to die during training, as they were unable to control their planes.</p>
</blockquote>

<blockquote>
  <p>The high death rate in the Air Force was a mystery for many years, but after blaming the pilots and their training programs, the military finally realized that the cockpit itself was to blame, that it didn’t actually fit most pilots.</p>
</blockquote>

<p>In 1950, the Air Force sent Gilbert S. Daniels out to collect ten measurements from thousands of airmen—yes, they were all men at the time—across the U.S. in order to establish a new average. After collecting the data, Daniels got curious and decided to see how many of the airmen he measured hit the average on all ten measurements. Not a single one. How about three of the measurements? Less than five percent. He realized that <span data-quotable="">in designing for an average, they were, in fact, designing for no one.</span> Based on this discovery, the Air Force commissioned new equipment that including features like adjustable foot pedals, helmet straps, flight suits, and seats. And, wonder of wonders, pilot performance improved dramatically.</p>

<p>When we design, we need to be cognizant of the variety of human experience and plan accordingly. <span data-quotable="">For our work to be successful, we need to accommodate the adjustments our users require for <em>them</em> to be successful.</span> Responsive layouts, adaptive interfaces, support for assistive technologies… all of these approaches enable our work to go further by enabling it to be tailored to the permanent, temporary, and/or situational needs of our users.</p>

<p>All of this is to say, this episode made me an even more ardent believer in the idea of <a href="http://alistapart.com/article/understandingprogressiveenhancement">progressive enhancement</a> and the continuum of experience it enables. You should go listen to it now, I promise there’s more to the story.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Insert Clickbait Headline About Progressive Enhancement Here]]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/insert-clickbait-headline-about-progressive-enhancement-here/"/>
    <updated>2016-12-06T14:45:25-05:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/insert-clickbait-headline-about-progressive-enhancement-here</id>
    <content type="html"><![CDATA[<p>Late last week, Josh Korr, a project manager at Viget, posted at length about <a href="https://www.viget.com/articles/the-case-against-progressive-enhancements-flimsy-moral-foundation">what he sees as a fundamental flaw with the argument for progressive enhancement</a>. In reading the post, it became clear to me that Josh really doesn’t have a good grasp on progressive enhancement or the reasons its proponents think it’s a good philosophy to follow. Despite claiming to be “an expert at spotting fuzzy rhetoric and teasing out what’s really being said”, Josh makes a lot of false assumptions and inferences. My response would not have fit in a comment, so here it is…</p>

<!-- more -->

<p>Before I dive in, it’s worth noting that Josh admits that he is not a developer. As such, he can’t really speak to the bits where the rubber really meets the road with respect to progressive enhancement. Instead, he focuses on the argument for it, which he sees as a purely moral one… and a flimsily moral one at that.</p>

<p>I’m also unsure as to how Josh would characterize me. I don’t think I fit his mold of PE “hard-liners”, but since I’ve written two books and countless articles on the subject and he quotes me in the piece, I’ll go out on a limb and say he probably thinks I am.</p>

<p>Ok, enough with the preliminaries, let’s jump over to his piece…</p>

<hr />

<p>Right out of the gate, Josh demonstrates a fundamental misread of progressive enhancement. If I had to guess, it probably stems from his source material, but he sees progressive enhancement as a moral argument:</p>

<blockquote>
  <p>It’s a moral imperative that everything on the web should be available to everyone everywhere all the time. Failing to achieve — or at least strive for — that goal is inhumane.</p>
</blockquote>

<p>Now he’s quick to admit that no one has ever explicitly said this, but this is his takeaway from the articles and posts he’s read. It’s a pretty harsh, black &amp; white, <a href="https://en.wikipedia.org/wiki/You're_either_with_us,_or_against_us"><em>you’re either with us or against us</em></a> sort of statement that has so many people picking sides and lobbing rocks and other heavy objects at anyone who disagrees with them. And everyone he quotes in the piece as examples of why he thinks this is progressive enhancement’s central conceit is much more of an “it depends” sort of person.</p>

<p>To clarify, progressive enhancement is neither moral or amoral. It’s a philosophy that recognizes the nature of the Web as a medium and asks us to think about how to build products that are robust and capable of reaching as many potential customers as possible. It isn’t concerned with any particular technology, it simply asks that we look at each tool we use with a critical eye and consider both its benefits and drawbacks. And it’s certainly not anti-JavaScript.</p>

<p>I could go on, but let’s circle back to Josh’s piece. Off the bat he makes some pretty bold claims about what he intends to prove in this piece:</p>

<blockquote cite="https://www.viget.com/articles/the-case-against-progressive-enhancements-flimsy-moral-foundation">
<ol><li>Progressive enhancement is a philosophical, moral argument disguised as a practical approach to web development.</li><li>This makes it impossible to engage with at a practical level.</li><li>When exposed to scrutiny, that moral argument falls apart.</li><li>Therefore, if PEers can’t find a different argument, it’s ok for everyone else to get on with their lives.</li></ol>
</blockquote>

<p>For the record, I plan to address <em>his</em> arguments quite practically. As I mentioned, progressive enhancement is not solely founded on morality, though that can certainly be viewed as a facet. The reality is that progressive enhancement is quite pragmatic, addressing the Web as it exists not as we might hope that it exists or how <em>we</em> experience it.</p>

<p>Over the course of a few sections—which I wish I could link to directly, but alas, the headings don’t have unique <code>id</code>s—he examines a handful of quotes and attempts to tease out their hidden meaning by following the <a href="https://en.wikipedia.org/wiki/Law_School_Admission_Test">LSAT</a>’s <a href="https://en.wikipedia.org/wiki/Logical_reasoning">Logic Reasoning</a> framework. We’ll start with the first one.</p>

<h2 id="working-without-javascript">Working without JavaScript</h2>

<blockquote cite="https://www.viget.com/articles/the-case-against-progressive-enhancements-flimsy-moral-foundation">
<h4>Statement</h4>
<ul><li>“When we write JavaScript, it’s critical that we recognize that we can’t be guaranteed it will run.” — <a href="https://www.aaron-gustafson.com/notebook/missed-connections/">Aaron Gustafson</a></li><li>“If you make your core tasks dependent on JavaScript, some of your potential users will inevitably be left out in the cold.” —&nbsp;<a href="https://adactio.com/journal/7706">Jeremy Keith</a></li></ul>
<p>Unstated assumptions:</p>
<ul><li><em>Because there is some chance JavaScript won’t run, we must always account for that chance.</em></li><li><em>Core tasks can always be achieved without JavaScript.</em></li><li><em>It is always bad to ignore some potential users for any reason.</em></li></ul>
</blockquote>

<p>His first attempt at teasing out the meaning of these statements comes close, but ignores some critical word choices. First off, neither Jeremy nor I speak in absolutes. As I mentioned before, we (and the other folks he quotes) all believe that the right technical choices for a project depend on specifically on the purpose and goals of <em>that specific project</em>. In other words <em>it depends</em>. We intentionally avoid absolutist words like “always” (which, incidentally, Josh has no problem throwing around, on his own or on our behalf).</p>

<p>For the development of <em>most</em> websites, the benefits of following a progressive enhancement philosophy far outweigh the cost of doing so. I’m hoping Josh will take a few minutes to read my post on <a href="http://blog.easy-designs.net/archives/the-true-cost-of-progressive-enhancement/">the true cost of progressive enhancement in relation to actual client projects</a>. As a project manager, I hope he’d find it enlightening and useful.</p>

<p>It’s also worth noting that he’s not considering the reason we make statements like this: Many sites rely 100% on JavaScript without needing to. The reasons why sites (like news sites, for instance) are built to be completely reliant on a fragile technology is somewhat irrelevant. But what isn’t irrelevant is that it happens. Often. That’s why I said “it’s critical that we <em>recognize</em> that we can’t be guaranteed it will run” (emphasis mine). A lack of acknowledgement of JavaScript’s fragility is one of the main problems I see with web development today. I suspect Jeremy and everyone else quoted in the post feels exactly the same. To be successful in a medium, you need to understand the medium. And the (sad, troubling, interesting) reality of the Web is that <a href="https://www.aaron-gustafson.com/notebook/a-fundamental-disconnect/">we don’t control a whole lot</a>. We certainly control a whole lot less than we often believe we do.</p>

<p>As I mentioned, I disagree with his characterization of the argument for progressive enhancement being a moral one. Morality can certainly be one argument for progressive enhancement, and as <a href="https://www.aaron-gustafson.com/notebook/egalitarianism/">a proponent of egalitarianism</a> I certainly see that. But it’s not the only one. If you’re in business, there are a few really good business-y reasons to embrace progressive enhancement:</p>

<ul>
  <li><strong>Legal:</strong> Progressive enhancement and accessibility are very closely tied. Whether <a href="https://en.wikipedia.org/wiki/National_Federation_of_the_Blind_v._Target_Corp.">brought by legitimate groups</a> or <a href="http://chrishofstader.com/stop-the-ada-trolls/">opportunists</a>, lawsuits over the accessibility of your web presence can happen; following progressive enhancement <em>may</em> help you avoid them.</li>
  <li><strong>Development Costs:</strong> As I mentioned earlier, progressive enhancement is a more cost-effective approach, especially for long-lived projects. Here’s that link again: <a href="http://blog.easy-designs.net/archives/the-true-cost-of-progressive-enhancement/">The True Cost of Progressive Enhancement</a>.</li>
  <li><strong>Reach:</strong> The more means by which you enable users to access your products, information, etc., the more opportunities you create to earn their business. Consider that no one thought folks would buy big-ticket items on mobile just a few short years ago. Boy, were they wrong. Folks buy cars, planes, and more from their tablets and smartphones on the regular these days.</li>
  <li><strong>Reliability:</strong> When your site is down, not only do you lose potential customers, you run the risk of losing existing ones too. There have been <a href="http://blogs.wsj.com/digits/2011/02/07/gawker-outage-causing-twitter-stir">numerous</a> <a href="http://www.theguardian.com/technology/2014/jan/28/sky-broadband-blocks-jquery-web-critical-plugin">incidents</a> where big sites got hosed due to JavaScript dependencies and they didn’t have a fallback. Progressive enhancement ensures users can always do what they came to your site to do, even if it’s not the ideal experience.</li>
</ul>

<p>Hmm, no moral arguments for progressive enhancement there… but let’s continue.</p>

<h2 id="some-experience-vs-no-experience">Some experience vs. no experience</h2>

<blockquote cite="https://www.viget.com/articles/the-case-against-progressive-enhancements-flimsy-moral-foundation">
<h4>Statement</h4>
<ul><li>“[With a PE approach,] Older browsers get a clunky experience with full page refreshes, but that’s still much, much better than giving them nothing at all.” — <a href="https://adactio.com/journal/7706">Jeremy Keith</a></li><li>“If for some reason JavaScript breaks, the site should still work and look good. If the CSS doesn’t load correctly, the HTML content should still be there with meaningful hyperlinks.” — <a href="http://blog.teamtreehouse.com/progressive-enhancement-past-present-future">Nick Pettit</a></li></ul>
<p>Unstated assumptions:</p>
<ul><li><em>A clunky experience is always better than no experience.</em></li><li><em>HTML content — i.e. text, images, unstyled forms — is the most important part of most websites.</em></li></ul>
</blockquote>

<p>You may be surprised to hear that I have no issue with Josh’s distillation here. Clunky is a bit of a loaded word, but I agree that <em>an</em> experience <em>is</em> better than no experience, especially for critical tasks like checking your bank account, registering to vote, making a purchase from an online shop. In my book, I talk a little bit about a strange thing we experienced <a href="http://alistapart.com/article/netscape">when <cite>A List Apart</cite> stopped delivering CSS to Netscape Navigator 4</a> way back in 2001:</p>

<blockquote>
  <p>We assume that those who choose to keep using 4.0 browsers have reasons for doing so; we also assume that most of those folks don’t really care about “design issues.” They just want information, and with this approach they can still get the information they seek. In fact, since we began hiding the design from non–compliant browsers in February 2001, ALA’s Netscape 4 readership has increased, from about 6% to about 11%.</p>
</blockquote>

<p>Folks come to our web offerings for a reason. Sometimes its to gather information, sometimes it’s to be entertained, sometimes it’s to make a purchase. It’s in our best interest to remove every potential obstacle that can preclude them from doing that. That’s good customer service.</p>

<h2 id="project-priorities">Project priorities</h2>

<blockquote cite="https://www.viget.com/articles/the-case-against-progressive-enhancements-flimsy-moral-foundation">
<h4>Statement</h4>
<ul><li>“Question any approach to the web where fancy features for a few are prioritized &amp; basic access is something you’ll ‘get to’&nbsp;eventually.” — <a href="https://twitter.com/tkadlec/status/565951127225896961">Tim Kadlec</a></li></ul>
<p>Unstated assumptions:</p>
<ul><li><em>Everything beyond HTML content is superfluous fanciness.</em></li><li><em>It’s morally problematic if some users cannot access features built with JavaScript.</em></li></ul>
</blockquote>

<p>Not to put words in Tim’s mouth (like Josh is here), but what Tim’s quote is discussing is <a href="https://blog.daftcode.pl/hype-driven-development-3469fc2e9b22#.ly6bqxv9s">hype-driven</a> (as opposed to <a href="https://en.wikipedia.org/wiki/User-centered_design">user-centered</a>) design. We (as developers) often <a href="https://www.aaron-gustafson.com/notebook/who-should-pay/">prioritize our own convenience/excitement/interest over our users’ actual needs</a>. It doesn’t happen all the time (note I said <em>often</em>), but it happens frequently enough to require us to call it out now and again (as Tim did here).</p>

<p>As for the “unstated assumptions”, I know for a fact that Tim would never call “everything beyond HTML” superfluous. What he is saying is that we should <em>question</em>—as in weigh the pros and cons—of each and every design pattern and development practice we consider. It’s important to do this because there are always tradeoffs. Some considerations that should be on your list include:</p>

<ul>
  <li>Download speed;</li>
  <li>Time to interactivity;</li>
  <li>Interaction performance;</li>
  <li>Perceived performance;</li>
  <li>Input methods;</li>
  <li>User experience;</li>
  <li>Screen size &amp; orientation;</li>
  <li>Visual hierarchy;</li>
  <li>Aesthetic design;</li>
  <li>Contrast;</li>
  <li>Readability;</li>
  <li>Text equivalents of rich interfaces for visually impaired users <em>and</em> headless UIs;</li>
  <li>Fallbacks; and</li>
  <li>Copywriting.</li>
</ul>

<p>This list is by no means exhaustive nor is it in any particular order; it’s what came immediately to mind for me. Some interfaces may have fewer or more considerations as each is different. And some of these considerations might be in opposition to others depending on the interface. It’s critical that we consider the implications of our design decisions by weighing them against one another before we make any sort of decision about how to progress. Otherwise we open ourselves up to potential problems and the cost of changing things goes up the further into a project we are:</p>

<figure id="fig-2016-12-06-01" class="media-container">
{% adaptive_image /i/posts/2016-12-06/01.png %}
<figcaption>The cost of changing your mind goes up the further into any project you are. Just ask any contractor you hire to work on your house.</figcaption>
</figure>

<p>As a project manager, I’m sure Josh understands this reality.</p>

<p>As to the “morally problematic” bit, I’ll refer back to <a href="#working-without-javascript">my earlier discussion of business considerations</a>. Sure, morality can certainly be part of it, but I’d argue that it’s unwise to make assumptions about your users regardless. It’s easy to fall into the trap of thinking that all of or users are like us (or like the personas we come up with). My employer, Microsoft, makes a great case for why we should avoid doing this in their <a href="https://www.microsoft.com/en-us/design/inclusive">Inclusive Design materials</a>:</p>

<figure id="fig-2016-04-11-02" class="media-container">
{% adaptive_image /i/posts/2016-04-11/02.png %}
<figcaption>When we design only for others like us, we exclude everyone who is not like us.</figcaption>
</figure>

<p>If you’re in business, it doesn’t pay to exclude potential customers (or alienate current ones).</p>

<h2 id="erecting-unnecessary-barriers">Erecting unnecessary barriers</h2>

<blockquote cite="https://www.viget.com/articles/the-case-against-progressive-enhancements-flimsy-moral-foundation">
<h4>Statement</h4>
<ul><li>“Everyone deserves access to the sum of all human knowledge.” — <a href="http://blog.teamtreehouse.com/progressive-enhancement-past-present-future">Nick Pettit</a></li><li>“[The web is] built with a set of principles that — much like the principles underlying the internet itself — are founded on ideas of universality and accessibility. ‘Universal access’&nbsp;is a pretty good rallying cry for the web.” — <a href="https://adactio.com/journal/8245">Jeremy Keith</a></li><li>“The minute we start giving the middle finger to these other platforms, devices and browsers is the minute where the concept of The Web starts to erode. Because now it’s not about universal access to information, knowledge and interactivity. It’s about catering to the best of breed and leaving everyone else in the cold.” — <a href="http://bradfrost.com/blog/mobile/support-vs-optimization/">Brad Frost</a></li></ul>
<p>Unstated assumptions:</p>
<ul><li><em>What’s on the web comprises the sum of&nbsp;human knowledge.</em></li><li><em>Progressive enhancement is fundamentally about universal access to this sum of human knowledge.</em></li><li><em>It is always immoral if something on the web isn’t available to everyone.</em></li></ul>
</blockquote>

<p>I don’t think anyone quoted here would argue that the Web (taken in its entirety) is “the sum of all human knowledge”—Nick, I imagine, was using that phrase somewhat hyperbolically. But there is a lot of information on the Web folks should have access too, whether from a business standpoint or a legal one. What Nick, Jeremy, and Brad are really highlighting here is that we often make somewhat arbitrary design &amp; development decisions that can block access to useful or necessary information and interactions.</p>

<p>In my talk <a href="https://vimeo.com/70018634"><em>Designing with Empathy</em></a> (<a href="http://www.slideshare.net/AaronGustafson/designing-with-empathy-beyond-tellerrand-2013">slides</a>), I discussed <a href="https://en.wikipedia.org/wiki/Mystery_meat_navigation">“mystery meat” navigation</a>. I can’t imagine any designer sets out to make their site difficult to navigate, but we are influenced by what we see (and are inspired by) on the web. Some folks took inspiration from web-based art projects like this Toyota microsite:</p>

<figure id="fig-2016-12-06-02" class="media-container">
{% adaptive_image /i/posts/2016-12-06/02.png %}
<figcaption><a href="http://www.northkingdom.com/cases/i-huvudet-pa-toyota/">On Toyota’s Mind</a> is a classic example of mystery meat navigation. It’s a Flash site and you can navigate when you happen to mouse over "hotspots" in the design. I’m pointing to one with a big red arrow here.</figcaption>
</figure>

<p>Though probably not directly influenced by On Toyota’s Mind, <a href="https://www.flatbush.org/">Yeshiva of Flatbush</a> was certainly influenced by the concept of “experiential” (which is a polite way of saying “mystery meat”) navigation.</p>

<figure id="fig-2016-12-06-03" class="media-container">
{% adaptive_image /i/posts/2016-12-06/03.png %}
<figcaption><a href="https://www.flatbush.org/">Yeshiva of Flatbush</a> uses giant circles for their navigation. Intuitive, right?</figcaption>
</figure>

<p>That’s a design/UX example, but development is no different. How many Single Page Apps have you see out there that really didn’t need to be built that way? Dozens? We often put the cart before the horse and decide to build a site using a particular stack or framework without even considering the type of content we’re dealing with or whether that decision is in the best interest of the project or its end users. That goes directly back to <a href="#project-priorities">Tim’s earlier point</a>.</p>

<p>Progressive enhancement recognizes that <a href="https://adaptivewebdesign.info/1st-edition/read/chapter-1.html#figure-1-2"><strong>experience is a continuum</strong></a> and we all have different needs when accessing the Web. Some are permanent: Low vision or blindness. Some are temporary: Imprecise mousing due to injury. Others are purely situational: Glare when your users are outside on a mobile device or have turned their screen brightness down to conserve battery. When we make our design and development decisions in the service of the project and the users who will access it, everyone wins.</p>

<h2 id="real-answers-to-real-questions">Real answers to real questions</h2>

<p>In the next section, Josh tries to say we only discuss progressive enhancement as a moral imperative. Clearly I don’t (and would go further to say no one else who was quoted does either). He argues that ours is “a philosophical argument, not a practical approach to web development”. I call bullshit. As I’ve just discussed in the previous sections, progressive enhancement is a practical, fiscally-responsible, developmentally robust philosophical approach to building for the Web.</p>

<p>But let’s look at some of the questions he says we don’t answer:</p>

<blockquote>
  <p>“Wait, how often do people turn off JavaScript?”</p>
</blockquote>

<p>Folks turning off JavaScript isn’t really the issue. It used to be, but that was years ago. I discussed <a href="https://www.aaron-gustafson.com/notebook/progressive-misconceptions/">the misconception that this is still a concern</a> a few weeks ago. The real issue is whether or not JavaScript is available. Obviously your project may vary, but <a href="https://gds.blog.gov.uk/2013/10/21/how-many-people-are-missing-out-on-javascript-enhancement/">the UK government pegged their non-JavaScript usage at 1.1%</a>. The more interesting bit, however, was that only 0.2% of their users fell into the “Javascript off or no JavaScript support” camp. 0.9% of their users <em>should have</em> gotten the JavaScript-based enhancement on offer, but didn’t. <a href="http://kryogenix.org/code/browser/everyonehasjs.html">The potential reasons are myriad</a>. JavaScript is great, but you can’t assume it’ll be available.</p>

<blockquote>
  <p>“I’m not trying to be mean, but I don’t think people in Sudan are going to buy my product.”</p>
</blockquote>

<p>This isn’t really a question, but it is the kinda thing I hear every now and then. An even more aggressive and ill-informed version I got was “I sell TVs; blind people don’t watch TV”. As a practical person, I’m willing to admit that your organization probably knows its market pretty well. If your products aren’t available in certain regions, it’s probably not worth your while to cater to folks in that region. But here’s some additional food for thought:</p>

<ul>
  <li><strong>When you remove barriers to access for one group, you create opportunities for others.</strong> A perfect example of this is the curb cut. Curb cuts were originally created to facilitate folks in wheelchairs getting across the road. In creating curb cuts, we’ve also enabled kids to ride bicycles more safely on the sidewalk, delivery personnel to more easily move large numbers of boxes from their trucks into buildings, and parents to more easily cross streets with a stroller. Small considerations for one group pay dividends to more. What rational business doesn’t want to enable more folks to become customers?</li>
  <li><strong>Geography isn’t everything.</strong> I’m not as familiar with specific design considerations for Sudanese users, but since about 97% of Sudanese people are Muslim, let’s tuck into that. Ignoring translations and right-to-left text, let’s just focus on cultural sensitivity. For instance, a photo of a muscular, shirtless guy is relatively acceptable in much of the West, but <a href="http://www.instantshift.com/2015/04/23/website-designs-for-various-cultures/">would be incredibly offensive to a traditional Muslim population</a>. Now your target audience may not be 100% Muslim (nor may your content lend itself to scantily-clad men), but if you are creating sites for mass consumption, knowing this might help you art direct the project better and build something that doesn’t offend potential customers.</li>
</ul>

<p>Reach is incredibly important for companies and is something the Web enables quite easily. To squander that—whether intentionally or not—would be a shame.</p>

<h2 id="failures-of-understanding">Failures of understanding</h2>

<p>Josh spends the next section discussing what he views as failures of the argument for progressive enhancement. He’s of course, still debating it as a purely moral argument, which I think I’ve disproven at this point, but let’s take a look at what he has to say…</p>

<p>The first “fail” he casts on progressive enhancement proponents is that we “are wrong about what’s actually on the Web.” Josh offers three primary offerings on the Web:</p>

<blockquote cite="https://www.viget.com/articles/the-case-against-progressive-enhancements-flimsy-moral-foundation">
<ul><li>Business and personal software, both of which have exploded in use now that <a href="http://www.wsj.com/articles/SB10001424053111903480904576512250915629460">software has eaten the world</a> and is accessed primarily via the web</li><li>Copyrighted news and entertainment content (text, photos, music, video, video games)</li><li>Advertising and marketing content</li></ul>
</blockquote>

<p>This is the fundamental issue with seeing the Web only through the lens of your own experience. Of course he would list software as the number one thing on the Web—I’m sure he uses Basecamp, Harvest, GitHub, Slack, TeamWork, Google Docs, Office 365, or any of a host of business-related Software as a Service offerings every day. As a beneficiary of fast network speeds, I’m not at all surprised that entertainment is his number two: Netflix, Hulu, HBO Go/Now… It’s great to be financially-stable and live in the West. And as someone who works at a web agency, of course advertising would be his number three. A lot of the work Viget, and most other agencies for that matter, does is marketing-related; nothing wrong with that. <strong>But the Web is so much more than this.</strong> Here’s just a fraction of the stuff he’s overlooked:</p>

<ul>
  <li>eCommerce,</li>
  <li>Social media,</li>
  <li>Banks,</li>
  <li>Governments,</li>
  <li>Non-profits,</li>
  <li>Small businesses,</li>
  <li>Educational institutions,</li>
  <li>Research institutions,</li>
  <li>Religious groups,</li>
  <li>Community organizations, and</li>
  <li>Forums.</li>
</ul>

<p>It’s hard to find figures on anything but porn—which incidentally accounts for <a href="http://www.bbc.com/news/technology-23030090">somewhere between 4% and 35% of the Web</a>, depending on who you ask—but I have to imagine that these categories he’s overlooked probably account for the vast majority of “pages” on the Web even if they don’t account for the majority of traffic on it. Of course, as of 2014, <a href="http://www.smithsonianmag.com/smart-news/majority-web-traffic-comes-robots-180950398/">the majority of traffic on the Web was bots</a>, so…</p>

<p>The second “fail” he identifies is that our “concepts of universal access and moral imperatives… make no sense” in light of “fail” number one. He goes on to provide a list of things he seems to think we want even though advocating for progressive enhancement (and even universal access) doesn’t mean advocating for any of these things:</p>

<ul>
  <li><em>All software and copyrighted news/entertainment content accessed via the web should be free.</em> and <em>Netflix, Spotify, HBO Now, etc. should allow anyone to download original music and video files because some people don’t have JavaScript.</em> I’ve never heard anyone say that… ever. Advocating a smart development philosophy doesn’t make you anti-copyright or against making money.</li>
  <li><em>Any content that can’t be accessed via old browsers/devices shouldn’t be on the web in the first place.</em> No one made that judgement. We just think it behooves you to increase the potential reach of your products and to have a workable fallback in case the ideal access scenario isn’t available. You know, smart business decisions.</li>
  <li><em>Everything on the web should have built-in translations into every language.</em> This would be an absurd idea given that the number of languages in use on this planet top 6,500. Even if you consider that 2,000 of those have less than 1,000 speakers it’s still absurd. I don’t know anyone who would advocate for translation to every language.<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup></li>
  <li><em>Honda needs to consider a universal audience for its marketing websites even though (a) its offline advertising is not universal, and (b) only certain people can access or afford the cars being advertised.</em> To you his first point, Honda does actually offline advertising in multiple languages. They even <a href="http://news.honda.com/newsandviews/article.aspx?id=8340-en">issue press releases mentioning it</a>: “The newspaper and radio advertisements will appear in Spanish or English to match the primary language of each targeted media outlet.” As for his second argument… making assumptions about target audience and who can or cannot afford your product seems pretty friggin’ elitist; it’s also incredibly subjective. For instance, we did a project for a major investment firm where we needed to support Blackberry 4 &amp; 5 even though there were many more popular smartphones on the market. The reason? They had several high-dollar investors who loved their older phones. You can’t make assumptions.</li>
  <li><em>All of the above should also be applied to offline software, books, magazines, newspapers, TV shows, CDs, movies, advertising, etc.</em> Oh, I see, he’s being intentionally ridiculous.</li>
</ul>

<p>I’m gonna skip the third fail since it presumes morality is the only argument progressive enhancement has and then chastises the progressive enhancement community for not spending time fighting for equitable Internet access and net neutrality and against things like censorship (which, of course, many of us actually do).</p>

<hr />

<p>In his closing section, Josh talks about progressive enhancement moderates and he quotes <a href="http://alistapart.com/article/the-future-of-the-web">Matt Griffin on <cite>A List Apart</cite></a>:</p>

<blockquote>
  <p>One thing that needs to be considered when we’re experimenting … is who the audience is for that thing. Will everyone be able to use it? Not if it’s, say, a tool confined to a corporate intranet. Do we then need to worry about sub-3G network users? No, probably not. What about if we’re building on the open web but we’re building a product that is expressly for transferring or manipulating HD video files? Do we need to worry about slow networks then? … Context, as usual, is everything.</p>
</blockquote>

<p>In other words, <em>it depends</em>, which is what we’ve all been saying all along.</p>

<p>I’ll leave you with these facts:</p>

<ul>
  <li>Progressive enhancement has many benefits, not the least of which are resilience and reach.</li>
  <li>You don’t have to like or even use progressive enhancement, but that doesn’t detract from its usefulness.</li>
  <li>If you ascribe to progressive enhancement, you may have a project (or several) that aren’t really good candidates for it (e.g., online photo editing software).</li>
  <li>JavaScript is a crucial part of the progressive enhancement toolbox.</li>
  <li>JavaScript availability is never guaranteed, so it’s important to consider offering fallbacks for critical tasks.</li>
  <li>Progressive enhancement is neither moral nor amoral, it’s just a smart way to build for the Web.</li>
</ul>

<p>Is progressive enhancement necessary to use on every project?</p>

<p><em>No.</em></p>

<p>Would users benefit from progressive enhancement if it was followed on more sites than it is now?</p>

<p><em>Heck yeah.</em></p>

<p>Is progressive enhancement right for your project?</p>

<p><em>It depends.</em></p>

<hr />

<p><em>My sincere thanks to <a href="https://sarasoueidan.com/">Sara Soueidan</a>, <a href="https://www.baldurbjarnason.com/">Baldur Bjarnasun</a>, <a href="https://sixtwothree.org/">Jason Garber</a>, and <a href="https://timkadlec.com/">Tim Kadlec</a> for taking the time give me feedback on this piece.</em></p>
<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>Of course, last I checked, over 55% of the Web was in English and just shy of 12% of the world speaks English, so… <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[One Person’s Bloat…]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/one-persons-bloat-dot-dot-dot/"/>
    <updated>2016-10-25T15:15:01-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/one-persons-bloat-dot-dot-dot</id>
    <content type="html"><![CDATA[<figure id="fig-2016-10-25-1" class="media-container">{% adaptive_image /i/posts/2016-10-25/webbloatscore.png %}</figure>

<p>The <a href="http://www.webbloatscore.com/">Web Bloat Score Calculator</a> has been making the rounds on Twitter and I wanted to share my immediate thoughts on it.</p>

<!-- more -->

<p>First off, I am a big fan of simple tools that provide an often much-needed reality check on a project. Based squarely on its simplicity, I’d put this tool right up there alongside <a href="https://www.webpagetest.org/">WebPageTest</a> and <a href="https://whatdoesmysitecost.com/">What Does My Site Cost?</a>. The Web Bloat Score (or WebBS… clever) Calculator is about as simple an interface as you can get: Enter a URL &amp; hit the “Calculate” button.</p>

<p>When you do this, the service runs two tasks:</p>

<ol>
  <li>Load the URL and all of its assets, calculating a total page weight and chronicling the number of requests required to get there; and</li>
  <li>Generate a static screen capture of the page and then grab its file size.</li>
</ol>

<p>Once it has these two bits of info, it compares the real file size of the tested page against the image version to come up with your WebBS.</p>

<p>I <a href="http://www.webbloatscore.com">ran the calculator against the 10k Apart contest homepage</a> and here are the results:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">URL</th>
      <th style="text-align: left">Page Size</th>
      <th style="text-align: left">Requests</th>
      <th style="text-align: left">Image Size</th>
      <th style="text-align: left">WebBS</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">https://a-k-apart.com/</td>
      <td style="text-align: left">200 <abbr title="kilobytes">kB</abbr></td>
      <td style="text-align: left">49</td>
      <td style="text-align: left">195 <abbr title="kilobytes">kB</abbr></td>
      <td style="text-align: left">1.03</td>
    </tr>
  </tbody>
</table>

<p>Not too bad, considering <a href="http://www.webbloatscore.com/Details/612ea9a9-c548-4e20-99d1-910b449ba2c4">the number of images on the page</a> and the interactivity of the SVG. In the documentation about the tool, they have this to say about a high WebBS:</p>

<blockquote>
  <p>A high WebBS usually indicates unused stuff on the page: JavaScript, CSS, oversized images, etc. Maybe you have a valid reason for that content. But more often than not, it means you can optimize it more.</p>
</blockquote>

<p>I completely agree with the sentiment here: smaller is better and if there’s a huge discrepancy between the file size of an image of your page and the page itself, there <em>may</em> be something not so awesome going on behind the scenes. They reference Amazon as being particularly bad, with a WebBS of 20 (<a href="http://www.webbloatscore.com/Details/4abea720-677c-48f6-9ff2-2b816424be06">I got 12.3 in my test</a>, but Amazon frequently changes their homepage).</p>

<p>There’s always room for improvement when it comes to optimization, but I also worry about folks getting too hung up on numbers like this, especially striving for a score of 1 or less. Here are a few legitimate reasons your score may be more than 1:</p>

<ul>
  <li><strong>Your page is heavily interactive.</strong> The calculator does not take into account any sort of interactivity—progressively enhanced or not—nor does it tell you how well-optimized your JavaScript code is. There’s also the possibility that you’ve consciously decided to trade verbosity for speed. For large loops, for instance, <a href="https://en.wikipedia.org/wiki/Duff%27s_device">Duff’s device</a> is much faster but a lot more verbose than a normal <code>for</code> loop.</li>
  <li><strong>Your page serves alternate file formats.</strong> The tool runs <a href="http://slimerjs.org/">SlimerJS</a> to collect the performance data and, for instance, it doesn’t currently support WebP images. We serve WebP with a JPG or PNG fallback on the 10k Apart site (using <code>picture</code>), but <a href="http://www.webbloatscore.com/Details/612ea9a9-c548-4e20-99d1-910b449ba2c4">the file log</a> doesn’t include the WebP images at all.</li>
  <li><strong>You make use of micro-optimizations.</strong> Perhaps you use <a href="https://github.com/filamentgroup/loadCSS"><code>loadCSS</code></a> or <a href="https://github.com/filamentgroup/loadJS"><code>loadJS</code></a> or split your CSS into a default and advanced stylesheet (with the advanced one only loading if media queries are supported). Perhaps you lazy load images or fonts via JavaScript. Perhaps you only load certain assets or scripts based on browser capabilities. The calculator takes none of this into account.</li>
</ul>

<p>These are just three reasons to take your WebBS with a grain of salt. It’s good for a gut-check, but I wouldn’t spend a whole lot of time worrying about getting your score at or below 1.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Progressive Misconceptions]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/progressive-misconceptions/"/>
    <updated>2016-10-17T15:33:55-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/progressive-misconceptions</id>
    <content type="html"><![CDATA[<p>Last week, my colleague<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup> <a href="https://nolanlawson.com/">Nolan Lawson</a> wrote <a href="https://nolanlawson.com/2016/10/13/progressive-enhancement-isnt-dead-but-it-smells-funny/">a lengthy post about his struggles with progressive enhancement</a>. In it, he identified a key tension between the JavaScript community and the progressive enhancement community that has, frankly, existed since the term “progressive enhancement” was coined some 13 years ago. I wanted to take a few minutes to tuck into that tension and assure Nolan and other folks within the JS community that neither progressive enhancement nor the folks who advocate it (like me) is at odds with them or their work.</p>

<!-- more -->

<p>But first let’s take a a trip back in time to 2003. In March of that year, <a href="http://hesketh.com/publications/inclusive_web_design_for_the_future.html">Steve Champion introduced a concept he called “progressive enhancement”</a>. It caused a bit of an upheaval at the time because it challenged the dominant philosophy of graceful degradation. Just so we’re all on the same page, I’ll compare these two philosophies.</p>

<h2 id="whats-graceful-degradation">What’s graceful degradation?</h2>

<p><em>Graceful degradation</em> assumes that an experience is going to be worse on older, less capable browsers and devices. To address potential problems, it recommends that developers take steps to avoid throwing errors—JavaScript or otherwise—for their users. Under this philosophy, a developer can take a range of approaches ranging from making everything work perfectly in down-level browsers to only addressing egregious errors or even chosing to block certain browsers from accessing the content if they are known to have problems. We saw this latter approach often with Flash-only sites, but it wasn’t limited to them. I used <a href="#2016-10-17-1">this “roadblock” example from Kodak.com</a> in <a href="http://adaptivewebdesign.info/">my book</a>:</p>

<figure id="fig-2016-10-17-1" class="media-container">{% adaptive_image /i/posts/2016-10-17/kodak-roadblock.png %}</figure>

<p>Overall, graceful degradation is about risk avoidance. The problem was that it created a climate on the Web where we, as developers, got comfortable with the idea of denying access to services (e.g., people’s bank accounts) because we deemed a particular browser (or browsers) too difficult to work with. Or, in many cases, we just didn’t have the time or budget (or both) to address the broadest number of browsers. It’s kind of hard to reconcile the challenge of cross-browser development in 2003 with what we are faced with today as we were only really dealing with 2-3 browsers back then, but you need to remember that standards support was far worse at the time.</p>

<h2 id="so-whats-progressive-enhancement">So what’s progressive enhancement?</h2>

<p>In his talk, Steve upended the generally shared perspective that older browsers deserved a worse experience because they were less technically capable. He asked us to look beyond the browsers and the technologies in play and focus on the user experience, challenging us to design inclusive experiences that would work in the broadest of scenarios. He asked that we focus on the content and core tasks in a given interface and then enhance the experience when we could. We accomplish this by layering experiences on top of one another, hence “progressive enhancement”.</p>

<p>What’s particularly interesting about this approach is that it is still technically graceful degradation because all of the interfaces do gracefully fall back to a usable state. But it’s graceful degradation at its best, focused on delivering a good experience to everyone. No excuses.</p>

<p>To give a simple example, consider a form field for entering your email address. If we were to mark it up like this</p>

<pre><code>&lt;input type="email" name="email" id="email"&gt;
</code></pre>

<p>I automatically create layers of experience with no extra effort:</p>

<ol>
<li>Browsers that don’t understand “email” as a valid <code>input</code> type will treat the “email” text as a typo in my HTML (like when you type “rdio” instead of “radio”… or maybe I’m the only one that does that). As a result, they will fall back to the default input type of “text”, which is usable in every browser that supports HTML2 and up.</li>
<li>Browsers that consider “email” a valid <code>input</code> type will provide one (or more) of many potential enhanced experiences:
<ol type="a">
<li>In a virtual keyboard context, the browser may present a keyboard that is tailored toward quickly entering email addresses.</li>
<li>In a browser that supports auto-completion, it may use this as a cue to suggest entering a commonly-entered email or one that has been stored in the user’s profile.</li>
<li>In a browser that supports HTML5 validation, the browser may validate this field for proper email formatting when the user attempts to submit the form.</li>
<li>In a browser that does not support HTML5 validation or that doesn’t actively block submission on validation errors—<a href="https://bugs.webkit.org/show_bug.cgi?id=28649">like Safari</a>—a developer-supplied JavaScript program may use the <code>type</code> attribute as a signal that it should validate the field for proper email address formatting.</li>
</ol>
</li>
</ol>

<p>That means that there are between 5 and 13 potential experiences (given all of the different possible combinations of these layers) in this one single single element… it’s kind of mind-boggling to think about, right? And the clincher here is that any of these experiences can be a good experience. Heck for nearly 15 years of the Web, the plain-ol’ text <code>input</code> was the only way we had for entering an email address. Anything better than that is gravy.</p>

<p>Progressive enhancement embraces the idea of experience as a continuum rather than some singular ideal. It recognizes that every person is different and we all have special requirements for Web access. Some may depend on our browser, the device we’re on, and the network we are using. Others may be the result of a limitation we have dealt with since birth, are dealing with temporarily as the result of an injury or incident, or are simply a factor of our current situation. We all experience the world differently and progressive enhancement not only respects that, it embraces that variability.</p>

<p>How does it do this? Progressive enhancement takes advantage of the fault tolerant nature of HTML and CSS. It also uses JavaScript’s own ability to test for browser features to tailor programmatic enhancements to the given device and situation. That’s right: progressive enhancement and JavaScript go hand-in-hand.</p>

<h2 id="why-are-so-many-javascript-folks-hostile-to-progressive-enhancement">Why are so many JavaScript folks hostile to progressive enhancement?</h2>

<p>As a member of the JavaScript community for over a decade now, I have theory for why many JavaScript developers are so antagonistic toward progressive enhancement. Part of it has to do with history and part of it has to do with programming culture. Let’s tackle the history first.</p>

<p>When progressive enhancement was first proposed, the Web was getting more standardized, but things were still a bit of a mess… especially in the JavaScript world. Many JavaScript programs were poorly-written, contained lots of browser-specific code, and were generally unfriendly to anyone who fell outside of the relatively narrow band of “normal” Web use… like screen reader users, for example. It’s not surprising though: Graceful degradation was the name of the game at the time.</p>

<p>Because JavaScript programs were creating barriers for users who just wanted to read news articles, access public services, and check their bank accounts, many accessibility advocates recommended that these folks disable JavaScript in their browsers. By turning off JavaScript, the theory went, users would get clean and clear access to the content and tasks they were using the Web for. Of course that was in the days before Ajax, but I digress.</p>

<p>This recommendation served as a bit of a wake-up call for many JavaScript developers who had not considered alternate browsing experiences. Some chose to write it off and continued doing their own thing. Others, however, accepted the challenge of making JavaScript more friendly to the folks who relied on assistive technologies (AT). Many even went on to write code that actually improved the experience specifically for folks who are AT-dependent. Dojo and YUI, though sadly out of favor these days, were two massive libraries that prioritized accessibility. In fact, I’d go so far as to say they ushered in a period of alignment between JavaScript and accessibility.</p>

<p>Even though JavaScript and accessibility are no longer at odds (and really haven’t been for the better part of a decade), there are still some folks who believe they are. People routinely come across old articles that talk about JavaScript being inaccessible and they turn around and unfairly demonize JavaScript developers as unsympathetic toward folks who rely on screen readers or other AT. It’s no wonder that some JavaScript developers become immediately defensive when the subject of accessibility comes up… especially if it’s not something they’re all that familiar with.</p>

<hr />

<p>I also mentioned that programming culture plays a part in the antagonistic relationship between the progressive enhancement camp and the JavaScript community. If you’ve been a programmer for any amount of time, you’ve probably borne witness to the constant finger-pointing, belittling, and arrogance when it come to the languages we choose to program in or the tools we use to do it.</p>

<p>As a programmer, you receive a near constant barrage of commentary on your choices… often unsolicited. <em>You’re using PHP? That’s so 1996! You’re still using TextMate?! You still use jQuery? How quaint!</em> I’m not exactly sure where this all began, but it’s unhealthy and causes a lot of programmers to get immediately defensive when anyone challenges their language of choice or their process. And this hostile/defensive environment makes it very difficult to have a constructive conversation about best practices.</p>

<p>Progressive enhancement should not be viewed as a challenge to JavaScript any more than concepts like <a href="https://www.safaribooksonline.com/library/view/learning-javascript-design/9781449334840/ch13s15.html">namespacing</a>, <a href="https://en.wikipedia.org/wiki/Test-driven_development">test driven development</a>, or <a href="http://www.yottaa.com/company/blog/application-optimization/how-does-reducing-javascript-requests-minifying-javascript/">file concatenation &amp; minification</a> are; it’s just another way to improve your code. That said, progressive enhancement does introduce a wrinkle many for hardcore JavaScript programmers seem unwilling to concede: JavaScript is fragile. At least on the client side, JavaScript development requires far more diligence when it comes to error handling and fallbacks than traditional programming because, unlike with traditional software development, <a href="https://www.aaron-gustafson.com/notebook/a-fundamental-disconnect/">we don’t control the execution environment</a>.</p>

<p><a href="http://www.crockford.com/">Douglas Crockford</a> (in)famously declared the Web “the most hostile software engineering environment imaginable” and he wasn’t wrong. A lot of things have to go right for our code to reach our users precisely the way we intend. Here are just a few of these requirements:</p>

<ol>
  <li>Our code must be bug-free;</li>
  <li>Included 3rd party code must be bug free and must not interfere with our code;</li>
  <li>Intermediaries—ISPs, routers, etc.—must not inject code or if they do, it must be bug free and not interfere with our code;</li>
  <li>Browser plugins must not interfere with our code;</li>
  <li>The browser must support every language feature and API we want to use; and</li>
  <li>The device must have enough RAM and a fast enough processor to run our code.</li>
</ol>

<p>Some of these can be addressed by programming defensively using test-driven development, <a href="http://www.slideshare.net/simonguest/automated-web-testing-using-javascript">automated QA testing</a>, <a href="https://developer.mozilla.org/docs/Using_Web_Standards_in_your_Web_Pages/Developing_cross-browser_and_cross-platform_pages#Using_Object.2FFeature_support_detection_approach:_best_and_overall_most_reliable">feature detection</a>, and markup detection. These aren’t guaranteed to catch everything—markup can change after a test has run but before the rest of the code executed, <a href="http://javascriptissexy.com/javascript-objects-in-detail/">JavaScript objects are mutable</a> meaning features can accidentally disappear, etc.—but they are incredibly helpful for creating robust JavaScript programs. You can also run your projects under HTTPS to avoid intermediaries manipulating your code, though <a href="http://arstechnica.com/security/2015/01/gogo-issues-fake-https-certificate-to-users-visiting-youtube/">that’s not fool-proof either</a>.</p>

<p>The devices themselves, we have no control over. It’s not like we can send a new device to each and every user (or prospective user) we have just to ensure they have the appropriate hardware and software requirements to use our product.<sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup> Instead, we need to <a href="https://www.smashingmagazine.com/2012/11/writing-fast-memory-efficient-javascript/">write JavaScript programs that play well in a multitude of of scenarios (including resource-limited ones)</a>.</p>

<p>And, of course, none of this addresses network availability. In many instances, a user’s network connection has the greatest impact on their experience of our products. If the connection is slow (or the page’s resources are exceptionally large) the page load experience can be excruciatingly painful. If the connection goes down and dependencies aren’t met, the experience can feel disjointed or may be flat out broken. Using <a href="https://developer.mozilla.org/docs/Web/API/Service_Worker_API">Service Worker</a> and client-side storage (<a href="https://developer.mozilla.org/docs/Web/API/IndexedDB_API"><code>indexedDB</code></a> and <a href="https://developer.mozilla.org/docs/Web/API/Web_Storage_API">Web Storage</a>) can definitely help mitigate these issues for repeat visits, but they don’t do much to help with initial load. They also don’t work at all if your JavaScript program doesn’t run. Which brings me to my last point.</p>

<p>When you love a language like JavaScript (as I do), it can be difficult to recognize (or even admit) it’s shortcomings, but recognizing them is part of becoming a better programmer. The Web is constantly evolving and our understanding of the languages we use to build it expands as fast as—or often faster than—their capabilities do. As such, we need to remain open to new and different ways of doing things. Change can be scary, but it can also be good. Being asked to consider a non-JavaScript experience shouldn’t be seen as an affront to JavaScript, but rather a challenge to create more robust experiences. After all, our last line of defense in providing a good user experience is providing one with <a href="https://www.smashingmagazine.com/2016/05/developing-dependency-awareness/">the least number of dependencies</a>. That’s what progressive enhancements asks us to do.</p>

<h2 id="javascript--pe-kissing-in-a-tree">JavaScript &amp; PE kissing in a tree?</h2>

<p>All of this is to say I don’t think JavaScript and progressive enhancement are diametrically opposed and I don’t think folks who love the JavaScript language or tout the progressive enhancement philosophy should be either. Together they have the potential to making the Web the best it can possibly be.</p>

<p>Progressive enhancement’s focus on providing a baseline experience that makes no assumptions about browser features will provide a robust foundation for any project. It also guides us to be smarter about <em>how</em> we apply technologies like HTML, CSS, JavaScript and ARIA by asking us to consider what happens when those dependencies aren’t met.</p>

<p>JavaScript absolutely makes the user experience better for anyone who can benefit from it. It can make interfaces more accessible. It can help mitigate networking issues. It can create smoother, more seamless experiences for our users. And it can reduce the friction inherent in accomplishing most tasks on the Web. JavaScript is an indispensable part of the modern Web.</p>

<p>In order to come together, however, folks <a href="https://www.baldurbjarnason.com/notes/debating-web-development/">need to stop demonizing and dismissing one another</a>. Instead we need to rally together to make the Web better. But before we can do that, we need to start with a common understanding of the nature of JavaScript. The progressive enhancement camp needs to concede that all JavaScript is not evil, or even bad—JavaScript can be a force for good and it’s got really solid support. The JavaScript camp needs to concede that, despite its ubiquity and near universal support, we can never be absolutely guaranteed our JavaScript programs will run.</p>

<p>I fully believe we can heal this rift, but it’s probably gonna take some time. I fully intend to do my part and I hope you will as well.</p>

<p><ins datetime="2016-10-18T11:11:00-04:00"><strong>Update:</strong> This post was updated to clarify that graceful degradation can take many forms and to explicitly tie progressive enhancement and graceful degradation together.</ins></p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>Full disclosure: We both work at Microsoft, but on different teams. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>It’s worth noting that <a href="http://gizmodo.com/website-opts-to-buy-customers-new-computers-rather-than-1513186669">one company, NursingJobs, actually did this</a>. <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What Would You Do With 10kB?]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/what-would-you-do-with-10kb/"/>
    <updated>2016-08-17T14:48:27-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/what-would-you-do-with-10kb</id>
    <content type="html"><![CDATA[<p>Sixteen years ago, <a href="https://twitter.com/stewart">Stewart Butterfield</a> conceived of a contest that would test the mettle of any web designer: <a href="http://web.archive.org/web/20000510010054/http:/www.sylloge.com/5k/home.html">The 5k</a>. The idea was that entrants would build <a href="http://alistapart.com/article/5k">an entire site in 5kB of code or less</a>. Its aim was to force us to get creative by putting a bounding box on what we could do:</p>

<blockquote>
  <p>Between servers and bandwidth, clients and users, HTML and the DOM, browsers and platforms, our conscience and our ego, we’re left in a very small space to find highly optimal solutions. Since the space we have to explore is so small, we have to look harder, get more creative; and that’s what makes it all interesting.</p>
</blockquote>

<!-- more -->

<p>The 5k contest ran from 2000 until 2002. In 2010, <a href="http://www.zeldman.com/2010/07/29/10k-apart-%E2%80%93%C2%A0inspire-the-web/">An Event Apart and Microsoft revived the idea</a> with an updated limit and a new name: <a href="http://web.archive.org/web/20100730090946/http:/10k.aneventapart.com/">10k Apart</a>. Staying true to its roots, this new incarnation, which ran for two years, continued to push designers and developers to get creative within a pretty extreme (though slightly expanded) limit while incorporating new goodies like HTML5 and responsive design.</p>

<p>I’m thrilled to announce that <a href="https://a-k-apart.com/">the 10k Apart contest is back</a> and brings with it a handful of new challenges:</p>

<ol>
  <li><strong>Each page must be usable in 10kB or less.</strong> The 10kB limit no longer applies to the size of a ZIP archive of your entry; the 10kB limit now applies to the total initial download size of the baseline experience of each page in your project. When we say “baseline experience,” we’re talking small screen devices running older, less capable browsers. The 10kB limit will apply to every page and whatever assets it loads by default; that means images, CSS, JavaScript, and so on.</li>
  <li><strong>Progressive enhancement is the name of the game.</strong> Your project should start with a super-basic, bare-bones-but-usable experience that will work no matter what (including without JavaScript). You can use clever CSS and JavaScript techniques to enhance that experience as it makes sense to do so. For example: You might lazy load an image using JavaScript if the screen size is above a certain threshold or when certain other conditions are met. Entries that depend entirely on JavaScript to render the front-end won’t be accepted. If you need a primer on progressive enhancement, <a href="http://alistapart.com/search?keywords=progressive%20enhancement">consult the pages of <cite>A List Apart</cite></a>.</li>
  <li><strong>Back ends are in this year.</strong> In previous iterations, each entry comprised client-side code submitted via ZIP file. Over time, that limitation led to an over-reliance on JavaScript for rendering. No more. This year, you can create dynamic experiences that work without front-end JavaScript using Node, PHP, Python or .Net. You will submit your entry as public GitHub repository (so we can all learn from your awesome code) and we’ll spin up a dedicated <a href="https://azure.microsoft.com/">Azure</a> instance running the appropriate stack.</li>
  <li><strong>Entries should be accessible.</strong> In line with the philosophy of progressive enhancement, your entry should be usable by the broadest number of users possible. <a href="http://www.accessiq.org/news/commentary/2012/09/web-accessibility-is-a-mindset-not-a-checklist">Accessibility is not a checklist</a>, but if you’re clueless about where to start, <a href="https://www.w3.org/TR/WCAG20-TECHS/">these techniques</a> can offer some guidance.</li>
  <li><strong>Nothing comes for free.</strong> In previous years, we gave a pass if you wanted to use jQuery or load some fonts from Typekit. This year we decided to change it up, not because we don’t love these products (we do), but because we wanted to force every piece of code, every asset, to fight for its place in your entry. Anything you add should be added with purpose.</li>
</ol>

<p>As with previous editions, your entry should use web standards and work in all modern browsers. You can use HTML, CSS, and JavaScript features and APIs that don’t have across-the-board support as long as you do so in keeping with the progressive enhancement philosophy. In other words, your entry can’t depend on that technology or feature in order to be usable.</p>

<p>All of this may sound like a tall order, but it’s entirely possible. In fact, the site we built for the contest also abides by these rules. My colleagues and I will touch on some of the techniques we used (and concessions we made) in building the site in future posts.</p>

<p>If you’ve read this far, you might be wondering <em>What’s in it for me?</em> Well, bragging rights, of course, but we’ve got some awesome prizes too! We’re giving away $10,000 to the top three entries, plus <a href="http://aneventapart.com/events">tickets to An Event Apart</a>, complete collections of <a href="https://abookapart.com/collections/standards-collection">A Book Apart titles</a>, and copies of <a href="http://adaptivewebdesign.info/2nd-edition/">my book</a> too. <a href="https://a-k-apart.com/#prizes">Complete details of the prizes</a> are over on <a href="https://a-k-apart.com/">the contest site</a>.</p>

<p>We’ve lined up an amazing group to judge the entires this year too: <a href="https://twitter.com/rachelandrew">Rachel Andrew</a>, <a href="https://twitter.com/lara_hogan">Lara Hogan</a>, <a href="https://twitter.com/wilto">Mat Marquis</a>, <a href="https://twitter.com/Heydonworks">Heydon Pickering</a>, <a href="https://twitter.com/jensimmons">Jen Simmons</a>, and <a href="https://twitter.com/SaraSoueidan">Sara Soueidan</a> will all be putting your entry through its paces and peering under the hood at your code. There’s also a People’s Choice award which will be based on votes you cast. Voting will open October 1st and run through October 14th.</p>

<p>The contest opened Monday and we will accept entries until 5pm Pacific Time on September 30th. <a href="https://a-k-apart.com/legal">Everything you should need to know about the contest, eligibility, etc.</a> is up on <a href="https://a-k-apart.com/">the 10k Apart site</a>, but if you have additional questions, <a href="https://a-k-apart.com/hi">you can always reach out</a>.</p>

<p>I can’t wait to see what you come up with! Happy coding!</p>
]]></content>
  </entry>
  
</feed>
