<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Browse by Tag: Javascript | Aaron Gustafson]]></title>
  <link href="https://www.aaron-gustafson.com/notebook/tags/javascript/atom.xml" rel="self"/>
  <link href="https://www.aaron-gustafson.com/"/>
  <updated>2016-12-06T16:38:51-05:00</updated>
  <id>https://www.aaron-gustafson.com/</id>
  <author>
    <name><![CDATA[Aaron Gustafson]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Progressive Misconceptions]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/progressive-misconceptions/"/>
    <updated>2016-10-17T15:33:55-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/progressive-misconceptions</id>
    <content type="html"><![CDATA[<p>Last week, my colleague<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup> <a href="https://nolanlawson.com/">Nolan Lawson</a> wrote <a href="https://nolanlawson.com/2016/10/13/progressive-enhancement-isnt-dead-but-it-smells-funny/">a lengthy post about his struggles with progressive enhancement</a>. In it, he identified a key tension between the JavaScript community and the progressive enhancement community that has, frankly, existed since the term “progressive enhancement” was coined some 13 years ago. I wanted to take a few minutes to tuck into that tension and assure Nolan and other folks within the JS community that neither progressive enhancement nor the folks who advocate it (like me) is at odds with them or their work.</p>

<!-- more -->

<p>But first let’s take a a trip back in time to 2003. In March of that year, <a href="http://hesketh.com/publications/inclusive_web_design_for_the_future.html">Steve Champion introduced a concept he called “progressive enhancement”</a>. It caused a bit of an upheaval at the time because it challenged the dominant philosophy of graceful degradation. Just so we’re all on the same page, I’ll compare these two philosophies.</p>

<h2 id="whats-graceful-degradation">What’s graceful degradation?</h2>

<p><em>Graceful degradation</em> assumes that an experience is going to be worse on older, less capable browsers and devices. To address potential problems, it recommends that developers take steps to avoid throwing errors—JavaScript or otherwise—for their users. Under this philosophy, a developer can take a range of approaches ranging from making everything work perfectly in down-level browsers to only addressing egregious errors or even chosing to block certain browsers from accessing the content if they are known to have problems. We saw this latter approach often with Flash-only sites, but it wasn’t limited to them. I used <a href="#2016-10-17-1">this “roadblock” example from Kodak.com</a> in <a href="http://adaptivewebdesign.info/">my book</a>:</p>

<figure id="fig-2016-10-17-1" class="media-container">{% adaptive_image /i/posts/2016-10-17/kodak-roadblock.png %}</figure>

<p>Overall, graceful degradation is about risk avoidance. The problem was that it created a climate on the Web where we, as developers, got comfortable with the idea of denying access to services (e.g., people’s bank accounts) because we deemed a particular browser (or browsers) too difficult to work with. Or, in many cases, we just didn’t have the time or budget (or both) to address the broadest number of browsers. It’s kind of hard to reconcile the challenge of cross-browser development in 2003 with what we are faced with today as we were only really dealing with 2-3 browsers back then, but you need to remember that standards support was far worse at the time.</p>

<h2 id="so-whats-progressive-enhancement">So what’s progressive enhancement?</h2>

<p>In his talk, Steve upended the generally shared perspective that older browsers deserved a worse experience because they were less technically capable. He asked us to look beyond the browsers and the technologies in play and focus on the user experience, challenging us to design inclusive experiences that would work in the broadest of scenarios. He asked that we focus on the content and core tasks in a given interface and then enhance the experience when we could. We accomplish this by layering experiences on top of one another, hence “progressive enhancement”.</p>

<p>What’s particularly interesting about this approach is that it is still technically graceful degradation because all of the interfaces do gracefully fall back to a usable state. But it’s graceful degradation at its best, focused on delivering a good experience to everyone. No excuses.</p>

<p>To give a simple example, consider a form field for entering your email address. If we were to mark it up like this</p>

<pre><code>&lt;input type="email" name="email" id="email"&gt;
</code></pre>

<p>I automatically create layers of experience with no extra effort:</p>

<ol>
<li>Browsers that don’t understand “email” as a valid <code>input</code> type will treat the “email” text as a typo in my HTML (like when you type “rdio” instead of “radio”… or maybe I’m the only one that does that). As a result, they will fall back to the default input type of “text”, which is usable in every browser that supports HTML2 and up.</li>
<li>Browsers that consider “email” a valid <code>input</code> type will provide one (or more) of many potential enhanced experiences:
<ol type="a">
<li>In a virtual keyboard context, the browser may present a keyboard that is tailored toward quickly entering email addresses.</li>
<li>In a browser that supports auto-completion, it may use this as a cue to suggest entering a commonly-entered email or one that has been stored in the user’s profile.</li>
<li>In a browser that supports HTML5 validation, the browser may validate this field for proper email formatting when the user attempts to submit the form.</li>
<li>In a browser that does not support HTML5 validation or that doesn’t actively block submission on validation errors—<a href="https://bugs.webkit.org/show_bug.cgi?id=28649">like Safari</a>—a developer-supplied JavaScript program may use the <code>type</code> attribute as a signal that it should validate the field for proper email address formatting.</li>
</ol>
</li>
</ol>

<p>That means that there are between 5 and 13 potential experiences (given all of the different possible combinations of these layers) in this one single single element… it’s kind of mind-boggling to think about, right? And the clincher here is that any of these experiences can be a good experience. Heck for nearly 15 years of the Web, the plain-ol’ text <code>input</code> was the only way we had for entering an email address. Anything better than that is gravy.</p>

<p>Progressive enhancement embraces the idea of experience as a continuum rather than some singular ideal. It recognizes that every person is different and we all have special requirements for Web access. Some may depend on our browser, the device we’re on, and the network we are using. Others may be the result of a limitation we have dealt with since birth, are dealing with temporarily as the result of an injury or incident, or are simply a factor of our current situation. We all experience the world differently and progressive enhancement not only respects that, it embraces that variability.</p>

<p>How does it do this? Progressive enhancement takes advantage of the fault tolerant nature of HTML and CSS. It also uses JavaScript’s own ability to test for browser features to tailor programmatic enhancements to the given device and situation. That’s right: progressive enhancement and JavaScript go hand-in-hand.</p>

<h2 id="why-are-so-many-javascript-folks-hostile-to-progressive-enhancement">Why are so many JavaScript folks hostile to progressive enhancement?</h2>

<p>As a member of the JavaScript community for over a decade now, I have theory for why many JavaScript developers are so antagonistic toward progressive enhancement. Part of it has to do with history and part of it has to do with programming culture. Let’s tackle the history first.</p>

<p>When progressive enhancement was first proposed, the Web was getting more standardized, but things were still a bit of a mess… especially in the JavaScript world. Many JavaScript programs were poorly-written, contained lots of browser-specific code, and were generally unfriendly to anyone who fell outside of the relatively narrow band of “normal” Web use… like screen reader users, for example. It’s not surprising though: Graceful degradation was the name of the game at the time.</p>

<p>Because JavaScript programs were creating barriers for users who just wanted to read news articles, access public services, and check their bank accounts, many accessibility advocates recommended that these folks disable JavaScript in their browsers. By turning off JavaScript, the theory went, users would get clean and clear access to the content and tasks they were using the Web for. Of course that was in the days before Ajax, but I digress.</p>

<p>This recommendation served as a bit of a wake-up call for many JavaScript developers who had not considered alternate browsing experiences. Some chose to write it off and continued doing their own thing. Others, however, accepted the challenge of making JavaScript more friendly to the folks who relied on assistive technologies (AT). Many even went on to write code that actually improved the experience specifically for folks who are AT-dependent. Dojo and YUI, though sadly out of favor these days, were two massive libraries that prioritized accessibility. In fact, I’d go so far as to say they ushered in a period of alignment between JavaScript and accessibility.</p>

<p>Even though JavaScript and accessibility are no longer at odds (and really haven’t been for the better part of a decade), there are still some folks who believe they are. People routinely come across old articles that talk about JavaScript being inaccessible and they turn around and unfairly demonize JavaScript developers as unsympathetic toward folks who rely on screen readers or other AT. It’s no wonder that some JavaScript developers become immediately defensive when the subject of accessibility comes up… especially if it’s not something they’re all that familiar with.</p>

<hr />

<p>I also mentioned that programming culture plays a part in the antagonistic relationship between the progressive enhancement camp and the JavaScript community. If you’ve been a programmer for any amount of time, you’ve probably borne witness to the constant finger-pointing, belittling, and arrogance when it come to the languages we choose to program in or the tools we use to do it.</p>

<p>As a programmer, you receive a near constant barrage of commentary on your choices… often unsolicited. <em>You’re using PHP? That’s so 1996! You’re still using TextMate?! You still use jQuery? How quaint!</em> I’m not exactly sure where this all began, but it’s unhealthy and causes a lot of programmers to get immediately defensive when anyone challenges their language of choice or their process. And this hostile/defensive environment makes it very difficult to have a constructive conversation about best practices.</p>

<p>Progressive enhancement should not be viewed as a challenge to JavaScript any more than concepts like <a href="https://www.safaribooksonline.com/library/view/learning-javascript-design/9781449334840/ch13s15.html">namespacing</a>, <a href="https://en.wikipedia.org/wiki/Test-driven_development">test driven development</a>, or <a href="http://www.yottaa.com/company/blog/application-optimization/how-does-reducing-javascript-requests-minifying-javascript/">file concatenation &amp; minification</a> are; it’s just another way to improve your code. That said, progressive enhancement does introduce a wrinkle many for hardcore JavaScript programmers seem unwilling to concede: JavaScript is fragile. At least on the client side, JavaScript development requires far more diligence when it comes to error handling and fallbacks than traditional programming because, unlike with traditional software development, <a href="https://www.aaron-gustafson.com/notebook/a-fundamental-disconnect/">we don’t control the execution environment</a>.</p>

<p><a href="http://www.crockford.com/">Douglas Crockford</a> (in)famously declared the Web “the most hostile software engineering environment imaginable” and he wasn’t wrong. A lot of things have to go right for our code to reach our users precisely the way we intend. Here are just a few of these requirements:</p>

<ol>
  <li>Our code must be bug-free;</li>
  <li>Included 3rd party code must be bug free and must not interfere with our code;</li>
  <li>Intermediaries—ISPs, routers, etc.—must not inject code or if they do, it must be bug free and not interfere with our code;</li>
  <li>Browser plugins must not interfere with our code;</li>
  <li>The browser must support every language feature and API we want to use; and</li>
  <li>The device must have enough RAM and a fast enough processor to run our code.</li>
</ol>

<p>Some of these can be addressed by programming defensively using test-driven development, <a href="http://www.slideshare.net/simonguest/automated-web-testing-using-javascript">automated QA testing</a>, <a href="https://developer.mozilla.org/docs/Using_Web_Standards_in_your_Web_Pages/Developing_cross-browser_and_cross-platform_pages#Using_Object.2FFeature_support_detection_approach:_best_and_overall_most_reliable">feature detection</a>, and markup detection. These aren’t guaranteed to catch everything—markup can change after a test has run but before the rest of the code executed, <a href="http://javascriptissexy.com/javascript-objects-in-detail/">JavaScript objects are mutable</a> meaning features can accidentally disappear, etc.—but they are incredibly helpful for creating robust JavaScript programs. You can also run your projects under HTTPS to avoid intermediaries manipulating your code, though <a href="http://arstechnica.com/security/2015/01/gogo-issues-fake-https-certificate-to-users-visiting-youtube/">that’s not fool-proof either</a>.</p>

<p>The devices themselves, we have no control over. It’s not like we can send a new device to each and every user (or prospective user) we have just to ensure they have the appropriate hardware and software requirements to use our product.<sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup> Instead, we need to <a href="https://www.smashingmagazine.com/2012/11/writing-fast-memory-efficient-javascript/">write JavaScript programs that play well in a multitude of of scenarios (including resource-limited ones)</a>.</p>

<p>And, of course, none of this addresses network availability. In many instances, a user’s network connection has the greatest impact on their experience of our products. If the connection is slow (or the page’s resources are exceptionally large) the page load experience can be excruciatingly painful. If the connection goes down and dependencies aren’t met, the experience can feel disjointed or may be flat out broken. Using <a href="https://developer.mozilla.org/docs/Web/API/Service_Worker_API">Service Worker</a> and client-side storage (<a href="https://developer.mozilla.org/docs/Web/API/IndexedDB_API"><code>indexedDB</code></a> and <a href="https://developer.mozilla.org/docs/Web/API/Web_Storage_API">Web Storage</a>) can definitely help mitigate these issues for repeat visits, but they don’t do much to help with initial load. They also don’t work at all if your JavaScript program doesn’t run. Which brings me to my last point.</p>

<p>When you love a language like JavaScript (as I do), it can be difficult to recognize (or even admit) it’s shortcomings, but recognizing them is part of becoming a better programmer. The Web is constantly evolving and our understanding of the languages we use to build it expands as fast as—or often faster than—their capabilities do. As such, we need to remain open to new and different ways of doing things. Change can be scary, but it can also be good. Being asked to consider a non-JavaScript experience shouldn’t be seen as an affront to JavaScript, but rather a challenge to create more robust experiences. After all, our last line of defense in providing a good user experience is providing one with <a href="https://www.smashingmagazine.com/2016/05/developing-dependency-awareness/">the least number of dependencies</a>. That’s what progressive enhancements asks us to do.</p>

<h2 id="javascript--pe-kissing-in-a-tree">JavaScript &amp; PE kissing in a tree?</h2>

<p>All of this is to say I don’t think JavaScript and progressive enhancement are diametrically opposed and I don’t think folks who love the JavaScript language or tout the progressive enhancement philosophy should be either. Together they have the potential to making the Web the best it can possibly be.</p>

<p>Progressive enhancement’s focus on providing a baseline experience that makes no assumptions about browser features will provide a robust foundation for any project. It also guides us to be smarter about <em>how</em> we apply technologies like HTML, CSS, JavaScript and ARIA by asking us to consider what happens when those dependencies aren’t met.</p>

<p>JavaScript absolutely makes the user experience better for anyone who can benefit from it. It can make interfaces more accessible. It can help mitigate networking issues. It can create smoother, more seamless experiences for our users. And it can reduce the friction inherent in accomplishing most tasks on the Web. JavaScript is an indispensable part of the modern Web.</p>

<p>In order to come together, however, folks <a href="https://www.baldurbjarnason.com/notes/debating-web-development/">need to stop demonizing and dismissing one another</a>. Instead we need to rally together to make the Web better. But before we can do that, we need to start with a common understanding of the nature of JavaScript. The progressive enhancement camp needs to concede that all JavaScript is not evil, or even bad—JavaScript can be a force for good and it’s got really solid support. The JavaScript camp needs to concede that, despite its ubiquity and near universal support, we can never be absolutely guaranteed our JavaScript programs will run.</p>

<p>I fully believe we can heal this rift, but it’s probably gonna take some time. I fully intend to do my part and I hope you will as well.</p>

<p><ins datetime="2016-10-18T11:11:00-04:00"><strong>Update:</strong> This post was updated to clarify that graceful degradation can take many forms and to explicitly tie progressive enhancement and graceful degradation together.</ins></p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>Full disclosure: We both work at Microsoft, but on different teams. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>It’s worth noting that <a href="http://gizmodo.com/website-opts-to-buy-customers-new-computers-rather-than-1513186669">one company, NursingJobs, actually did this</a>. <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[More Proof We Don’t Control Our Web Pages]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/more-proof-we-dont-control-our-web-pages/"/>
    <updated>2015-09-01T11:33:59-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/more-proof-we-dont-control-our-web-pages</id>
    <content type="html"><![CDATA[<p>I’ve talked about this before: As web designers, <a href="http://www.aaron-gustafson.com/notebook/the-network-effect/">we can’t trust the network</a>. Sure, we have to contend with mobile data “dead zones” and dropped connections as our users move about throughout the day, but there’s a lot more to the network that’s beyond our control.</p>

<!-- more -->

<p>Here’s a roundup of some of my “favorite” network issue related headlines from the last few years:</p>

<ul>
  <li><a href="http://www.theguardian.com/technology/2014/jan/28/sky-broadband-blocks-jquery-web-critical-plugin">Sky Broadband misclassified the jQuery CDN as a malware site</a> and broke much of the web for their users.</li>
  <li><a href="http://arstechnica.com/tech-policy/2014/09/why-comcasts-javascript-ad-injections-threaten-security-net-neutrality/">Comcast admitted to injecting self-promotional advertising</a> into web pages served by their Xfinity routers. (They have also been called out for <a href="https://blog.ryankearney.com/2013/01/comcast-caught-intercepting-and-altering-your-web-traffic/">artificially inflating subscriber bandwidth usage with their own crap</a>.)</li>
  <li><a href="http://arstechnica.com/business/2015/08/united-in-flight-wi-fi-reportedly-blocks-ars-technica-and-new-york-times/">United was recently called out for blocking access to the <cite>New York Times</cite></a> on their in-flight Wi-Fi.</li>
  <li><a href="http://webpolicy.org/2015/08/25/att-hotspots-now-with-advertising-injection/">Someone discovered AT&amp;T was injecting CSS, images, and JavaScript into pages</a> served via their airport hotspots.</li>
  <li><a href="http://www.cnet.com/au/news/samsung-smart-tvs-forcing-ads-into-video-streaming-apps/">Samsung smart TVs were found to be injecting video ads</a> into video streaming apps.</li>
  <li><a href="http://pleckey.me/blog/2013/09/11/sprint-mobile-broadband-injecting-3rd-party-javascript/">Sprint injects JavaScript into pages</a> served via its data connections.</li>
  <li><a href="http://www.ecommercetimes.com/story/82117.html">Browser add-ins can inject their own advertisements</a>. They can also alter the DOM, load conflicting versions of JavaScript libraries, and more. Awesome, I know. (This is being addressed, but is a persistent issue when add-ins have the ability to manipulate the DOM.)</li>
</ul>

<p>Some of these issues can be avoided by serving content over HTTPS, but that still won’t enable you to bypass things like firewall blacklists (which led to the jQuery outage on Sky). Your best bet is to design defensively and make sure your users can still accomplish their goals on your site when some resources are missing or markup is altered.</p>

<p>We can’t control what happens to us in this world, we can only control our reaction to it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lies, Damn Lies, and JavaScript]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/lies-damn-lies-and-javascript/"/>
    <updated>2015-04-27T15:10:11-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/lies-damn-lies-and-javascript</id>
    <content type="html"><![CDATA[<p>Late last week I stumbled on a video from <a href="https://twitter.com/graemepyle">Graeme Pyle</a> that exposed a UX lie in the <a href="https://www.fnb.co.za/">First National Bank of South Africa</a>.</p>

<!-- more -->

<p>{% youtube gpBWwl-Ngak %}</p>

<p>On the off chance you don’t want to watch the video, I’ll recap: When accessing certain screens on the FNB site, a progress meter is shown to indicate new content is being flowed into the browser. But it’s not.</p>

<p>As Graeme uncovered, the site uses JavaScript to create the progress bar, but the progress is not tied to anything except some basic JavaScript logic. The progress bar has no grounding in reality. It uses timeouts and follows a steady incrementation for a bit, then jumps up randomly for a bit before finishing.</p>

<p>Taking the easy way out like this may seem like a non-issue, but what happens when your user loses network connectivity? You guessed it: The progress meter still runs. <em>Doh!</em></p>

<p>Tracking true activity progress (like time to upload a file) involves constant communication between the server and the client. It used to be pretty difficult to do (and <a href="http://search.cpan.org/~lgoddard/CGI-ProgressBar-0.05/lib/CGI/ProgressBar.pm">required Perl</a>), but nowadays we have <a href="http://www.w3.org/TR/websockets/">WebSockets</a> and it’s much easier to keep the lines of communication between client and server open.</p>

<p>There is no reason to fake a progress bar. It’s pointless. Especially when you don’t even check to see if the user’s connection is still online.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Apply Progressive Enhancement When JavaScript Seems Like a Requirement]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/how-to-apply-progressive-enhancement-when-javascript-seems-like-a-requirement/"/>
    <updated>2015-04-02T10:14:40-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/how-to-apply-progressive-enhancement-when-javascript-seems-like-a-requirement</id>
    <content type="html"><![CDATA[<p>On Stack Overflow last week, <a href="http://stackoverflow.com/users/4719194/jamham">JamHam</a> asked how to apply progressive enhancement in interfaces that seem to require JavaScript. Unfortunately he deleted the question before I could post my response, so I thought I would post it all here for posterity.</p>

<!-- more -->

<blockquote>
  <p>I’ve been trying to make my site (a content publishing “web app”) work fully without JavaScript, however, I’ve found myself in situations where I can’t honestly think how I would do some features without it.</p>
</blockquote>

<blockquote>
  <p>For instance:</p>
</blockquote>

<blockquote>
  <ul>
    <li>I have a form submission page where you change certain settings, and the form changes accordingly.This is alright, I can apply query strings in the url and have some logic in my layout so that certain fields are shown/hidden according to the query string. The thing is, I also need to update a “price” dynamically, according to what fields are filled in, how they are filled in, and some other factors, and I don’t honestly see how I could do that without JavaScript.</li>
    <li>I have a messaging section where I’m using WebSockets (with the help of Socket.io). The UI of the messaging (and of course, the
WebSockets) stuff pretty much depends on JavaScript, with ‘messages’ being created as they arrive and appended into DOM and also a form that allows you to quickly look up an user via AJAX so you can send a message easily, among many other things.</li>
  </ul>
</blockquote>

<blockquote>
  <p>I mean, I could probably come up with very complicated solutions for each situation, and obviously the functionality wouldn’t be the same. I’m thinking I might as well just require JavaScript for the whole thing</p>
</blockquote>

<blockquote>
  <p>But it kinda sucks, since I’ve been making everything work without JavaScript, up until this point. And I would like some consistency across the whole site. In these kind of situations, is it acceptable to not support non-js clients? What would you suggest in this case?</p>
</blockquote>

<p>My response (which I was drafting when he deleted the question):</p>

<blockquote>
  <p>First off, I applaud your interest in using progressive enhancement. It will ensure the most users possible have access to your content and will also result in a more robust application overall. As a general guiding principle, look to the past. How did we solve these issues before widespread JavaScript availability? Those “Web 1.0” solutions will still work and can be overtaken by supplanted by your JavaScript solution whenever it is possible to do so.</p>
</blockquote>

<blockquote>
  <p>Every situation is different, but it is even possible to reuse a lot of code in both scenarios.</p>
</blockquote>

<blockquote>
  <p>Now to address your interfaces…</p>
</blockquote>

<blockquote>
  <p><strong>Your Submission Page</strong> - I could be wrong, but this sounds like a shopping cart to me (at least in essence). You are on the right track with query parameters, but you could also store info about the cart (and the user’s capabilities) in a session or cookie.</p>
</blockquote>

<blockquote>
  <p>In terms of updating the “cart”, a simple “update” submit button that posts the form and triggers a redirection back to this page with the updated info would be sufficient. And if you need to show or hide fields based on choices made, you simply apply that logic on the server side. You could even have the server generate that same markup into the page, but hidden for situations where JavaScript is available.</p>
</blockquote>

<blockquote>
  <p><strong>Your Messaging App</strong> - This can seem like a daunting challenge, but before we had web sockets and even Ajax, we relied on a small form which posts messages to the back end and a running feed of messages being sent from the back-end. One of the most common way to handle this involved frames and a “meta refresh” like this one:</p>
</blockquote>

<blockquote>
  <pre><code>&lt;meta http-equiv="refresh" content="30"&gt;
</code></pre>
</blockquote>

<blockquote>
  <p>That simple <code>meta</code> tag will make any browser refresh the page every 30 seconds. Now if you put that in an <code>iframe</code> to keep it from causing a refresh of the entire interface, any new messages would be picked up and displayed automatically at that interval (which you should tune to be appropriate for your app).</p>
</blockquote>

<blockquote>
  <p>Once that is in place the page itself could even post to that frame by using the non-standard but well-supported <code>_target</code> attribute on the <code>form</code>.</p>
</blockquote>

<blockquote>
  <p>Obviously with JavaScript enabled, you’d probably throw away that <code>iframe</code>, but the rest of the setup (including the templates for displaying the messages) could certainly be reused with WebSockets.</p>
</blockquote>

<p>I hope this helps. Progressive enhancement may seem like a huge challenge, but when you take a few moments to think about how we handled these challenges in the past, the way forward becomes clear.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Google Embraces Progressive Enhancement]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/google-embraces-progressive-enhancement/"/>
    <updated>2014-10-28T21:07:35-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/google-embraces-progressive-enhancement</id>
    <content type="html"><![CDATA[<p>In case you missed it, <a href="http://googlewebmastercentral.blogspot.com/2014/10/updating-our-technical-webmaster.html">yesterday Pierre Far updated Google’s Webmaster Guidelines</a>. In his post, Pierre lays out their case for <a href="https://en.wikipedia.org/wiki/Progressive_enhancement">progressive enhancement</a>:</p>

<blockquote>
  <p>Just like modern browsers, our rendering engine might not support all of the technologies a page uses. Make sure your web design adheres to the principles of progressive enhancement as this helps our systems (and a wider range of browsers) see usable content and basic functionality when certain web design features are not yet supported.</p>
</blockquote>

<!-- more -->

<p>As someone who has been beating the drum for progressive enhancement for over a decade, this sort of support from such an influential company gets me a little teary-eyed.</p>

<p>It’s nice to see Steve Champeon’s philosophy for web design finally beginning to gain traction outside of the ivory tower of Web standards. It is a fantastic philosophy that has been guiding our work since Steve unveiled it. And it has paid some handsome dividends for both us and our clients.</p>

<p>If you need help wrapping your head around progressive enhancement, you should read <a href="#fn-2014-10-28">my introductory series for <cite>A List Apart</cite></a>. If you want more, there’s also <a href="http://adaptivewebdesign.info">my book on progressive enhancement: <cite>Adaptive Web Design</cite></a>. And if you need help getting your team up to speed, I’m more than happy to hop on a plane and come to you. Just <a href="/contact/">drop me a line</a>. I have helped many companies embrace this philosophy and have seen it improve their productivity, increase their reach by supporting more devices, and improve the accessibility of their products. Oh… and <a href="http://blog.easy-designs.net/archives/the-true-cost-of-progressive-enhancement">progressive enhancement has saved our clients real money and reduced their time to market</a>.</p>

<p>I don’t tend to be a “magic pill” kind of believer, but I can honestly say that embracing progressive enhancement can radically change your business for the better. And I’m glad to see Google agrees with me.</p>

<h2 id="fn-2014-10-28">My (still-relevant) 2008 series on Progressive Enhancement</h2>

<ol>
  <li><a href="http://www.alistapart.com/articles/understandingprogressiveenhancement/">Understanding Progressive Enhancement</a></li>
  <li><a href="http://www.alistapart.com/articles/progressiveenhancementwithcss/">Progressive Enhancement with CSS</a></li>
  <li><a href="http://www.alistapart.com/articles/progressiveenhancementwithjavascript/">Progressive Enhancement with JavaScript</a></li>
</ol>
]]></content>
  </entry>
  
</feed>
