<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Browse by Tag: Conferences | Aaron Gustafson]]></title>
  <link href="https://www.aaron-gustafson.com/notebook/tags/conferences/atom.xml" rel="self"/>
  <link href="https://www.aaron-gustafson.com/"/>
  <updated>2016-08-15T12:51:47-04:00</updated>
  <id>https://www.aaron-gustafson.com/</id>
  <author>
    <name><![CDATA[Aaron Gustafson]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[The Web Should Just Work for Everyone]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/the-web-should-just-work-for-everyone/"/>
    <updated>2016-04-11T11:51:52-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/the-web-should-just-work-for-everyone</id>
    <content type="html"><![CDATA[<p><em>I had the great pleasure of delivering the following talk at the <a href="http://lanyrd.com/2016/edgesummit/">Edge Web Summit</a> on April 4th. The talk is largely about accessibility with a push for thinking about the future of the interface and how considering accessibility now will help us prepare for a world of “headless UIs”.</em></p>

<!-- more -->

<hr />

<p>We, as an industry, tend to have a pretty myopic view of experience. Those of us who work day-to-day in accessibility probably have a broader perspective than most, but I would argue that even we all fall short now and again when it comes to seeing the Web as others do.</p>

<p>I’m, of course, talking about accessibility. Now if you’re like most audiences, I’m guessing when you hear the word “accessibility” you probably think “screen reader”. That’s ok. Screen readers are certainly one part of the assistive technology spectrum, but my hope is, that by the end of this talk, when someone says “accessibility” you instead think… “opportunity”.</p>

<figure id="fig-2016-04-11-01" class="media-container"><img src="https://www.aaron-gustafson.com/i/posts/2016-04-11/01.gif" alt="The word “Accessibility” exploding to reveal the word “opportunity”." /></figure>

<p>Accessibility is concerned with accommodating disabilities, but our understanding of what a disability is has changed over time. In the 1980s, the World Health Organization defined a disability as a personal attribute:</p>

<blockquote>
  <p>In the context of health experience, a disability is any restriction or lack of ability (resulting from an impairment) to perform an activity in the manner or within the range considered normal for a human being.</p>
</blockquote>

<p>They have since <a href="http://www.who.int/topics/disabilities/en/">updated their definition of a disability</a> to be more context-dependent:</p>

<blockquote>
  <p>Disability is not just a health problem. It is a complex phenomenon, reflecting the interaction between features of a person’s body and features of the society in which he or she lives.</p>
</blockquote>

<p>The points of interaction between a person and society are where disability happens. It’s our responsibility to know how our designs affect these interactions.</p>

<p>If we use our own abilities and biases as a starting point, we end up with products designed for people of a specific age, language ability, tech literacy, and physical ability. Plus those with specific access to money, time, and stable network connections.</p>

<figure id="fig-2016-04-11-02" class="media-container">
{% adaptive_image /i/posts/2016-04-11/02.png %}
<figcaption>A figurative graph charting user ability against population using a bunch of different icons for people. One person is identified as a designer and she is part of a subset of the people that are in grey, signifying that they are "included" when the designer considers things from their own perspective. The vast majority of the people icons are in red, signifying they are "excluded" by this line of thinking.</figcaption>
</figure>

<p>When it comes to people, there’s no such thing as “normal”. For example, the interactions we design with technology depend heavily on what we can see, hear, say, and touch. If we’re designing with ourselves as a baseline, we can overlook people with circumstances different from ours.</p>

<p>I love exercises that create opportunities for revelation. One of my favorites originates from <a href="https://en.wikipedia.org/wiki/John_Rawls">John Rawls</a>. Rawls was a philosopher who used to run a social experiment with students, church groups, and the like. In the experiment, individuals were allowed to create their ideal society. It could follow any philosophy. It could be a monarchy or democracy or anarchy. It could be capitalist or socialist. The people in this experiment had free rein to control absolutely every facet of the society… but then he’d add the twist: They could not control what position they occupied in that society.</p>

<p>This twist is what <a href="https://en.wikipedia.org/wiki/John_Harsanyi">John Harsanyi</a>—an early game theorist—refers to as the <a href="https://en.wikipedia.org/wiki/Veil_of_ignorance">“Veil of Ignorance”</a> and what Rawls found, time and time again, was that individuals participating in the experiment would gravitate toward creating the most egalitarian societies.</p>

<p>It makes sense: what rational, self-interested human being would treat the elderly, the sick, people of a particular gender or race or creed or color, poorly if they could find themselves in that position?</p>

<p>We’re often told accessibility is only concerned with folks with “special needs.” Well news flash: <em>we all have special needs</em>. Some we’re born with. Some we develop. Some are temporary. Some have nothing to do with us personally, but are situational or purely dependent on the hardware we are using, the interaction methods we have available to us, or even the speed at which we can access the Internet or process data.</p>

<p>Sometimes disability is a temporary thing. A short-term injury and illness affect the way people interact with the world around them. Looking into bright light can cause brief visual impairment. Being sick with a cough makes it hard to speak. Wearing a cast can severely limit a person’s ability to lift an everyday object.</p>

<p>On the more technical side of things, small touchscreens can be awkward to interact with is you’re fat-fingered like me. Glossy screens can be difficult to read under glaring light. Low-contrast text can be difficult to read when you turn the screen brightness down to conserve battery life on your mobile device.</p>

<p>Recognizing that we all have special needs leads us to make better decisions as designers and developers. When we understand that disability is a universal and dynamic way of interacting with the world, it can become something else as well: a new source for creativity. Our impact can also expand, as our inclusive designs reach a greater number of people.</p>

<p>Designing for people with permanent disabilities can seem like a significant constraint, but the resulting designs can actually benefit a much larger number of people. For example, curb cuts in sidewalks were first created to make it safer and easier for people in wheelchairs to cross the street.</p>

<figure id="fig-2016-04-11-03" class="media-container">
{% adaptive_image /i/posts/2016-04-11/03.jpg %}
<figcaption>A curb cut. <b class="media-container__credit">Photo credit: <a href="https://www.flickr.com/photos/12155320@N00/6793281764/">Dylan Passmore</a></b></figcaption>
</figure>

<p>But curb cuts also help people with a wide range of circumstances, from kids riding bicycles, to parents pushing strollers, to workers hauling heavy equipment.</p>

<figure id="fig-2016-04-11-04" class="media-container">
{% adaptive_image /i/posts/2016-04-11/04.png alt="Numerous needs that benefit from curb cuts: wheelchairs, strollers, bicycles, and skateboards." %}
</figure>

<p>Similarly, high-contrast screen settings were initially made to benefit people with vision impairments. But today, many people benefit from high-contrast settings when they use a device in bright sunlight. The same is true for remote controls, automatic door openers, voice controls, and much more. Designing with constraints in mind is simply designing well.</p>

<figure id="fig-2016-04-11-05" class="media-container">
{% adaptive_image /i/posts/2016-04-11/05.png alt="A disability continuum from permanent (a person with one arm) to temporary (a person with an arm injury) to situational (a new parent holding a baby)." %}
</figure>

<p>By designing for someone with a permanent disability, someone with a situational disability can also benefit. For example, a device designed for a person who has one arm could be used just as effectively by a person with a temporary wrist injury or a new parent holding an infant.</p>

<figure id="fig-2016-04-11-06" class="media-container">
{% adaptive_image /i/posts/2016-04-11/06.png alt="Adding up the number of people in the U.S. who deal with disabilities relating to arm usage gets your to 21 million pretty quickly." %}
</figure>

<p>Being mindful of the continuum from permanent to situational disabilities helps us rethink how our designs can scale to more people in new ways. In the United States, 26,000 people a year suffer from loss of upper extremities.</p>

<p>But when we include people with temporary and situational disabilities, the number is greater than 20M.</p>

<p>As a web design philosophy, progressive enhancement is right in line with the egalitarian inclusive design approach. It calls for equality of opportunity, but doesn’t require equality of outcome. It’s okay for different folks to experience your products in different ways as long as everyone can accomplish the task they set out to do.</p>

<p>As <a href="http://benhoh.com/journal/2012/01/30/from-degradation-to-enhancement">Ben Hoh eloquently put it</a></p>

<blockquote>
  <p>[Progressive enhancement] keeps the design open to the possibilities of sexiness in opportune contexts, rather than starting with the ‘whole’ experience that must be compromised.</p>
</blockquote>

<p>At its essence, progressive enhancement is about being good designers. The definition of design is “to devise for a specific function or end” Classically, it means “to indicate” and comes from the medieval Latin: <i lang="la">designare</i>, meaning “to mark out”.</p>

<blockquote>
  <p>I’ve been amazed at how often those outside the discipline of design assume that what designers do is decoration—likely because so much bad design simply is decoration. Good design isn’t. Good design is problem solving.</p>
</blockquote>

<p>As Jeff Veen so astutely observed in <a href="http://www.inspireux.com/2009/01/19/good-design-isnt-decoration-good-design-is-problem-solving/">this quote</a>, there is a lot of bad “design” out there that is more concerned with aesthetics than problem solving.</p>

<p>When we are concerned with the user interface, it can sometimes be at the expense of the user experience.</p>

<figure id="fig-2016-04-11-07" class="media-container">
{% adaptive_image /i/posts/2016-04-11/07.png %}
<figcaption>The <a href="http://impossibleobjects.com/coffeepot-for-masochists.html">Coffeepot for Masochists by Jaques Carelman</a> famously referenced by Donald Norman in <a href="http://amzn.to/1RP2vB9"><cite>Emotional Design</cite></a>.</figcaption>
</figure>

<p>It is possible to have something both beautiful and highly functional.</p>

<figure id="fig-2016-04-11-08" class="media-container">
{% adaptive_image /i/posts/2016-04-11/08.jpg %}
<figcaption>A ramp embedded in staircase of <a href="https://en.wikipedia.org/wiki/Robson_Square">Robson Square</a> in Vancouver, <abbr aria-label="British Columbia">BC</abbr>. <b class="media-container__credit">Photo credit: <a href="https://www.flickr.com/photos/mag3737/">Tom Magliery</a></b></figcaption>
</figure>

<p><a href="https://24ways.org/">24 Ways</a> is an advent calendar for web professionals. It’s a magazine of sorts, but it is both highly interactive and accessible. The site’s developers employ a handful of features from <a href="https://www.w3.org/TR/wai-aria/">the ARIA spec</a> to increase the accessibility of the site.</p>

<p>One such feature is <a href="https://www.w3.org/WAI/GL/wiki/Using_ARIA_landmarks_to_identify_regions_of_a_page">ARIA landmarks</a>, which identify key areas of a web page. Such as the primary header or “banner” of a site.</p>

<p>{% gist 9b3c92fec79342edc9400b48ecaa0cb8 banner.html embed %}</p>

<p>The main content.</p>

<p>{% gist 9b3c92fec79342edc9400b48ecaa0cb8 main.html embed %}</p>

<p>Content concerned with easing navigation of the site.</p>

<p>{% gist 9b3c92fec79342edc9400b48ecaa0cb8 navigation.html embed %}</p>

<p>Or even information about the content, such as copyright designations.</p>

<p>{% gist 9b3c92fec79342edc9400b48ecaa0cb8 contentinfo.html embed %}</p>

<p>Users browsing with an ARIA-aware screen reader can use these landmarks to quickly navigate through a document.</p>

<figure id="figure-2016-04-11-09">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-04-11/09.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-04-11/09.mp3" type="audio/mpeg;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-04-11/09.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-04-11/09.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<p>This example hints at a simple reality: <strong>Every interface is a conversation</strong>. We engage our users directly in an effort to inform them, entertain them, or persuade them to act in a particular way. How this conversation goes directly affects the experience our users have.</p>

<p>Now this may sound great as a quote to share on Twitter—feel free—but it’s absolutely true. And it’s going to become even more important that we pay attention to this conversation as personal assistants—you know, “assistive technology”, it’s right there in the name—begins to play a larger part in our users’ lives.</p>

<p>We need to consider the experience when our products are stripped to their essence. When there is no visual design to entice our users to overlook the fundamental flaws in the design of our interfaces. When there is no UI to help them manage the cognitive load of accomplishing a given task.</p>

<p>Considering this now will put you way ahead of your competition and empower your users to do more with your products. It can seem like a daunting task when we’ve spent so much time fixated on how to enable our users to accomplish key tasks on a screen, especially in a responsive context. But what is responsive design about if not accessibility? Responsive design is concerned with presenting the most appropriate visual experience given the constraints of a screen’s size.</p>

<p>Similarly, conversational interfaces are concerned with the way we communicate with our users, whether there is a screen or not and whether the user can see it or not. This isn’t new, it’s a challenge we’ve tackled before…</p>

<p>Let’s take a trip back in time to one of the earliest computer games: Zork. Zork was written between 1977 and 1979. It’s a text-based adventure game that operates a lot like a game of <em>Dungeons &amp; Dragons</em>—with the program serving the role of gamemaster.</p>

<p>As you move from location to location throughout the game, the program describes the environment and notes objects and people you can interact with. You type what you want to do and the program tells you the results of your actions.</p>

<blockquote>
  <p>West of House<br /> You are standing in an open field west of a white house, with a boarded front door.<br /> There is a small mailbox here.<br /><br />&gt; <strong>open mailbox</strong></p>
</blockquote>

<p>As this was the early days of computer gaming, you might think Zork’s interactions would be simple noun-verb combinations—”kill troll”—but Zork was more sophisticated than that. Its parser was could understand far more complex commands like “hit the troll with the Elvish sword”. This made the experience far more natural, as if you were playing a table top game with friends.</p>

<p>Whether Zork or a webpage, <strong>every interface is a conversation</strong>. When I create a homepage, I’m talking to visitors as if we’ve just met. I’m explaining what they can do on my site (and, in some cases, why it matters). If I’m designing a product page, the conversation is a little different. I’m explaining to my users what a particular object or service is, what it does, and how it will benefit them. I’ll skip the BS sales pitch and talk honestly about the product’s benefits. If I’m designing a contact form, I want to help my users get a message to me quickly and efficiently. I’m also going to set some expectations around how long it will take me to get back to them (and, of course, I’ll need to abide by that promise). Even the humble status update is a conversation. I’m asking a question and then stepping back and letting my users speak. The floor is theirs. (But I’m probably mining what they say for data so I can market to them later.)</p>

<p>Conversations consist of words, so it should come as no surprise that we should choose our words carefully. When talking to people, things generally go better when you talk to them like they talk to you. This is a lesson Facebook learned the (somewhat) hard way.</p>

<p>Over the 2011 holidays, Facebook users were uploading photos like crazy. In the span of a few days, Facebook processed more photo uploads than are contained in the entirety of Flickr. Seriously, that’s a lot of photos.</p>

<p>One unintended consequence of this deluge of photo uploads was a significant uptick in people asking Facebook to remove specific ones. Facebook received millions of these “photo reports”, but they made no sense: Moms holding babies reported for harassment, pictures of puppies reported for hate speech, and so on. Roughly 97% of these photo reports were dramatically mis-categorized.</p>

<p>Facebook’s engineers reached out to some of the users who had reported these photos to get a bit more background regarding their submissions.</p>

<p>At the time Facebook’s photo reporting interface provided a list of reasons users could choose from if they wanted a photo removed, but, as Facebook soon discovered, many of the reports were made because users didn’t want the photo posted for reasons other than those provided.</p>

<p>In some cases, it was because they didn’t like how they looked in the photo. In others, it was because the photo was of an ex-partner or even a beloved pet they’d shared with an ex-boyfriend or ex-girlfriend. The existing photo reporting tool had not done a good job of accounting for these more personal reasons for wanting a photo removed, so the Facebook engineers went to work. They added a step that asked <em>How does this photo make you feel?</em> The options were simple:</p>

<ul>
  <li>Embarrassing</li>
  <li>Upsetting</li>
  <li>Saddening</li>
  <li>Bad Photo</li>
  <li>Other</li>
</ul>

<p>The “other” option also provided a free-response text field to fill in.</p>

<p>With this system in place, they found that 50% of reporters who answered the new question chose one of the provided options. That was pretty helpful, but there was still a problem: 34% of the “other” respondents were writing “It’s embarrassing” in the blank rather than choosing the “embarrassing” option already provided.</p>

<p>What the Facebook team realized was that people were not identifying with the “embarrassing” text (or may have even thought it was referring to them, rather than assuming an implied “It’s”). A subtle shift in language was needed, so they changed the label to <em>Please describe the photo</em> and they updated the options to mirror how people actually talk:</p>

<ul>
  <li>It’s embarrassing</li>
  <li>It’s a bad photo of me</li>
  <li>It makes me sad</li>
</ul>

<p>With this subtle change, they were able to increase the percentage of photo reporters who chose one of the options provided to a whopping 78%.</p>

<p>Words matter. Even in something as simple and banal as a form, the words we choose set the tone for our users’ experiences and often have an affect on what they do… or fail to do. The words we choose matter even more in the world of headless UIs. Without visual aids to help a user see where they are in a form or to aid them in managing the cognitive load of our interfaces, every bit of label and helper text becomes even more important.</p>

<p>When Luke Wroblewski coined “mobile first”, he told us to focus on the core purpose each and every page. He was, in essence, telling us to focus on the conversation we are having with our users. This approach pays huge dividends on small screens, but when it comes to voice-based interactions, “the page” doesn’t really exist. Experience is the sum of each individual interaction.</p>

<p>As part of their Alexa Skills Kit, Amazon offers a ton of recommendations for designing for voice, many of which happen to be equally useful for sighted users.</p>

<h2 id="write-for-people">Write for People</h2>

<p>We don’t author content for ourselves. We write for others. If what we write frustrated or alienates our users, we’ve failed at our job. In their profoundly helpful book <a href="http://amzn.to/1YpYLq1"><cite>Nicely Said</cite></a>, Nicole Fenton and Kate Kiefer Lee offer numerous suggestions for how to write with the reader in mind:</p>

<ul>
  <li>Be clear.</li>
  <li>Be concise.</li>
  <li>Be honest.</li>
  <li>Be considerate.</li>
  <li>Write how you speak.</li>
</ul>

<p>They also make the recommendation that you read your work aloud. As we head into the world of voice-based interactions, that’s beta testing!</p>

<h2 id="avoid-technical-and-legal-jargon">Avoid Technical and Legal Jargon</h2>

<p>For example, if you track error codes for issues on your site, send them to <em>your developers</em>, but never present them to a user. Similarly, we should avoid legalese and write in plain language. Medium has done a great job of this with <a href="https://medium.com/policy/medium-terms-of-service-9db0094a1e0f#.mgexdk816">their Terms of Service</a>.</p>

<h2 id="when-requesting-feedback-make-it-clear-that-the-user-needs-to-respond">When Requesting Feedback, Make It Clear That the User Needs to Respond</h2>

<p>In perhaps the most common form example, consider the label “First Name”. It’s not terribly conversational and doesn’t beg for a response.</p>

<p>{% gist 6f5b7c0f0c072631a908 better-labels.html %}</p>

<figure id="figure-2016-03-04-05">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.mp3" type="audio/mpeg;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<p>Similarly, when there’s an error, notify them of the error and, if possible, give them some clues on how to fix it.</p>

<p>{% gist 6f5b7c0f0c072631a908 field-error.html %}</p>

<figure id="figure-2016-03-04-06">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.mp3" type="audio/mpeg; codecs=&quot;mp3&quot;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<h2 id="when-asking-a-user-to-choose-clearly-present-the-options">When Asking a User to Choose, Clearly Present the Options</h2>

<p>This comes into play often when dealing with forms. Ensuring radio and checkbox controls are properly associated with their labels is critical.</p>

<p>{% gist 6f5b7c0f0c072631a908 radio-label.html %}</p>

<p>You can also use the <code>fieldset</code> and <code>legend</code> elements to group the related controls, but be sure to make the <code>legend</code> focusable or associate it with the first focusable form control in order to ensure the question is read out.</p>

<p>{% gist 6f5b7c0f0c072631a908 fieldset.html %}</p>

<figure id="figure-2016-03-04-07">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.mp3" type="audio/mpeg; codecs=&quot;mp3&quot;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<p>We should strive for the same sort of clarity when presenting navigation options. The HTML5 <code>nav</code> element enables us to semantically identify an area of the page being used for navigation. It is not, however, always identified as being navigation when encountered naturally in the flow of the document. (It is when using role-based navigation like we saw earlier.) For that reason, it can be useful to provide an textual introduction to the section, even if you choose to visibly hide it. You might even consider expanding the text of your navigation items to provide additional context like I do on my site.</p>

<p>{% gist 6f5b7c0f0c072631a908 navigation.html %}</p>

<figure id="figure-2016-03-04-08">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.mp3" type="audio/mpeg; codecs=&quot;mp3&quot;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<p><a href="http://www.npr.org/">NPR</a> has multiple navigation elements on the page and they use ARIA to label them without adding additional tags. Instead, they use the <code>aria-label</code> attribute to distinguish them.</p>

<p>{% gist 9b3c92fec79342edc9400b48ecaa0cb8 aria-label.html embed %}</p>

<h2 id="prompts-should-be-short-while-still-being-clear">Prompts Should be Short, While Still Being Clear</h2>

<p>In <a href="https://www.stmarys-ca.edu/sites/default/files/attachments/files/On_The_Method_of_Theoretical_Physics.pdf">a 1933 lecture at Oxford</a>, Albert Einstein famously said</p>

<blockquote>
  <p>It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience.</p>
</blockquote>

<p>Or, as <a href="https://books.google.com/books?id=prDfAFjet9cC&amp;lpg=PR7&amp;ots=PA9rRog4cr&amp;dq=How%20a%20%E2%80%98Difficult%E2%80%99%20Composer%20Gets%20That%20Way&amp;pg=PA230#v=onepage&amp;q&amp;f=false">Roger Sessions paraphrased it</a></p>

<blockquote>
  <p>Everything should be as simple as it can be but not simpler.</p>
</blockquote>

<p>Clear and concise writing is the hallmark of great content. We need to resist the urge to write for writing’s sake. We write in the service our audience, not for ourselves.</p>

<p>Government websites are some of the worst offenders in this area. Consider this lovely passage:</p>

<blockquote>
  <p>Heavy rains throughout most of the State have given an optimistic outlook for lessened fire danger for the rest of the season. However, an abundance of lightning maintains a certain amount of hazard in isolated areas that have not received an excessive amount of rain.</p>
</blockquote>

<p>It could be written far more clearly as</p>

<blockquote>
  <p>Heavy rains throughout most of the State have lessened fire danger for the rest of the season. However, lightning threatens isolated dry areas.</p>
</blockquote>

<p>In the UK, the Government Digital Service has made great strides overhauling excruciatingly painful content and making it easier to read and understand. One such example is <a href="https://gds.blog.gov.uk/2014/07/28/doing-the-hard-work-to-make-things-simple/">their overhaul of the Accelerated Possession process</a> that allows landlords to evict a tenant.</p>

<p>The original paper form asked for the address like this</p>

<blockquote>
  <p>The claimant seeks an order that the defendant(s) give possession of:<br /> (If the premises of which you seek possession are part of a building identify the part eg. Flat 3, Rooms 6 and 7)</p>
</blockquote>

<p>Before requesting the type of property concerned</p>

<blockquote>
  <p>(‘the premises’) which is<br /> ☐ a dwelling house<br /> ☐ part of a dwellinghouse</p>
</blockquote>

<figure id="figure-2016-03-04-09">
{% adaptive_image /i/posts/2016-03-04/09.png %}
</figure>

<p>Clear and to the point, right?</p>

<p>The GDS went to work and streamlined the process in plain language:</p>

<blockquote>
  <p>What kind of property do you want to take back?<br /> ◎ A self-contained house, flat or bedsit<br /> ◎ Room or rooms in a property.<br /> Tenants may share kitchen or bathroom</p>
</blockquote>

<p>Then they allow you to lookup the property or manually enter the address.</p>

<figure id="figure-2016-03-04-10">
{% adaptive_image /i/posts/2016-03-04/10.png %}
</figure>

<p>While not specifically designed for the future of headless UIs, this form is prepared for their eventuality.</p>

<h2 id="ask-only-necessary-questions">Ask Only Necessary Questions</h2>

<p>We show our users respect by respecting their time. Obviously straightforward, brief writing is one way we do that, but another is to reduce the time it takes to complete a task. Many forms are brimming with fields to be filled in. In some cases, the vast majority are purely optional. And while it may be easy to spot the required fields visually, bypassing them in an aural interface can be incredibly difficult.</p>

<figure id="figure-2016-03-04-11">
{% adaptive_image /i/posts/2016-03-04/11.jpg %}
</figure>

<p>User experience designers have been pushing for simplified forms since… well, as long as I can remember. Users appreciate them, they tend to result in better data, and they also tend to convert better than long forms. And when it comes to voice-based interactions, they will become a necessity. No one is going to want to spend 15 minutes working their way through a 15 question registration form when all that’s required is their email address and for them to choose a password.</p>

<figure id="figure-2016-03-04-12">
{% adaptive_image /i/posts/2016-03-04/12.jpg %}
</figure>

<p>On a similar note, we should avoid slicing fields into multiple parts if at all possible. For instance, you still see fields like this one, asking for a US phone number, quite often:</p>

<figure id="figure-2016-03-04-13">
{% adaptive_image /i/posts/2016-03-04/13.png %}
</figure>

<p>When interacting with this construct via voice, a user will be required to supply three separate values. In order to do so, each field would require a label. Most developers only know how to label the first of those three boxes and users would be really confused if you asked them for their exchange code and line number.</p>

<p>HTML5 introduced a host of new field types that consolidate phone numbers, dates, times, and other complex data types into single fields. Use them! As an added bonus, most enforce content validation and formatting rules for you automatically.</p>

<h3 id="present-information-in-consumable-pieces">Present Information in Consumable Pieces</h3>

<p>Like computers, we humans have a finite amount of “working memory”. The amount of mental resources required to operate an interface is called its “cognitive load”. When the amount of information we need to process exceeds our capacity to handle it, we can miss important details, have trouble concentrating, and become frustrated.</p>

<p>We deal with cognitive load in GUI design all the time, but in voice-based interactions, there are no visuals to act as signposts and provide reminders about where we are and what we’re doing. This is why it is critical to break complicated tasks down into simpler ones and eliminate excess noise (like non-required fields). We can also reduce cognitive load by chunking search results and other list-type content into small groups, asking the user if they want more before loading and presenting them.</p>

<blockquote>
  <p>The top seller in the garden department is Repel Lemon Eucalyptus Natural Insect Repellent, 4-Ounce Pump Spray</p>
</blockquote>

<blockquote>
  <p>Would you like to hear the rest?</p>
</blockquote>

<hr />

<p>As human beings, we all have special needs, but as designers and developers, it can sometimes be difficult to diagnose potential issues within our products when it comes to accessibility. Especially if we don’t typically experience that need or are unfamiliar with the tools used to address it.</p>

<p>To that end, my colleagues have been hard at work to make it easier to enhance the accessibility of our products. The first tool I want to discuss is the F12 developer tools in Edge.</p>

<p>As Andy Sterland mentioned in his talk, in a forthcoming release of F12, the inspector will surface accessibility information about each node in the DOM. Let’s take a look at an example:</p>

<p>{% youtube Z0PSK4IUAVM %}</p>

<p>Here we have the forthcoming redesign of <a href="http://html5accessibility.com/">HTML5accessibility.com</a> and if I inspect the section containing the test results, I can see information about that section element. On the right hand side, you’ll notice an inspector tab dedicated to accessibility information such as the node’s accessible name, it’s role, whether it’s keyboard focusable, ARIA properties assigned to it (in this case, <code>aria-label</code>), and so on.</p>

<p>Adding this functionality into F12 lifts the veil from the way Edge exposes the DOM to assistive technology and will go a long way toward helping us fine tune our experiences for <abbr aria-label="assistive technology">AT</abbr>, including screen readers and virtual assistants.</p>

<p>Another area where we are doing some work is within Narrator itself. When testing with screen readers, it can be quite tempting as a sighted user, to leave your screen on so you can follow along. Sadly, that action directly prohibits you from experiencing a site or application the way folks with visual impairments or in a headless UI scenario do. It can cause you to miss things or assume something makes sense when, in fact, it doesn’t.</p>

<p>To help address that, Narrator will soon sport a “Developer Mode” that enables you to blank out a single app (such as the Edge browser window) so you can experience it without any visual access to the UI. (You can also use it for installed and hosted apps.)</p>

<p>{% youtube lJ-4AVxAIsc %}</p>

<p>Here we see the HTML5accessibility site again. If I flip on Developer Mode in Narrator, the Edge browser window goes black and I can see where the focus carat moves (the blue box), but I can’t see the design. For diagnostic purposes, the contents being read by Narrator are also presented as text on the screen in the position of the element (which can help with identifying where the issue was when you come back out of Developer Mode).</p>

<p>Microsoft is committed to improving the accessibility, not only of its own products, but of the Web as a whole. These two tools are only a few of the many ways we are doing that today.</p>

<p>Obviously, part of that is continuing to evolve and improve the accessibility of the Web for users browsing in Edge, whether they are using Narrator or other screen readers like Jaws or NVDA.</p>

<p>But, in addition to that, Microsoft—in partnership with Carnegie Mellon and Stanford, Adobe, AT&amp;T, Dropbox, Facebook, Intuit, LinkedIn, and Yahoo—helped launch <a href="http://teachaccess.org/">TeachAccess</a>. This site is an effort to address the “lack of awareness and understanding of basic accessibility issues, concepts and best practices” in the world of <abbr aria-label="computer science">CS</abbr> and <abbr aria-label="human-computer interaction">HCI</abbr> education. If successful, which I sincerely hope it is, it will help address the dire need we have for a more accessibility-aware workforce building for the Web.</p>

<p>Similarly, <a href="https://www.microsoft.com/design">Microsoft Design</a> has shared <a href="https://www.microsoft.com/design/practice">their fantastic set of resources for improving the inclusiveness of design</a>. They have created a guide as well as a set of activities you can use to get your team into the <a href="http://www.inclusivedesigntoolkit.com/betterdesign2/whatis/whatis.html">Inclusive Design</a> mindset.</p>

<p>And in the not too distant future, we’ll be publishing a series of in-depth posts about accessibility on the <a href="https://blogs.windows.com/msedgedev/">Microsoft Edge Dev Blog</a>. These will tackle topics like how we re-architected Edge for better ARIA support and name computation, working with HTML5 accessibility to improve the tests, and how we can enable automated testing in order to discover accessibility regressions before they make it into production.</p>

<p>We do this because, with accessibility in mind, we can improve the lives of billions of people. Friends, family, neighbors, and complete strangers, all of whom deserve the opportunity to access the products we create regardless of the different ways we experience the world.</p>

<p>Ultimately “accessibility” is not about disabilities or the technologies we use to address them, <strong>it’s about people</strong>. Sure, we’ll make it easier to look up movie times and purchase tickets to see the latest Transformers debacle, but we’ll also empower the nearly 900 million people globally—over 60% of whom are female—that are illiterate by enabling our sites to be used purely via voice, even translated in real-time into their native language and dialect.</p>

<p>We will create new opportunities for the poor and disadvantaged to participate in a world that has largely excluded them. You may not be aware, but 80% of Fortune 500 companies—think Target, Walmart—only accept job applications online or via computers.</p>

<p>We will enable people who have limited computer skills or who struggle with reading to apply for jobs with these companies.</p>

<p>We will empower immigrants to read lease agreements and postal mail in languages they haven’t fully grasped yet.</p>

<p>We will enable people with visual disabilities to vote, even on paper ballots, without human assistance.</p>

<p>We can help bridge the digital divide and the literacy gap. We can create opportunities for people to better their lives and the lives of their families. We have the power to create more equity in this world than most of us have ever dreamed.</p>

<p>This is an incredibly exciting time, not just for accessibility, not just for user experience, not just the Web, but for the world! I can’t wait to see how awesome you make it!</p>

<p>Thank you!</p>

<hr />

<p><em>You can watch (or listen) to me present this talk (albeit with a bit of technical difficulty) <a href="https://channel9.msdn.com/Events/WebPlatformSummit/edgesummit2016/ES1612">over on the Channel 9 website.</a></em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[My Top Takeaways From the 2016 Edge Web Summit]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/my-top-takeaways-from-the-edge-web-summit-2016/"/>
    <updated>2016-04-06T15:18:15-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/my-top-takeaways-from-the-edge-web-summit-2016</id>
    <content type="html"><![CDATA[<p>Earlier this week, my colleagues on the Microsoft Edge team put on the second of what has now become an annual event: <a href="http://lanyrd.com/2016/edgesummit/">the Edge Web Summit</a>. The format was a little different this year, with team members from across the organization delivering quick, punchy 30-minute talks on topics ranging from standard implementations to the user experience of a browser to real-time communications. I live-tweeted quite a few of the talks, but I thought I’d provide a bit of a round-up of what was revealed, discussed, and more so you can read it all in one place.</p>

<!-- more -->

<ul>
  <li>Since launching Edge 8 months ago, the team has pushed 12 update releases, 128 new features, and 6,527 bug fixes!</li>
  <li>The team has launched a new, highly transparent bug tracker for Edge: <a href="https://developer.microsoft.com/en-us/microsoft-edge/platform/issues/">issues.microsoftedge.com</a>.</li>
  <li>The Edge team has done a ton of research into what specs are being used and how they are being used on the open Web. They are starting to share this information on <a href="https://developer.microsoft.com/en-us/microsoft-edge/platform/data/">data.microsoftedge.com</a>. It currently consists of 2 parts: 1) <a href="https://developer.microsoft.com/en-us/microsoft-edge/platform/usage/">usage data</a> from real sites that looks at not only CSS properties in use, but values too; and 2) <a href="https://developer.microsoft.com/en-us/microsoft-edge/platform/catalog/">a catalog of available APIs</a> and a detailed analysis of browser support, down to specific configuration and property values.</li>
  <li>Hot on the tails of <a href="https://developer.microsoft.com/en-us/microsoft-edge/tools/remote/">RemoteIE</a> opening up for Linux users, RemoteEdge is coming soon! Jacob Rossi showed <a href="https://twitter.com/aarongustafson/status/717022717652828163">a screenshot of an Edge instance running on Azure, within Chrome</a>. So cool!</li>
  <li><a href="https://dvcs.w3.org/hg/speech-api/raw-file/tip/speechapi.html#tts-section">Text-to-speech</a> directly from within JavaScript!</li>
  <li>The <a href="https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API">Fetch API</a>!</li>
  <li><a href="https://developer.mozilla.org/en-US/docs/Web/API/Navigator/sendBeacon">Beacons</a> as an alternative to blocking JavaScript requests for telemetry data: <code>navigator.sendBeacon( uri, data )</code>.</li>
  <li><a href="https://developer.mozilla.org/en-US/docs/Web/API/Notifications_API">Web notifications</a>!</li>
  <li><a href="https://www.w3.org/TR/WOFF2/">WOFF 2</a> font support for better compression and faster downloads/decompression!</li>
  <li>The team is currently prototyping and investigating <a href="https://www.w3.org/TR/service-workers/">Service Workers</a>, <a href="https://developer.mozilla.org/en-US/docs/Web/API/Push_API">Push Notifications</a>, <a href="https://www.w3.org/TR/shadow-dom/">Shadow DOM</a>, <a href="https://www.w3.org/TR/custom-elements/">Custom Elements</a>, <a href="https://www.w3.org/Payments/">Web Payments</a>, <a href="https://www.w3.org/community/webassembly/">Web Assembly</a>, and <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/import">ES Modules</a>.</li>
  <li>Cortana in Edge has gotten some major upgrades, such as being able to “Ask Cortana” about an image to get more information (like a recipe for the cookies you saw on Pinterest that did’t include a link).</li>
  <li>Microsoft open-sourced <a href="https://github.com/MicrosoftEdge/css-usage">the CSS crawler powering their data portal</a> so other browser vendors can run it too.</li>
  <li><a href="https://en.wikipedia.org/wiki/FIDO_Alliance">FIDO</a>-based login (like <a href="http://windows.microsoft.com/en-us/windows-10/getstarted-what-is-hello">Windows Hello</a>) is coming to the Web!</li>
  <li><a href="http://windows.microsoft.com/en-us/windows/hear-text-read-aloud-narrator">Microsoft’s Narrator</a> screen reader now supports a “Developer Mode” that blanks out the current app (such as your browser window) in order to enable you to more easily debug accessibility issues.</li>
  <li>The F12 tools in Edge now enable you to view the previously mysterious <a href="https://www.paciellogroup.com/blog/2015/01/the-browser-accessibility-tree/">Accessibility Tree</a> in addition to allowing you to drill more deeply into the various properties of an element that relate to its accessibility.</li>
</ul>

<p>I didn’t take a ton of notes in the second half of the day as I was prepping for <a href="https://channel9.msdn.com/Events/WebPlatformSummit/edgesummit2016/ES1612">my own session on accessibility</a>, but other highlights included building &amp; debugging <a href="https://blogs.windows.com/msedgedev/2016/03/17/preview-extensions/">extensions for Edge</a> (tldr; you can easily port Chrome extensions) and cool things you can do using <a href="https://www.microsoft.com/en-us/windows/Continuum">Continuum</a>.</p>

<p>Overall, the event was incredibly informative and has me really excited about the work the Edge team is doing and where the browser is going. The new stuff that‘s ready for prime time will be out for the public in <a href="https://blogs.windows.com/windowsexperience/2016/03/30/windows-10-anniversary-update-brings-new-experiences-and-developer-opportunity/">the Anniversary Update of Windows 10</a> this Summer, but some of it is has already landed in <a href="https://insider.windows.com/">Windows Insider</a> builds.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[An Event Apart Nashville 2016, Day One]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/an-event-apart-nashville-2016-day-one/"/>
    <updated>2016-03-16T10:54:59-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/an-event-apart-nashville-2016-day-one</id>
    <content type="html"><![CDATA[<p>Unfortunately, I was unable to spend Tuesday in Nashville for An Event Apart (for reasons that will be revealed in about a month), but I did catch Monday and it was amazing.</p>

<!-- more -->

<p>The esteemed <a href="http://www.zeldman.com/">Jeffrey Zeldman</a> kicked the day off with a talk entitled <em>Designing with Web Standards in 2016</em>. A theme he touched on repeatedly was that none of the problems we are facing in web design today are new problems. It’s a topic near and dear to my heart, something I wrote about in the closing chapter of <a href="http://adaptivewebdesign.info/2nd-edition/"><cite>Adaptive Web Design’s</cite> Second Edition</a> and <a href="/notebook/learn-from-the-past-enhance-for-the-future/">recently spoke about at EnhanceConf in London</a>. He knocked this one out of the park and my head was nodding so much my neck began to hurt.</p>

<p>Next up was <a href="http://www.webstandards.org/about/members/">my former WaSP colleague</a> <a href="https://rachelandrew.co.uk/">Rachel Andrew</a> to give us the skinny on CSS Grid Layouts. This is an amazing spec that I’ve always struggled to understand fully (despite the fact that’s i’ve written a Javascript polyfill for it). Rachel made it crystal clear and got me very excited about the future of layout on the Web.</p>

<p><a href="http://jensimmons.com/">Jen Simmons</a> dropped some serious CSS-related design knowledge bombs that perfectly complimented Rachel’s talk. She discussed Flexbox, CSS Shapes, Multi-column layout, viewport units and more, demonstrating how they can be used right now to progressively enhance the design of your sites.</p>

<p>After lunch, <a href="http://bradfrost.com/">Brad Frost</a> took to the stage to talk about Style Guides. I only caught the last half—I’ll admit to doing some last-minute rehearsing in the hallway—but the bits I did catch were good. I’ve seen his Atomic Design talk a few times, which this one builds on. In this talk he touches on a lot of the atomic design concepts, but he also talked a lot more about workflow and the role of the front-end developer. No doubt the evolution of this talk has come in large part through writing <a href="http://atomicdesign.bradfrost.com/">a book on Atomic Design</a> and in hosting <a href="http://styleguides.io/podcast/">a podcast with Anna Debenham on website style guides</a>.</p>

<p>Next, I was given the opportunity to share some thoughts and advice on designing and building. My talk, <em>The Features of Highly Effective Forms</em>, evolved out of several earlier talks on building forms. With this one, I wanted to strike a little more balance between the nuts and bolts of building forms and the hows and whys of building better forms.</p>

<p>The deck, <a href="http://www.slideshare.net/AaronGustafson/the-features-of-highly-effective-forms-an-event-apart-nashville-2016">which I’ve posted to SlideShare</a>, doesn’t stand on its own quite as well as some of my other forms decks simply because the talk contained a lot of storytelling I chose not to pair with slides—instead opting for an black screen so folks could focus—but I did call out the salient points. I’ve begun writing up some of the recommendations as part of my <a href="/notebook/tags/web-forms/">Modern Web Forms Best Practices series</a> and will continue to do so in the future. And one of the stories I told, which I highly recommend you check out, had to do with <a href="/notebook/consider-how-your-forms-read/">a lesson Facebook learned in managing how users report offensive photos</a>.</p>

<p><a href="https://bigmedium.com/">Josh Clark</a> wrapped the day up with a discussion of the future of interface as things move from digital back to physical. He talked about a lot of really cool new tech that has me excited about the future, including <a href="https://google.github.io/physical-web/">the Physical Web</a>, which Josh had running as a live demo. I wonder if anyone noticed I had a beacon running too ;-)</p>

<p>All in all, day one was a blast. As always, Jeffrey, Eric, <a href="https://www.linkedin.com/in/toby-malina-6247a028">Toby</a>, and <a href="http://www.escapadeproductions.com/">Marci</a> do an awesome job programming their events. I’m really bummed I could not stick around to see <a href="http://valhead.com/">Val</a>, <a href="https://twitter.com/grigs">Jason</a>, <a href="http://www.kryshiggins.com/">Krystal</a>, <a href="http://meyerweb.com/">Eric</a>, <a href="http://braintraffic.com/">Kristina</a>, and <a href="http://cameronmoll.com/">Cameron</a> rock it out though. I’m sure it was amazing.</p>

<p>You can check out attendees thoughts from the event by <a href="https://twitter.com/search?q=%23aeansh&amp;src=typd">searching Twitter using the #aeansh hashtag</a>. I’ve <a href="https://storify.com/AaronGustafson/reactions-and-takeaways-from-my-aeansh-talk">collected reactions to my talk on Storify</a> for posterity as well.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Planning Adaptive Interfaces: The Workshop]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/planning-adaptive-interfaces-the-workshop/"/>
    <updated>2016-02-21T18:56:05-05:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/planning-adaptive-interfaces-the-workshop</id>
    <content type="html"><![CDATA[<p>For the last few years I’ve been running a workshop alternately titled “Planning Adaptive Interfaces” or “Beyond Responsive”, depending on the conference. It’s been one of my favorite workshops to run for a number of reasons, but before I get into that, let me explain what it is and how it works.</p>

<!-- more -->

<p>I think we all recognize how much Ethan’s seminal article <a href="http://alistapart.com/article/responsive-web-design">“Responsive Web Design”</a> (and <a href="https://abookapart.com/products/responsive-web-design">his follow-up book</a>) shook up our industry. It changed the way we look at visual design and kindled (or in some cases re-kindled) an interest in catering an experience to mobile devices. But simply incorporating responsive design’s three core strategies—fluid grids, flexible media, media queries—is not the goal; meeting our user’s needs is. Responsive design is not an end in itself… it’s just the beginning.</p>

<p>We need to embrace the heterogenous nature of the Web—myriad connected devices with vastly different screen sizes (if they even have screens), network connectivity, and capabilities in use by countless individuals, each with their own special needs—and craft experiences that will work anywhere at any time. We need to build robust systems that adapt in ways far beyond aesthetics. I designed this workshop to explore the rich variety of use cases that often get overlooked in the course of building web projects and to show how we can begin considering them as early as possible.</p>

<p>When I was starting out, I gave “workshops” that basically amounted to a half-day or (worse) a full day for folks to listen to me blather on about one topic or another. People liked them, but I wouldn’t call them fun. And, in hindsight, I question how much value people got from an extended survey of what’s possible without the opportunity to put that knowledge to use. Workshops should encourage attendees to get their hand dirty.</p>

<p>I kick this workshop off with a relatively brief discussion of the considerations that we should be aware of—beyond screen size and pixel density. I also provide examples of how to adapt interfaces so they rise to meet our customers’ needs. Then I throw out a list of common interface patterns—modals, tabs, etc.—and turn the floor over to the attendees, asking them to build small teams that each examine a single pattern in detail with these considerations in mind. They then spend the rest of the workshop planning out how that interface would adapt to consider factors like accessibility, screen dimensions, device capabilities, JavaScript availability, and so on. All the while, I circulate among the groups, asking and answering questions, pressing them to go a little further with each iteration. Some teams sketch, some prototype, and all spend a lot of time debating, which is awesome!</p>

<p>I leave the last hour or so for a group discussion of what each team’s accomplished. It gives them a chance to talk through their approach, what they learned, what their pain points were, and how they overcame them. Not does it celebrate their work, but it helps the other attendees discover novel ways to approach these common UI constructs.</p>

<p>It’s been a blast and I have learned so much from the teams I’ve coached. Each workshop is completely different because each group of attendees is completely different. I’ve run it with groups ranging from 12 to 120, for internal teams at large companies to mixed audiences from all over the world. Everyone who has attended one of these workshops has brought a unique perspective and helped us all get better at our jobs. That’s been one of the best parts of this experience for me.</p>

<p>If a workshop like this sounds up your alley, I’ll be giving it a few more times in 2016. Your next opportunity will be at <a href="http://enhanceconf.com/workshop.html">EnhanceConf in London in early March</a>. Later in the year, I’ll be giving it as part of <a href="https://buildright.io/maker-series/2016/aaron-gustafson">Sparkbox’s Build Right: Maker Series</a>. I’d love the opportunity to work with you if you can make it!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Progressive Enhancement Gets a Conference]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/progressive-enhancement-gets-a-conference/"/>
    <updated>2016-02-15T10:00:51-05:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/progressive-enhancement-gets-a-conference</id>
    <content type="html"><![CDATA[<p>On March 4th, I’ll be in London to give the closing talk at <a href="http://enhanceconf.com/">EnhanceConf</a>, the first conference dedicated progressive enhancement. Over the last few months, I’ve been talking to the conference’s organizer, <a href="https://twitter.com/simonmcmanus">Simon McManus</a>, quite a lot. He’s put a lot of thought into the conference and I thought it might be interesting to  interview him so he could share his motivations and hopes for the event.</p>

<!-- more -->

<p><b class="interview__attribution">Me:</b> As a philosophy, progressive enhancement has been around for more than a dozen years. Why do you think it needs a conference now?</p>

<p><b class="interview__attribution">Simon:</b> I first started thinking about EnhanceConf in 2014. At the time, Tom Dale had declared progressive enhancement dead and I had just heard Henrik Joreteg telling his Single Page Story.I was hearing lots of talk about progressive enhancement being hard and expensive when my experience showed quite the opposite.</p>

<p>It’s been fascinating to watch how views have changed since, Tom Dale now loves progressive enhancement and Henrik likes to do as much of his rendering at build time as possible.</p>

<p>As the web continues to grow in weird and wonderful ways techniques like progressive enhancement just keep giving more and more value.</p>

<p><b class="interview__attribution">Me:</b> What does progressive enhancement mean to you?</p>

<p><b class="interview__attribution">Simon:</b> I try to build applications that provide the best possible experience to the end user. Regardless of who they are, where they are or what device they are using. For me, that means using progressive enhancement in every part of the stack.</p>

<p>Progressive enhancement is about so much more than whether an app work with JavaScript turned off, realising we don’t have control over the runtime environment and building applications in the most robust way possible is far more important.</p>

<p><b class="interview__attribution">Me:</b> Do you think it’s an approach that everyone should use on every web project?</p>

<p><b class="interview__attribution">Simon:</b> I guess that depends on what you mean by a web project. In my mind to work on the web, you have to give up that illusion of control. You need to assume as little as possible about the device or user and for me that fits very well with progressive enhancement.</p>

<p>Web technologies transcend the capabilities of any one device with their reach alone, it seems strange to me when people use them but don’t take full advantage.</p>

<p><b class="interview__attribution">Me:</b> If a web designer or developer is only passingly familiar with progressive enhancement and is considering coming to the event, what should they expect to get out of it?</p>

<p><b class="interview__attribution">Simon:</b> These are probably the people with the most to benefit from EnhanceConf.</p>

<p>We are going to start the day looking at why progressive enhancement is still important on the modern web, so that should provide a nice intro for anyone who is not already familiar with progressive enhancement.</p>

<p><b class="interview__attribution">Me:</b> What about a seasoned practitioner who already applies this philosophy to their work?</p>

<p><b class="interview__attribution">Simon:</b> Originally, EnhanceConf was a very selfish idea. I wanted to learn more about the tools and techniques being in use in industry: Over the last few years contracting I’ve seen many in use in that just weren’t surfacing at conferences.</p>

<p>EnhanceConf is about the state of the art in progressive enhancement, I’d like to think EnhanceConf will be the perfect event for such people to come together and learn from one another.</p>

<p><b class="interview__attribution">Me:</b> What if the person thinks progressive enhancement is a waste of time?</p>

<p><b class="interview__attribution">Simon:</b> I’d really like to encourage these people to come along to the event, I think it’s important their voice is a part of this discussion so that we can learn from each other and move forward together.</p>

<p>With an open mind I think they should have a really good time, they might hear some viewpoints they disagree with, but there will be lots of opportunities for Q&amp;A to discuss those topics in detail.</p>

<p><b class="interview__attribution">Me:</b> As a hyper-focused event, there’s a risk of it being a bit of an echo chamber. Have you taken steps to mitigate that possibility?</p>

<p><b class="interview__attribution">Simon:</b> I hope by being a hyper-focused event we can move beyond the bikeshedding that so often surrounds such discussions.</p>

<p>But yes. I have taken a couple of steps to mitigate an echo chamber:</p>

<ol>
  <li>
    <p><strong>Duplicate content</strong>
If you take all the talks about progressive enhancement and put them all on the same day you would end up with a fair amount of similar content. There will be no generic talks about progressive enhancement at EnhanceConf. Each talk will dig into real examples to provide unique tales from the trenches.</p>
  </li>
  <li>
    <p><strong>Preaching to the choir</strong>
I’ve been reaching out to lots of different communities around London to bring as many voices into the discussions as possible. The other day I was at the Meteor London meetup talking about EnhanceConf. Tableflip (the organisers) even bought tickets for their whole company!</p>
  </li>
</ol>

<p>The event is also being recorded so anyone not at the event will be able to watch all the talks and Q&amp;A.</p>

<p><b class="interview__attribution">Me:</b> You’re modeling the format of the event—four acts, each comprising three twenty-minute talks and a group Q&amp;A session—on Responsive Day Out. What was the draw of that approach?</p>

<p><b class="interview__attribution">Simon:</b> Yes, we get to hear lots of different viewpoints and then bring the speakers together for a Q&amp;A. This should allow new viewpoints to emerge from discussions and join related threads. It also means we get to spend each section focusing on a particular area.</p>

<p><b class="interview__attribution">Me:</b> Can you talk a bit about your speaker selection process?</p>

<p><b class="interview__attribution">Simon:</b> I had lots of people in mind to talk at EnhanceConf. To ensure we heard a wide range of viewpoints we also opened a call for proposals to which we received some superb submissions.</p>

<p>I was fortunate to have some trusted advisors who helped me out throughout the process. I’m really pleased with how the line-up turned out.</p>

<p><b class="interview__attribution">Me:</b> When the event is done and dusted, what are you hoping will happen?</p>

<p><b class="interview__attribution">Simon:</b> I’d quite like a holiday! :D</p>

<p>But seriously, I hope we can demonstrate how to maximise the benefits and minimise any costs associated with progressive enhancement.</p>

<p>If at the end of EnhanceConf we had a reasoned and nurturing community able to take discussions forward that would be a fine outcome. :)</p>

<p><b class="interview__attribution">Me:</b> Do you think there will be another EnhanceConf?</p>

<p><b class="interview__attribution">Simon:</b> EnhanceConf is the first conference I’ve organised. It’s been an unfathomable amount of work and financial risk to get this far and it’s mostly been done in my evenings and weekends. That said, it has been quite fun.</p>

<p>I’d like to do some traveling this year, maybe 2018?</p>

<hr />

<p>EnhanceConf will take place March 4th at the <a href="http://www.thersa.org/">RSA House</a> in London. <a href="http://enhanceconf.com/tickets.html">Tickets are available on the conference website</a>. I will also be giving <a href="http://enhanceconf.com/workshop.html">a one-day workshop entitled Planning Adaptive Interfaces</a> on March 3rd as part of the conference. Seating is limited.</p>

<p>EnhanceConf is offering a small number of educational scholarships. For more information on the scholarships and how to apply, check out <a href="https://simonmcmanus.wordpress.com/2016/02/14/enhanceconf-scholarship/">Simon’s post about the program</a>.</p>
]]></content>
  </entry>
  
</feed>
