<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Browse by Tag: User Experience | Aaron Gustafson]]></title>
  <link href="https://www.aaron-gustafson.com/notebook/tags/user-experience/atom.xml" rel="self"/>
  <link href="https://www.aaron-gustafson.com/"/>
  <updated>2017-01-04T11:51:16-05:00</updated>
  <id>https://www.aaron-gustafson.com/</id>
  <author>
    <name><![CDATA[Aaron Gustafson]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Lessons in Averaging]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/lessons-in-averaging/"/>
    <updated>2016-12-14T13:01:32-05:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/lessons-in-averaging</id>
    <content type="html"><![CDATA[<p>In the work that we do on the Web (as well as in our daily lives), we’re often confronted, informed, or judged based on averages. I never really stopped to think about it, beyond being bugged by the fact that averages aren’t truly representative of reality. Then I listened to <a href="http://99percentinvisible.org/episode/on-average/">99% Invisible’s episode “On Average”</a>. It was incredibly enlightening and the stories shared in that episode provide sage wisdom that is very relevant to the work that we do.</p>

<!-- more -->

<p>Do you know where our fascination with averages began? It all started with Adolphe Quételet, a Belgian mathematician and astronomer:</p>

<blockquote>
  <p>In the 1830s, astronomers were some of the only people that regularly calculated averages, since early telescopes were extremely imprecise. To obtain more accurate data for say, tracking the orbits of planets, astronomers would take multiple measurements (all of which were slightly different) add them together, then divide by the number of observations to get a better approximation of the true value.</p>
</blockquote>

<p>Quetelet decided to apply this tool to people, starting with Scottish soldiers’ chest sizes. Turns out the average chest size of a Scottish soldier in the 1830s was 39.75 inches. File that one away for Pub Trivia.</p>

<p>Quetelet believed that the average was the “true” size of something… something that we should strive for or that nature would attempt to create. The <a href="https://en.wikipedia.org/wiki/Platonic_idealism">Platonic ideal</a> if you will:</p>

<blockquote>
  <p>In Quetelet’s mind, human averages had a certain moral mandate. By his logic, if everyone were optimally fed and lived under the same environmental conditions, they would be average. And this is what society should be striving for: the continual improvement of the average of the group.</p>
</blockquote>

<p>We look at averages all the time in our work. Some, like average <a href="https://developers.google.com/web/tools/lighthouse/audits/time-to-interactive">Time To Interactive (TTI)</a>, are useful measurements that allow us to improve our work; others, like the “average” user are decidedly less so. <span data-quotable="">The “average” person (or dog or flower) is a myth. Everyone and everything is unique to some equally unique degree.</span> <a href="https://en.wikipedia.org/wiki/Factory_second">Even mass-produced objects have variance</a>.</p>

<p>Designing for the “average” user is incredibly problematic. The episode I mentioned captured this perfectly in a story about the U.S. Army’s design of airplane cockpits:</p>

<blockquote>
  <p>[I]n 1926, when the Army designed its first airplane cockpit, they measured the physical dimensions of male pilots and calculated the average measurement of their height, weight, arm-length and other dimensions.</p>
</blockquote>

<blockquote>
  <p>The results determined the size and shape of the seat, the distance to the pedals and the stick, and even the shape of the flight helmets. This mean that, in part, pilots were selected based on their ability to fit into the cockpit designed for the average 1920s man.</p>
</blockquote>

<blockquote>
  <p>This worked more or less up until World War II, when the Army began recruiting hundreds of new pilots to expand its air forces (which became a separate branch of the military in 1947). But with the birth and expansion of the Air Force came a decline in performance and a rash of deaths. Even with no war, pilots continued to die during training, as they were unable to control their planes.</p>
</blockquote>

<blockquote>
  <p>The high death rate in the Air Force was a mystery for many years, but after blaming the pilots and their training programs, the military finally realized that the cockpit itself was to blame, that it didn’t actually fit most pilots.</p>
</blockquote>

<p>In 1950, the Air Force sent Gilbert S. Daniels out to collect ten measurements from thousands of airmen—yes, they were all men at the time—across the U.S. in order to establish a new average. After collecting the data, Daniels got curious and decided to see how many of the airmen he measured hit the average on all ten measurements. Not a single one. How about three of the measurements? Less than five percent. He realized that <span data-quotable="">in designing for an average, they were, in fact, designing for no one.</span> Based on this discovery, the Air Force commissioned new equipment that including features like adjustable foot pedals, helmet straps, flight suits, and seats. And, wonder of wonders, pilot performance improved dramatically.</p>

<p>When we design, we need to be cognizant of the variety of human experience and plan accordingly. <span data-quotable="">For our work to be successful, we need to accommodate the adjustments our users require for <em>them</em> to be successful.</span> Responsive layouts, adaptive interfaces, support for assistive technologies… all of these approaches enable our work to go further by enabling it to be tailored to the permanent, temporary, and/or situational needs of our users.</p>

<p>All of this is to say, this episode made me an even more ardent believer in the idea of <a href="http://alistapart.com/article/understandingprogressiveenhancement">progressive enhancement</a> and the continuum of experience it enables. You should go listen to it now, I promise there’s more to the story.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[An Event Apart Nashville 2016, Day One]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/an-event-apart-nashville-2016-day-one/"/>
    <updated>2016-03-16T10:54:59-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/an-event-apart-nashville-2016-day-one</id>
    <content type="html"><![CDATA[<p>Unfortunately, I was unable to spend Tuesday in Nashville for An Event Apart (for reasons that will be revealed in about a month), but I did catch Monday and it was amazing.</p>

<!-- more -->

<p>The esteemed <a href="http://www.zeldman.com/">Jeffrey Zeldman</a> kicked the day off with a talk entitled <em>Designing with Web Standards in 2016</em>. A theme he touched on repeatedly was that none of the problems we are facing in web design today are new problems. It’s a topic near and dear to my heart, something I wrote about in the closing chapter of <a href="http://adaptivewebdesign.info/2nd-edition/"><cite>Adaptive Web Design’s</cite> Second Edition</a> and <a href="/notebook/learn-from-the-past-enhance-for-the-future/">recently spoke about at EnhanceConf in London</a>. He knocked this one out of the park and my head was nodding so much my neck began to hurt.</p>

<p>Next up was <a href="http://www.webstandards.org/about/members/">my former WaSP colleague</a> <a href="https://rachelandrew.co.uk/">Rachel Andrew</a> to give us the skinny on CSS Grid Layouts. This is an amazing spec that I’ve always struggled to understand fully (despite the fact that’s i’ve written a Javascript polyfill for it). Rachel made it crystal clear and got me very excited about the future of layout on the Web.</p>

<p><a href="http://jensimmons.com/">Jen Simmons</a> dropped some serious CSS-related design knowledge bombs that perfectly complimented Rachel’s talk. She discussed Flexbox, CSS Shapes, Multi-column layout, viewport units and more, demonstrating how they can be used right now to progressively enhance the design of your sites.</p>

<p>After lunch, <a href="http://bradfrost.com/">Brad Frost</a> took to the stage to talk about Style Guides. I only caught the last half—I’ll admit to doing some last-minute rehearsing in the hallway—but the bits I did catch were good. I’ve seen his Atomic Design talk a few times, which this one builds on. In this talk he touches on a lot of the atomic design concepts, but he also talked a lot more about workflow and the role of the front-end developer. No doubt the evolution of this talk has come in large part through writing <a href="http://atomicdesign.bradfrost.com/">a book on Atomic Design</a> and in hosting <a href="http://styleguides.io/podcast/">a podcast with Anna Debenham on website style guides</a>.</p>

<p>Next, I was given the opportunity to share some thoughts and advice on designing and building. My talk, <em>The Features of Highly Effective Forms</em>, evolved out of several earlier talks on building forms. With this one, I wanted to strike a little more balance between the nuts and bolts of building forms and the hows and whys of building better forms.</p>

<p>The deck, <a href="http://www.slideshare.net/AaronGustafson/the-features-of-highly-effective-forms-an-event-apart-nashville-2016">which I’ve posted to SlideShare</a>, doesn’t stand on its own quite as well as some of my other forms decks simply because the talk contained a lot of storytelling I chose not to pair with slides—instead opting for an black screen so folks could focus—but I did call out the salient points. I’ve begun writing up some of the recommendations as part of my <a href="/notebook/tags/web-forms/">Modern Web Forms Best Practices series</a> and will continue to do so in the future. And one of the stories I told, which I highly recommend you check out, had to do with <a href="/notebook/consider-how-your-forms-read/">a lesson Facebook learned in managing how users report offensive photos</a>.</p>

<p><a href="https://bigmedium.com/">Josh Clark</a> wrapped the day up with a discussion of the future of interface as things move from digital back to physical. He talked about a lot of really cool new tech that has me excited about the future, including <a href="https://google.github.io/physical-web/">the Physical Web</a>, which Josh had running as a live demo. I wonder if anyone noticed I had a beacon running too ;-)</p>

<p>All in all, day one was a blast. As always, Jeffrey, Eric, <a href="https://www.linkedin.com/in/toby-malina-6247a028">Toby</a>, and <a href="http://www.escapadeproductions.com/">Marci</a> do an awesome job programming their events. I’m really bummed I could not stick around to see <a href="http://valhead.com/">Val</a>, <a href="https://twitter.com/grigs">Jason</a>, <a href="http://www.kryshiggins.com/">Krystal</a>, <a href="http://meyerweb.com/">Eric</a>, <a href="http://braintraffic.com/">Kristina</a>, and <a href="http://cameronmoll.com/">Cameron</a> rock it out though. I’m sure it was amazing.</p>

<p>You can check out attendees thoughts from the event by <a href="https://twitter.com/search?q=%23aeansh&amp;src=typd">searching Twitter using the #aeansh hashtag</a>. I’ve <a href="https://storify.com/AaronGustafson/reactions-and-takeaways-from-my-aeansh-talk">collected reactions to my talk on Storify</a> for posterity as well.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Avoiding Link Rot in Print With the Help of Perma.cc]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/avoiding-linkrot-in-print-with-the-help-of-perma-dot-cc/"/>
    <updated>2015-12-02T16:03:35-05:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/avoiding-linkrot-in-print-with-the-help-of-perma-dot-cc</id>
    <content type="html"><![CDATA[<p>I think we can all agree, <a href="https://en.wikipedia.org/wiki/Link_rot">link rot</a> is a problem. A 2014 study by Harvard Law School determined that <a href="http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=9282809&amp;fileId=S1472669614000255/">roughly 50% of the URLs referenced in U.S. Supreme Court opinions no longer work</a>. That’s <em>terrifying</em>.</p>

<!-- more -->

<p>When I was mid-way through writing <a href="http://adaptivewebdesign.info/2nd-edition/">the Second Edition of <cite>Adaptive Web Design</cite></a>, I realized that it was pretty likely some of the links I was referencing might disappear over the years. Little did I know, some of them would disappear <em>while I was writing the book!</em></p>

<p><a href="https://archive.org/web/">The Internet Archive’s Wayback Machine</a> is pretty good, but it doesn’t archive everything, and I often find captured pages end up broken—especially if they rely heavily JavaScript, but often images go missing as well. I wanted to make sure that when you pick up the book a year from now or even 10 years from now, the links will still work.</p>

<p>I evaluated a few options for creating a permanent archive of each and every link in the book (there are over 200), but then it dawned on me that <a href="https://perma.cc/">Perma.cc</a> might be the perfect answer.</p>

<p>Perma.cc was created by the <a href="http://librarylab.law.harvard.edu/">Harvard Library Innovation Lab</a> in reaction to the paper I mentioned earlier. It is a distributed archive of URLs for scholarly and legal documents, supported not only by Harvard, but over 90 (<em>and counting!</em>) libraries, distributed all over the world. <a href="https://github.com/harvard-lil/perma">It’s also open source</a>. Each <a href="https://perma.cc/docs#archive-formats">URL is preserved as a live view, an archived view, and a screen capture</a> taken when the link is added. Archived URLs are kept for a minumum of 2 years, but <a href="https://perma.cc/docs#vesting-links">may be “vested” into the permanent archive by a member organization</a>.</p>

<p>I had contributed some CSS to the project a while back, so I reached out to my contacts to see if they might be interested in vesting all of the links for the book. Turns out they were big fans of <a href="http://adaptivewebdesign.info/1st-edition/">the First Edition</a> and enthusiastically offered their support.</p>

<p>Converting all of the links took time (and a lot of double- and triple-checking), but the result is that every article, blog post, and web page that I referenced in the book will remain accessible to you in perpetuity. I think that’s pretty awesome. And, as an added bonus, since Perma.cc creates unique URLs that are relatively short, those of you who read it in print won’t have to re-type the often incredibly-lengthy original URLs.</p>

<p>I can’t thank <a href="http://mattphillips.info/">Matt Phillips</a>, <a href="https://twitter.com/abziegler">Adam Ziegler</a>, <a href="http://jackcushman.org/">Jack Cushman</a>, and everyone else at the Harvard Library Innovation Lab enough for creating Perma.cc <em>and</em> for offering their service to my readers. You all are amazing!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interface Experience Maps]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/interface-experience-maps/"/>
    <updated>2015-05-28T08:43:20-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/interface-experience-maps</id>
    <content type="html"><![CDATA[<p>One of the greatest challenges of progressive enhancement lies not with the coding, but with the planning. It can be incredibly challenging to articulate how a single interface might adapt to a wide variety of situations. Interface Experience Maps (Ix Maps) can help.</p>

<!-- more -->

<hr />

<p>Back in 2007, I was presented with this challenge while putting together a talk called <a href="https://web.archive.org/web/20070515221318/http://2007.sxsw.com/interactive/programming/panels/?action=show&amp;id=IAP060214">Ruining the User Experience</a> (which I co-presented for the first time at SXSW with <a href="https://twitter.com/sarahbeee">Sarah B. Nelson</a>). In the talk, Sarah and I discussed how to treat JavaScript as an enhancement and what happens when you don’t—in 2007, I know!</p>

<p>Anyway, in the talk I was struggling to convey the various decision points and interface adjustments that would happen as a result of those decisions. I don’t remember which of us came up with the idea—it was probably Sarah—but we opted to use a flowchart to visually describe what we were talking about on stage. Here was the first one we did:</p>

<figure id="fig-2015-05-28-01" class="media-container">{% adaptive_image /i/posts/2015-05-28/01.png %}<figcaption>An early flowchart used to describe progressive enhancement with JavaScript</figcaption></figure>

<p>It was pretty rudimentary, but it got the point across.</p>

<p>In future iterations of the talk, I expounded upon the idea of a flowchart for describing how an interface might adapt to different circumstances and browser capabilities. Here’s a particularly complex one I used to describe how a FAQ might function:</p>

<figure id="fig-2015-05-28-02" class="media-container">{% adaptive_image /i/posts/2015-05-28/02.png %}<figcaption>A flowchart describing the progressive enhancement and interaction options for an FAQ.</figcaption></figure>

<p>Over the years I found more and more ways to put these artifacts to use. And at a certain point, “flowchart” didn’t seem to cut it, so I began calling them “UI construction flows”—which, admittedly, was a mouthful—and then finally settled on the name “Interaction Experience Maps” with the help of a client.</p>

<h2 id="the-benefits-of-ix-maps">The Benefits of Ix Maps</h2>

<p>Ix Maps have become an invaluable tool to me and the teams I’ve worked with. They excel at articulating the different ways in which a given interface might adapt and what the end results of each adaptation might be.</p>

<p>This sort of documentation is invaluable to just about everyone on the team:</p>

<ul>
  <li>Copywriters get a clear picture of the different experience possibilities so they can craft the copy accordingly;</li>
  <li>Designers can see the different experience possibilities and can create wireframes and visual designs that account for each;</li>
  <li>Developers get a clear outline of what functionality is expected and know exactly what features and capability detection to employ in generating each experience; and</li>
  <li>The quality assurance team has a clear picture of what they should be looking for in each component of an interface.</li>
</ul>

<p>In short, Ix Maps ensure everyone on the team has a clear picture of what’s expected so they can work toward the common goal. One company I worked with found Ix Maps so useful that they created one for each and every pattern in their pattern library. Then they included the drawings as part of each pattern’s documentation.</p>

<h2 id="ix-maps-facilitate-collaboration-and-iteration">Ix Maps Facilitate Collaboration and Iteration</h2>

<p>An Ix Map is a pretty simple concept for anyone to come to grips with, making it a fantastic tool for enabling mixed teams—designers, developers, content folks, business strategists, etc.—to brainstorm ideas and build a strategy around progressive enhancement.</p>

<p>Time and time again, I have seen these simple diagrams bring a diverse team together and help them quickly and easily come up with very creative ways to address complex interface problems. That’s why I frequently use them as a tool in the workshops I lead.</p>

<p>Because they are so basic, Ix Maps can be sketched out quickly on paper, a whiteboard, or in software like OmniGraffle. And their simplicity also makes it quite easy to explore different ideas of how to adapt things and you don’t have to worry about throwing away an idea that doesn’t play out because it’s only a few boxes and arrows… you haven’t invested any time in design or production.</p>

<p>Here’s an example from <a href="https://www.facebook.com/events/804756366246427/">my Beyond Responsive workshop</a> that illustrates the evolution of a tabbed interface Ix Map from basic into something that is far more appropriate for differently-sized screens:</p>

<figure id="fig-2015-05-28-03" class="media-container">{% adaptive_image /i/posts/2015-05-28/03.png %}<figcaption>Pass 1: If JavaScript’s available, make a tabbed interface out of linear content. If not, leave it as it was.</figcaption></figure>

<figure id="fig-2015-05-28-04" class="media-container">{% adaptive_image /i/posts/2015-05-28/04.png %}<figcaption>Pass 2: Add a live width test into the mix to see if there’s enough room for the tabs and make it an accordion if the screen is too narrow.</figcaption></figure>

<figure id="fig-2015-05-28-05" class="media-container">{% adaptive_image /i/posts/2015-05-28/05.png %}<figcaption>Pass 3: Test for native <code>details</code>/<code>summary</code> support and use the native functionality if available.</figcaption></figure>

<h2 id="simple-powerful">Simple, Powerful</h2>

<p>Ix Maps have been incredibly useful to me and the dozens of teams I’ve worked with. They’ve helped us explore innovative ways to solve design challenges and have been an amazing touchstone to organize our work around. Give them a shot and I’m sure you’ll discover lots of ways to put them to use in your own projects.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lies, Damn Lies, and JavaScript]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/lies-damn-lies-and-javascript/"/>
    <updated>2015-04-27T15:10:11-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/lies-damn-lies-and-javascript</id>
    <content type="html"><![CDATA[<p>Late last week I stumbled on a video from <a href="https://twitter.com/graemepyle">Graeme Pyle</a> that exposed a UX lie in the <a href="https://www.fnb.co.za/">First National Bank of South Africa</a>.</p>

<!-- more -->

<p>{% youtube gpBWwl-Ngak %}</p>

<p>On the off chance you don’t want to watch the video, I’ll recap: When accessing certain screens on the FNB site, a progress meter is shown to indicate new content is being flowed into the browser. But it’s not.</p>

<p>As Graeme uncovered, the site uses JavaScript to create the progress bar, but the progress is not tied to anything except some basic JavaScript logic. The progress bar has no grounding in reality. It uses timeouts and follows a steady incrementation for a bit, then jumps up randomly for a bit before finishing.</p>

<p>Taking the easy way out like this may seem like a non-issue, but what happens when your user loses network connectivity? You guessed it: The progress meter still runs. <em>Doh!</em></p>

<p>Tracking true activity progress (like time to upload a file) involves constant communication between the server and the client. It used to be pretty difficult to do (and <a href="http://search.cpan.org/~lgoddard/CGI-ProgressBar-0.05/lib/CGI/ProgressBar.pm">required Perl</a>), but nowadays we have <a href="http://www.w3.org/TR/websockets/">WebSockets</a> and it’s much easier to keep the lines of communication between client and server open.</p>

<p>There is no reason to fake a progress bar. It’s pointless. Especially when you don’t even check to see if the user’s connection is still online.</p>
]]></content>
  </entry>
  
</feed>
